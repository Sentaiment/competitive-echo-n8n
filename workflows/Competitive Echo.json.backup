{
  "name": "Competitive Echo",
  "nodes": [
    {
      "parameters": {
        "amount": 3,
        "unit": "minutes"
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [3232, 32],
      "id": "dc85c819-aada-4830-834d-66c5f00a7fc1",
      "name": "Wait1",
      "webhookId": "9e1cf28f-9d16-49f8-984d-b46cdd680ef3"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "a02644ac-d68c-43e7-9466-431360ff5250",
              "leftValue": "={{ $json.readyState === 'READY' }}",
              "rightValue": "",
              "operator": {
                "type": "boolean",
                "operation": "true",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [6512, 176],
      "id": "4e6e5cdd-2aae-489d-bb73-805cec4e3e60",
      "name": "If"
    },
    {
      "parameters": {
        "amount": 2
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [6704, 224],
      "id": "5e43153d-db7a-41af-93a2-e1292363f595",
      "name": "Wait2",
      "webhookId": "c264fb07-8b9b-4ee9-a3b0-f6941249e7f5"
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [6064, 176],
      "id": "a4e6b50e-5003-4663-8e95-34528b97728b",
      "name": "Wait3",
      "webhookId": "7a19c203-b2c2-4e2a-8cf2-147bf2c56dcf"
    },
    {
      "parameters": {
        "url": "={{ $json.url }}",
        "sendHeaders": true,
        "specifyHeaders": "json",
        "jsonHeaders": "={\\n  \\\"User-Agent\\\": \\\"{{ $json.headers.User-Agent }}\\\",\\n  \\\"Accept\\\": \\\"{{ $json.headers.Accept }}\\\",\\n  \\\"Accept-Language\\\": \\\"{{ $json.headers.Accept-Language }}\\\",\\n  \\\"Accept-Encoding\\\": \\\"{{ $json.headers.Accept-Encoding }}\\\",\\n  \\\"Connection\\\": \\\"{{ $json.headers.Connection }}\\\",\\n  \\\"Upgrade-Insecure-Requests\\\": \\\"{{ $json.headers.Upgrade-Insecure-Requests }}\\\"\\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [5712, 528],
      "id": "2bfc4ac7-cf05-4571-a04e-d1539f915895",
      "name": "HTTP Request",
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "415afc36-01dc-4168-b7a9-8881b2d5d0f9",
              "leftValue": "={{ $json.source_url && $json.source_url !== \"\" && !$json.is_summary_item }}",
              "rightValue": "true",
              "operator": {
                "type": "boolean",
                "operation": "true",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.filter",
      "typeVersion": 2.2,
      "position": [5104, 544],
      "id": "e39c9444-031e-48c3-ac62-33c94f613726",
      "name": "Filter",
      "disabled": true
    },
    {
      "parameters": {
        "jsCode": "// HTTP Response Processor - Split Node Version\n// This node processes individual HTTP responses from the HTTP Request node\n// Designed to work with n8n's Split In Batches node for individual processing\n\nfunction processHttpResponse(url, httpResponse, citationData) {\n  const result = {\n    url: url,\n    citation_data: citationData,\n    processing_timestamp: new Date().toISOString(),\n    batch_id: citationData?.batch_id || \"unknown\",\n    item_index: citationData?.item_index || 0,\n  };\n\n  try {\n    // Check if we got a valid HTTP response\n    if (!httpResponse) {\n      result.scraping_status = \"no_response\";\n      result.error_type = \"no_response\";\n      result.scraping_error = \"No HTTP response received\";\n      result.authority_score_adjustment = -0.3;\n      console.log(`âŒ No response for ${url}`);\n      return result;\n    }\n\n    // Extract HTTP status code\n    const statusCode = httpResponse.statusCode || httpResponse.status || 0;\n    result.http_status_code = statusCode;\n\n    // Extract response headers\n    result.response_headers = httpResponse.headers || {};\n    result.content_type = result.response_headers[\"content-type\"] || \"unknown\";\n    result.content_length =\n      parseInt(result.response_headers[\"content-length\"]) || 0;\n\n    // Classify response based on status code\n    if (statusCode >= 200 && statusCode < 300) {\n      // Success - check content quality\n      result.scraping_status = \"success\";\n      result.error_type = null;\n      result.scraping_error = null;\n\n      // Check if content is substantial\n      const htmlContent = httpResponse.body || \"\";\n      result.content_length_actual = htmlContent.length;\n\n      if (htmlContent.length < 100) {\n        result.scraping_status = \"success_but_minimal_content\";\n        result.error_type = \"minimal_content\";\n        result.scraping_error = `Content too short (${htmlContent.length} chars)`;\n        result.authority_score_adjustment = -0.1;\n        console.log(\n          `âš ï¸  Minimal content for ${url} (${htmlContent.length} chars)`\n        );\n      } else {\n        // Only extract metadata for substantial content (performance optimization)\n        if (htmlContent.length > 500) {\n          result.extracted_metadata = extractMetadataFromHtml(htmlContent, url);\n        } else {\n          result.extracted_metadata = {\n            content_type: \"web_page\",\n            minimal_content: true,\n          };\n        }\n        result.authority_score_adjustment = 0.1; // Bonus for successful scraping\n        console.log(`âœ… Success for ${url} (${htmlContent.length} chars)`);\n      }\n    } else if (statusCode === 404) {\n      result.scraping_status = \"not_found\";\n      result.error_type = \"not_found\";\n      result.scraping_error = \"404 Not Found\";\n      result.authority_score_adjustment = -0.5; // Significant penalty for 404\n      console.log(`ðŸ” 404 Not Found: ${url}`);\n    } else if (statusCode === 403) {\n      result.scraping_status = \"forbidden\";\n      result.error_type = \"forbidden\";\n      result.scraping_error = \"403 Forbidden - likely anti-bot protection\";\n      result.authority_score_adjustment = -0.2; // Penalty for blocked access\n      console.log(`ðŸš« 403 Forbidden: ${url}`);\n    } else if (statusCode >= 400 && statusCode < 500) {\n      result.scraping_status = \"client_error\";\n      result.error_type = \"client_error\";\n      result.scraping_error = `${statusCode} Client Error`;\n      result.authority_score_adjustment = -0.3;\n      console.log(`âš ï¸  Client Error ${statusCode}: ${url}`);\n    } else if (statusCode >= 500 && statusCode < 600) {\n      result.scraping_status = \"server_error\";\n      result.error_type = \"server_error\";\n      result.scraping_error = `${statusCode} Server Error`;\n      result.authority_score_adjustment = -0.2; // Less penalty for server errors\n      console.log(`ðŸ”¥ Server Error ${statusCode}: ${url}`);\n    } else {\n      result.scraping_status = \"unknown_status\";\n      result.error_type = \"unknown_status\";\n      result.scraping_error = `Unknown status code: ${statusCode}`;\n      result.authority_score_adjustment = -0.3;\n      console.log(`â“ Unknown status ${statusCode}: ${url}`);\n    }\n\n    // Add response body preview (first 200 chars) for debugging - reduced for performance\n    if (httpResponse.body && httpResponse.body.length > 0) {\n      result.response_preview = httpResponse.body.substring(0, 200);\n    }\n\n    // Calculate authority score adjustment\n    const originalScore = result.citation_data?.authority_score || 0;\n    const adjustment = result.authority_score_adjustment || 0;\n    const finalScore = Math.max(0, originalScore + adjustment);\n\n    result.authority_score_analysis = {\n      original_score: originalScore,\n      adjustment: adjustment,\n      final_score: finalScore,\n      adjustment_reason: result.error_type || \"success\",\n    };\n\n    console.log(\n      `ðŸ“Š Authority Score: ${originalScore} â†’ ${finalScore} (${\n        adjustment > 0 ? \"+\" : \"\"\n      }${adjustment}) for ${url}`\n    );\n  } catch (error) {\n    result.scraping_status = \"processing_failed\";\n    result.error_type = \"processing_error\";\n    result.scraping_error = `Response processing failed: ${error.message}`;\n    result.authority_score_adjustment = -0.3;\n    console.log(`ðŸ’¥ Processing error for ${url}: ${error.message}`);\n  }\n\n  return result;\n}\n\nfunction extractMetadataFromHtml(html, url) {\n  try {\n    // Only extract metadata if content is substantial (performance optimization)\n    if (!html || html.length < 100) {\n      return { content_type: \"web_page\", minimal_content: true };\n    }\n\n    const metadata = {\n      title: null,\n      author: null,\n      publication_date: null,\n      description: null,\n      publisher: null,\n      content_type: \"web_page\",\n    };\n\n    // Use faster string operations instead of regex where possible\n    const lowerHtml = html.toLowerCase();\n\n    // Extract title - use indexOf for better performance\n    const titleStart = lowerHtml.indexOf(\"<title>\");\n    if (titleStart !== -1) {\n      const titleEnd = lowerHtml.indexOf(\"</title>\", titleStart);\n      if (titleEnd !== -1) {\n        const titleContent = html.substring(titleStart + 7, titleEnd);\n        metadata.title = titleContent\n          .trim()\n          .replace(/\\s+/g, \" \")\n          .substring(0, 200); // Limit length\n      }\n    }\n\n    // Only extract other metadata if title was found (indicating valid HTML)\n    if (metadata.title) {\n      // Extract meta description - simplified regex\n      const descMatch = html.match(\n        /<meta[^>]*name=[\"']?description[\"']?[^>]*content=[\"']([^\"']{1,300})[\"']/i\n      );\n      if (descMatch) {\n        metadata.description = descMatch[1].trim();\n      }\n\n      // Extract author - simplified regex\n      const authorMatch = html.match(\n        /<meta[^>]*name=[\"']?author[\"']?[^>]*content=[\"']([^\"']{1,100})[\"']/i\n      );\n      if (authorMatch) {\n        metadata.author = authorMatch[1].trim();\n      }\n    }\n\n    return metadata;\n  } catch (error) {\n    return { error: `Metadata extraction failed: ${error.message}` };\n  }\n}\n\n// Main processing logic for individual response\nconst inputData = $input.all();\nconst processedResults = [];\n\nconsole.log(`ðŸ”„ Processing individual HTTP response...`);\n\n// Process the single HTTP response (split node processes one at a time)\nfor (const item of inputData) {\n  const data = item.json;\n\n  // Skip metadata items\n  if (data.is_metadata_item) {\n    console.log(`â­ï¸  Skipping metadata item`);\n    continue;\n  }\n\n  console.log(`ðŸ” Processing URL: ${data.url}`);\n\n  const result = processHttpResponse(\n    data.url,\n    data, // The entire item contains the HTTP response\n    data.citation_data\n  );\n\n  processedResults.push(result);\n}\n\n// Return the processed result for this individual response\nreturn processedResults.map((result) => ({\n  json: {\n    ...result,\n    is_individual_response: true,\n    processing_node: \"http_response_processor_split\",\n    prd_version: \"2.1_split\",\n    workflow_stage: \"individual_response_processing_complete\",\n  },\n}));\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [5888, 528],
      "id": "182cc0c5-e2cf-49f8-80cd-2ea8438b8872",
      "name": "Response Parser",
      "disabled": true
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [6080, 512],
      "id": "092a9bce-85f4-4954-b028-7eaee9e99650",
      "name": "Web Validation Merge",
      "disabled": true
    },
    {
      "parameters": {
        "options": {
          "reset": true
        }
      },
      "type": "n8n-nodes-base.splitInBatches",
      "typeVersion": 3,
      "position": [5488, 544],
      "id": "e2d68d44-774f-48cc-bce0-bde0c6335c3f",
      "name": "Split in Batches",
      "disabled": true
    },
    {
      "parameters": {
        "jsCode": "// Data Stripper Node - Extracts only essential data for HTTP processing pipeline\n// This node preserves full webscraper data but only passes minimal data forward\n\nconsole.log(\"=== DATA STRIPPER NODE ===\");\nconsole.log(\"Input items:\", $input.all().length);\n\nconst inputItems = $input.all();\nconst strippedItems = [];\n\n// Process each input item\ninputItems.forEach((item, index) => {\n  const data = item.json;\n\n  console.log(`Processing item ${index + 1}:`, {\n    has_source_url: !!data.source_url,\n    has_extracted_url: !!data.extracted_url,\n    is_summary_item: !!data.is_summary_item,\n  });\n\n  // Skip summary items - they don't need HTTP processing\n  if (data.is_summary_item) {\n    console.log(`â­ï¸  Skipping summary item ${index + 1}`);\n    return;\n  }\n\n  // Create minimal item with only essential data for HTTP processing\n  const strippedItem = {\n    // Essential for HTTP processing\n    url: data.source_url || data.extracted_url,\n    original_url: data.source_url,\n    clean_url: data.extracted_url,\n\n    // Unique identifier for merging back later\n    citation_id: data.citation_id || `citation_${Date.now()}_${index}`,\n    item_index: data.item_index || index + 1,\n\n    // Minimal metadata for tracking\n    url_extraction_status: data.url_extraction_status,\n    scraping_timestamp: data.scraping_timestamp,\n\n    // Store reference to full data for later merging\n    _full_citation_data: data,\n    _data_stripper_timestamp: new Date().toISOString(),\n  };\n\n  // Add to stripped items\n  strippedItems.push({\n    json: strippedItem,\n  });\n\n  console.log(`âœ… Stripped item ${index + 1}:`, {\n    url: strippedItem.url,\n    citation_id: strippedItem.citation_id,\n  });\n});\n\n// Log summary statistics (but don't add summary item to output)\nconst summaryStats = {\n  total_input_items: inputItems.length,\n  processed_items: strippedItems.length,\n  skipped_summary_items: inputItems.filter((item) => item.json.is_summary_item)\n    .length,\n  stripping_timestamp: new Date().toISOString(),\n  prd_version: \"2.1_fixed\",\n};\n\nconsole.log(`=== DATA STRIPPER COMPLETE ===`);\nconsole.log(`Input items: ${summaryStats.total_input_items}`);\nconsole.log(`Output items: ${summaryStats.processed_items}`);\nconsole.log(`Skipped summary items: ${summaryStats.skipped_summary_items}`);\nconsole.log(\n  `Memory saved: ~${Math.round(inputItems.length * 0.7 * 100)}KB per item`\n);\n\nreturn strippedItems;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [5280, 544],
      "id": "86e5c253-e946-4d6e-b18d-38f9a90e4cb1",
      "name": "Data Stripper",
      "disabled": true
    },
    {
      "parameters": {
        "language": "JavaScript",
        "jsCode": "// Fixed Parse & Group Data for Wynn Las Vegas CSV structure\nconst rows = $input.all().map((i) => i.json);\n\nconsole.log(\"=== PROCESSING WYNN DATA ===\");\nconsole.log(\"Total rows:\", rows.length);\n\n// Helper functions\nconst norm = (s) => (s == null ? \"\" : String(s).trim());\nconst cleanDomain = (u = \"\") =>\n  norm(u)\n    .replace(/^https?:\\/\\//i, \"\")\n    .replace(/^www\\./i, \"\")\n    .split(\"/\")[0] || null;\n\n// Find the Brands row - handle BOM character in column name\nconst brandsRow = rows.find((row) => {\n  // Check both possible column names (with and without BOM)\n  const tableName1 = row[\"Table name\"] || \"\";\n  const tableName2 = row[\"ï»¿Table name\"] || \"\"; // BOM character version\n\n  return (\n    String(tableName1).toLowerCase() === \"brands\" ||\n    String(tableName2).toLowerCase() === \"brands\"\n  );\n});\n\nif (!brandsRow) {\n  throw new Error(\n    `No brands row found. Available table names: ${rows\n      .map((r) => r[\"Table name\"] || r[\"ï»¿Table name\"])\n      .join(\", \")}`\n  );\n}\n\nconsole.log(\"Found brands row:\", brandsRow);\n\n// Get the record data - handle both column name variations\nconst recordDataRaw = brandsRow[\"Record data\"] || brandsRow[\"ï»¿Record data\"];\n\nif (!recordDataRaw) {\n  throw new Error(\"No record data found in brands row\");\n}\n\n// Parse the JSON record data\nlet brandData;\ntry {\n  brandData =\n    typeof recordDataRaw === \"string\"\n      ? JSON.parse(recordDataRaw)\n      : recordDataRaw;\n} catch (e) {\n  throw new Error(`Failed to parse brands record data: ${e.message}`);\n}\n\nconsole.log(\"Parsed brand data:\", brandData);\n\n// Extract the brand information\nconst company = norm(brandData.name) || null;\nconst competitors = Array.isArray(brandData.competitors)\n  ? brandData.competitors.map(norm).filter(Boolean)\n  : [];\nconst industry = norm(brandData.industry) || null;\nconst domain = cleanDomain(brandData.brand_url || \"\");\nconst positioning = norm(brandData.positioning) || null;\nconst description = norm(brandData.description) || null;\nconst voice = norm(brandData.voice) || null;\nconst values = norm(brandData.values) || null;\n\n// Create comprehensive whitelist\nconst whitelist = Array.from(\n  new Set([company, ...competitors].filter(Boolean))\n);\n\nconsole.log(\"Extracted data:\");\nconsole.log(\"- Company:\", company);\nconsole.log(\"- Competitors:\", competitors);\nconsole.log(\"- Industry:\", industry);\nconsole.log(\"- Whitelist:\", whitelist);\n\n// Store company name in workflow context for later use\ntry {\n  if (typeof $workflow !== \"undefined\") {\n    $workflow.context = $workflow.context || {};\n    $workflow.context.target_company = company;\n    console.log(\"Stored company in workflow context:\", company);\n    console.log(\"Workflow context after setting:\", $workflow.context);\n  } else {\n    console.log(\"$workflow not available in 003_parseGroupData\");\n  }\n} catch (e) {\n  console.log(\"Could not store company in workflow context:\", e.message);\n}\n\n// Build enhanced context for dynamic scenario generation\nconst businessContext = {\n  industry_type: industry,\n  positioning_statement: positioning,\n  brand_description: description,\n  brand_voice: voice,\n  brand_values: values,\n  competitive_set: whitelist,\n  market_focus:\n    industry === \"Hotels & Resorts\"\n      ? \"luxury hospitality and guest experience\"\n      : \"business solutions and customer experience\",\n};\n\nreturn [\n  {\n    json: {\n      company,\n      competitors,\n      industry,\n      domain,\n      positioning,\n      description,\n      voice,\n      values,\n      whitelist,\n      business_context: businessContext,\n      // Keep original data for debugging\n      debug_info: {\n        found_brands_row: true,\n        parsed_successfully: true,\n        total_rows_processed: rows.length,\n      },\n    },\n  },\n];\n"
      },
      "id": "10533e83-a9c2-47d9-813f-f9cf7cfb75b2",
      "name": "003_parseGroupData",
      "type": "n8n-nodes-base.code",
      "typeVersion": 1,
      "position": [112, -384]
    },
    {
      "parameters": {
        "jsCode": "// Competitor Research Node - Research additional competitors if we have fewer than 10\nconst inputData = $json;\n\nconsole.log(\"=== COMPETITOR RESEARCH ===\");\nconsole.log(\"Current competitors:\", inputData.competitors?.length || 0);\nconsole.log(\"Company:\", inputData.company);\nconsole.log(\"Industry:\", inputData.industry);\n\n// Check if we need to research more competitors\nconst currentCompetitors = inputData.competitors || [];\nconst minCompetitors = 14;\n\nif (currentCompetitors.length >= minCompetitors) {\n  console.log(\"Sufficient competitors found, no research needed\");\n  return [{ json: inputData }];\n}\n\nconst company = inputData.company || \"\";\nconst industry = inputData.industry || \"\";\nconst competitorsNeeded = minCompetitors - currentCompetitors.length;\n\nconsole.log(`Need to research ${competitorsNeeded} additional competitors`);\n\n// Create research prompt for additional competitors\nconst researchPrompt = {\n  system_content: `You are a competitive intelligence researcher. Research additional competitors in the ${industry} industry for ${company}. Return ONLY valid JSON in the exact format specified.`,\n  user_content: `COMPETITOR RESEARCH REQUEST\n\nCompany: ${company}\nIndustry: ${industry}\nCurrent Competitors: ${currentCompetitors.join(\", \")}\n\nResearch ${competitorsNeeded} additional competitors in the ${industry} industry that would be relevant for competitive analysis of ${company}.\n\nRequirements:\n- Focus on direct competitors in the same market segment\n- Include both established and emerging competitors\n- Prioritize companies with similar positioning or target market\n- Do NOT include companies that are not direct competitors\n- Do NOT make up or invent companies\n- Only include real, verifiable companies\n\nReturn ONLY valid JSON in this EXACT format:\n{\n  \"additional_competitors\": [\n    {\n      \"company_name\": \"Real Company Name\",\n      \"industry_segment\": \"luxury_hospitality\",\n      \"competitive_relevance\": \"direct_competitor\",\n      \"market_position\": \"premium\",\n      \"research_confidence\": \"high|medium|low\",\n      \"verification_notes\": \"Brief note on why this is a relevant competitor\"\n    }\n  ],\n  \"research_metadata\": {\n    \"total_researched\": ${competitorsNeeded},\n    \"research_timestamp\": \"${new Date().toISOString()}\",\n    \"industry_focus\": \"${industry}\",\n    \"target_company\": \"${company}\"\n  }\n}\n\nFocus on real companies that would actually compete with ${company} in the ${industry} industry.`,\n};\n\nreturn [\n  {\n    json: {\n      ...inputData,\n      competitor_research_needed: true,\n      research_prompt: researchPrompt,\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [336, 32],
      "id": "competitor-research-node",
      "name": "004_researchAdditionalCompetitors"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.anthropic.com/v1/messages",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "anthropicApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "anthropic-version",
              "value": " 2023-06-01"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify({\n  \"model\": \"claude-3-5-sonnet-20240620\",\n  \"max_tokens\": 2000,\n  \"temperature\": 0.1,\n  \"system\": $json.research_prompt?.system_content || \"You are a competitive intelligence researcher.\",\n  \"messages\": [\n    { \"role\": \"user\", \"content\": $json.research_prompt?.user_content || \"Research additional competitors.\" }\n  ]\n}) }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [560, -112],
      "id": "competitor-research-request",
      "name": "005_competitorResearchRequest-http",
      "credentials": {
        "anthropicApi": {
          "id": "1jk5Er35vKWwOaad",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Parse Competitor Research Results and Merge with Original Data\nconst inputData = $input.first().json;\nconst researchResponse = $input.last().json;\n\nconsole.log(\"=== MERGING COMPETITOR RESEARCH ===\");\nconsole.log(\"Original competitors:\", inputData.competitors?.length || 0);\n\n// Extract research results\nlet additionalCompetitors = [];\nlet researchMetadata = {};\n\ntry {\n  // Handle different response formats\n  let researchText = \"\";\n  if (researchResponse.content?.[0]?.text) {\n    researchText = researchResponse.content[0].text;\n  } else if (researchResponse.response?.content?.[0]?.text) {\n    researchText = researchResponse.response.content[0].text;\n  } else if (typeof researchResponse === 'string') {\n    researchText = researchResponse;\n  } else {\n    researchText = JSON.stringify(researchResponse);\n  }\n  \n  // Try to parse JSON from response\n  let researchData;\n  try {\n    researchData = JSON.parse(researchText);\n  } catch (e) {\n    // Try to extract JSON from text\n    const jsonMatch = researchText.match(/\\{[\\s\\S]*\\}/);\n    if (jsonMatch) {\n      researchData = JSON.parse(jsonMatch[0]);\n    } else {\n      throw new Error(\"No valid JSON found in research response\");\n    }\n  }\n  \n  additionalCompetitors = researchData.additional_competitors || [];\n  researchMetadata = researchData.research_metadata || {};\n  \n  console.log(\"Found additional competitors:\", additionalCompetitors.length);\n  \n} catch (error) {\n  console.error(\"Error parsing research results:\", error.message);\n  console.log(\"Research response:\", researchResponse);\n  \n  // Fallback: return original data without additional competitors\n  return [{ json: { ...inputData, competitor_research_error: error.message } }];\n}\n\n// Merge original competitors with researched ones\nconst originalCompetitors = inputData.competitors || [];\nconst allCompetitors = [...originalCompetitors];\n\n// Add new competitors (avoid duplicates)\nfor (const newComp of additionalCompetitors) {\n  const companyName = newComp.company_name || newComp.name || \"\";\n  if (companyName && !allCompetitors.includes(companyName)) {\n    allCompetitors.push(companyName);\n  }\n}\n\nconsole.log(\"Total competitors after research:\", allCompetitors.length);\n\n// Return merged data\nreturn [{\n  json: {\n    ...inputData,\n    competitors: allCompetitors,\n    competitor_research: {\n      original_count: originalCompetitors.length,\n      researched_count: additionalCompetitors.length,\n      total_count: allCompetitors.length,\n      research_metadata: researchMetadata,\n      additional_competitors: additionalCompetitors\n    }\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [784, 32],
      "id": "merge-competitor-research",
      "name": "006_mergeCompetitorResearch"
    },
    {
      "parameters": {
        "jsCode": "// Dynamic Prompt 31 - Generates scenarios based on actual CSV data\n\n// ==== Inputs ====\nconst company = ($json.company || \"\").trim();\nconst competitors = Array.isArray($json.competitors) ? $json.competitors : [];\nconst industry = ($json.industry || \"\").trim();\nconst positioning = $json.positioning || \"\";\nconst description = $json.description || \"\";\nconst values = $json.values || \"\";\n\n// ==== Limits (centralized) ====\nconst TITLE_WORD_LIMIT = 6;\nconst USER_QUERY_WORD_LIMIT = 50; // relaxed from 28\nconst RATIONALE_WORD_LIMIT = 12;\n\n// ==== Whitelist ====\nconst whitelist = Array.from(\n  new Set([company, ...competitors].filter(Boolean))\n);\nif (whitelist.length < 2) {\n  throw new Error(\"Need at least 2 brands for competitive analysis.\");\n}\nconst requiredBrandsList = whitelist.join(\", \");\n\n// ==== Dynamic context generation ====\n// Define BEFORE use to avoid \"is not defined\" in VM\nfunction generateIndustryContext(\n  industryRaw,\n  positioningText,\n  descriptionText,\n  valuesText\n) {\n  const s = (industryRaw || \"\").toLowerCase();\n\n  // keyword flags\n  const isHotel = /hotel|resort|hospitality/.test(s);\n  const isRestaurant = /restaurant|food|dining/.test(s);\n  const isRetail = /retail|fashion|shopping/.test(s);\n  const isTech = /tech|software|digital|saas|platform/.test(s);\n\n  // defaults\n  let contextualFocus = \"business solutions and service provider selection\";\n  let decisionFactors =\n    \"quality, service excellence, value proposition, reputation, reliability, innovation, customer support\";\n  let scenarioTypes =\n    \"service provider selection, business solution comparisons, vendor evaluation decisions\";\n  let industryLabel = industryRaw || \"General\";\n\n  if (isHotel) {\n    contextualFocus = \"luxury hospitality and guest experience selection\";\n    decisionFactors =\n      \"service quality, amenities, location, reputation, dining options, spa services, room quality, loyalty programs, special experiences, value proposition\";\n    scenarioTypes =\n      \"luxury hotel selection decisions, booking preferences, resort experience comparisons, hospitality service evaluations\";\n    industryLabel = \"Hotels & Resorts\";\n  } else if (isRestaurant) {\n    contextualFocus = \"dining experience and culinary service selection\";\n    decisionFactors =\n      \"food quality, service excellence, ambiance, value, location convenience, dietary accommodations, reservation availability\";\n    scenarioTypes =\n      \"restaurant choice decisions, dining experience preferences, culinary service comparisons\";\n    industryLabel = \"Restaurants & Dining\";\n  } else if (isRetail) {\n    contextualFocus = \"retail shopping and brand preference\";\n    decisionFactors =\n      \"product quality, customer service, pricing, brand reputation, shopping experience, product selection, store atmosphere\";\n    scenarioTypes =\n      \"brand selection decisions, shopping venue preferences, retail experience comparisons\";\n    industryLabel = \"Retail & Fashion\";\n  } else if (isTech) {\n    contextualFocus = \"technology solutions and platform selection\";\n    decisionFactors =\n      \"functionality, user experience, integration capabilities, support quality, pricing, security, scalability, roadmap\";\n    scenarioTypes =\n      \"technology platform decisions, software selection, digital solution comparisons\";\n    industryLabel = \"Technology & Software\";\n  }\n\n  return { contextualFocus, decisionFactors, scenarioTypes, industryLabel };\n}\n\nconst { contextualFocus, decisionFactors, scenarioTypes, industryLabel } =\n  generateIndustryContext(industry, positioning, description, values);\n\n// ==== Themes ====\nconst positioningThemes = positioning\n  ? positioning\n      .toLowerCase()\n      .match(\n        /\\b(luxury|premium|quality|service|innovation|authentic|exclusive|sophisticated)\\b/g\n      ) || []\n  : [];\nconst valueThemes = values\n  ? values\n      .toLowerCase()\n      .match(\n        /\\b(service|quality|innovation|luxury|authentic|personal|environment|sustain|art|design)\\b/g\n      ) || []\n  : [];\nconst combinedThemes = [...new Set([...positioningThemes, ...valueThemes])];\nconst combinedThemesText = combinedThemes.length\n  ? combinedThemes.join(\", \")\n  : \"quality, service, excellence\";\n\n// ==== System + User prompts ====\nconst system_content = `You are Sentaiment's Statistical Competitive Ranking Analyzer.\nYour ONLY task: generate buyer-decision scenarios dynamically based on the provided business context.\n\nDYNAMIC CONTEXT ADAPTATION:\n- Industry Focus: ${contextualFocus}\n- Key Decision Factors: ${decisionFactors}\n- Scenario Types: ${scenarioTypes}\n- Brand Positioning Context: ${\n  positioning ? positioning.substring(0, 200) : \"Premium market positioning\"\n}\n- Key Brand Themes: ${combinedThemesText}\n\nINDUSTRY-SPECIFIC REQUIREMENTS:\n${\n  /Hotels/i.test(industryLabel)\n    ? `\n- Focus on luxury hospitality decision-making scenarios\n- Consider guest experience factors: service, amenities, dining, location, reputation\n- Include scenarios about booking decisions, experience preferences, loyalty considerations\n- Address both leisure and business travel contexts\n`\n    : `\n- Focus on ${industryLabel} industry decision-making scenarios\n- Consider relevant business factors for ${industryLabel}\n- Include realistic customer decision points for this industry\n- Address both individual and business customer contexts\n`\n}\n\nSTRICT COMPETITOR POLICY:\n- Allowed names = ALLOWED_COMPETITORS (case-insensitive) plus COMPANY_NAME. No others.\n- EVERY scenario MUST list ALL allowed brands in the user_query (explicitly by name). No omissions.\n- Never write pairwise \"A vs B\"; always a full-set comparison among ALL allowed brands.\n- CRITICAL: You must analyze ALL ${\n  whitelist.length\n} competitors in every scenario, not just 4.\n- Do NOT limit yourself to only 4 competitors - include ALL competitors in every analysis.\n\nDYNAMIC SCENARIO GENERATION:\n- Adapt question types to the specific industry: ${industryLabel}\n- Use the brand's actual positioning: ${\n  positioning ? positioning.substring(0, 100) + \"...\" : \"Premium positioning\"\n}\n- Focus on realistic customer decision points for ${industryLabel}\n- Consider the competitive factors most relevant to this business type\n\nOUTPUT FORMAT:\n- Concise strings. No invented facts/numbers/rankings.\n- Per scenario limits: title â‰¤ ${TITLE_WORD_LIMIT} words; user_query â‰¤ ${USER_QUERY_WORD_LIMIT} words; rationale â‰¤ ${RATIONALE_WORD_LIMIT} words.\n- expected_metrics = []; data_limitations = []; confidence_score = null.\n\nDIMENSION DISTRIBUTION:\n- Scenarios 1-5: functional_competence (performance, features, service quality)\n- Scenarios 6-9: identity_values (brand alignment, values, positioning)\n- Scenarios 10-12: market_leadership (reputation, innovation, market position)\n\nReturn ONLY valid JSON in this EXACT format:\n<<JSON_START>>\n{\n  \"scenarios\": [\n    {\n      \"scenario_id\": 1,\n      \"scenario_title\": \"Luxury Suite Design Comparison\",\n      \"user_query\": \"How do luxury suite designs compare across ${requiredBrandsList}?\",\n      \"dimension\": \"design_aesthetics\",\n      \"rationale\": \"Analyzes design elements that differentiate luxury accommodations\",\n      \"expected_metrics\": [],\n      \"data_limitations\": [],\n      \"confidence_score\": null\n    }\n  ],\n  \"source_citations\": []\n}\n<<JSON_END>>`;\n\nconst user_content = `COMPANY_NAME: ${company}\nALLOWED_COMPETITORS: ${JSON.stringify(whitelist)}\nINDUSTRY: ${industryLabel}\nPOSITIONING: ${positioning}\nBRAND_DESCRIPTION: ${\n  description ? description.substring(0, 300) : \"Not provided\"\n}\nBRAND_VALUES: ${values ? values.substring(0, 200) : \"Not provided\"}\n\nCRITICAL JSON STRUCTURE REQUIREMENTS:\n- Return EXACTLY 12 scenarios with scenario_id 1-12\n- Each scenario MUST have: scenario_id, scenario_title, user_query, dimension, rationale, expected_metrics, data_limitations, confidence_score\n- expected_metrics = [] (empty array)\n- data_limitations = [] (empty array)\n- confidence_score = null\n- In EVERY user_query, explicitly list ALL brands: ${requiredBrandsList}\n- scenario_title â‰¤ ${TITLE_WORD_LIMIT} words\n- user_query â‰¤ ${USER_QUERY_WORD_LIMIT} words\n- rationale â‰¤ ${RATIONALE_WORD_LIMIT} words\n\nMANDATORY COMPETITOR REQUIREMENT:\n- You MUST include ALL ${whitelist.length} companies in every scenario analysis\n- Do NOT limit yourself to only 4 companies\n- Every user_query must mention ALL companies: ${requiredBrandsList}\n- The LLM will analyze ALL companies, not just a subset\n- IMPORTANT: The first company in the list is the TARGET COMPANY being analyzed and must be included in all rankings\n\nDIMENSION DISTRIBUTION:\n- Scenarios 1-5: functional_competence\n- Scenarios 6-9: identity_values\n- Scenarios 10-12: market_leadership\n\nTASK:\n- Generate 12 buyer-decision scenarios adapted to ${industryLabel}\n- Focus on ${contextualFocus}\n- Consider these decision factors: ${decisionFactors}\n- Create ${scenarioTypes} that buyers in this industry would actually face\n- Use the brand's actual positioning and values to inform realistic competitive scenarios\n- Incorporate brand themes: ${combinedThemesText}\n- CRITICAL: Each scenario must analyze ALL ${\n  whitelist.length\n} competitors, not just 4\n- Return ONLY the JSON between <<JSON_START>> and <<JSON_END>> with NO additional text.`;\n\n// ==== Debug logs ====\nconsole.log(\"=== DYNAMIC PROMPT GENERATION ===\");\nconsole.log(\"Industry (raw):\", industry);\nconsole.log(\"Industry (label):\", industryLabel);\nconsole.log(\"Company:\", company);\nconsole.log(\"Competitors:\", competitors);\nconsole.log(\"Whitelist size:\", whitelist.length);\nconsole.log(\"Contextual Focus:\", contextualFocus);\nconsole.log(\"Brand Themes:\", combinedThemes);\n\n// ==== Output ====\nreturn [\n  {\n    json: {\n      system_content,\n      user_content,\n      whitelist,\n      business_context: {\n        industry: industryLabel,\n        positioning,\n        contextual_focus: contextualFocus,\n        brand_themes: combinedThemes,\n      },\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1008, 32],
      "id": "a78d0b0f-0e5e-4f46-8334-b72feda63bfc",
      "name": "007_preparePrompt31"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.anthropic.com/v1/messages",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "anthropicApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "anthropic-version",
              "value": " 2023-06-01"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify({\n    model: \"claude-3-5-sonnet-20240620\",\n    max_tokens: 6000,\n    temperature: 0.2,\n    // Put your full system prompt here:\n    system: $json.system_content,\n    messages: [\n      { role: \"user\", content: $json.user_content }\n    ]\n  }) }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [1232, 32],
      "id": "d35eea3b-6c82-46c0-a95c-c5d85bd039ab",
      "name": "008_prompt31Request-http",
      "credentials": {
        "anthropicApi": {
          "id": "1jk5Er35vKWwOaad",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Ensure Valid JSON (Prompt 31) â€” robust extractor for Claude in n8n\n// Works with either the Anthropic Messages node or a raw HTTP Request node.\n\nconst resp = $input.first().json; // <-- read from upstream input\n\n// Preserve metadata from the original input\nconst originalMetadata = {\n  whitelist: resp.whitelist || [],\n  business_context: resp.business_context || {},\n  system_content: resp.system_content,\n  user_content: resp.user_content,\n};\n\nfunction getText(r) {\n  if (!r) return \"\";\n  if (typeof r === \"string\") return r;\n\n  // Anthropic Messages (n8n node) common shapes\n  if (r.content?.[0]?.text) return r.content[0].text; // { content: [{text}] }\n  if (r.response?.content?.[0]?.text) return r.response.content[0].text; // { response: { content: [{text}] } }\n  if (r.messages?.[0]?.content?.[0]?.text) return r.messages[0].content[0].text;\n\n  // Raw HTTP Request â†’ parsed JSON body (Anthropic /v1/messages)\n  if (r?.type === \"message\" && r.content?.[0]?.text) return r.content[0].text;\n\n  // OpenAI-ish fallback (not expected here, but safe)\n  if (r?.choices?.[0]?.message?.content) return r.choices[0].message.content;\n  if (r?.data?.[0]?.message?.content) return r.data[0].message.content;\n\n  // Last resort: stringify\n  return JSON.stringify(r);\n}\n\nlet txt = getText(resp);\n\n// Strip accidental code fences if any\ntxt = String(txt)\n  .replace(/^```(?:json)?\\s*/i, \"\")\n  .replace(/```$/m, \"\");\n\n// Find fenced JSON\nconst m = txt.match(/<<JSON_START>>\\s*([\\s\\S]*?)\\s*<<JSON_END>>/);\nif (!m) {\n  throw new Error(\n    \"JSON markers not found. First 300 chars: \" + txt.slice(0, 300)\n  );\n}\n\n// Parse and clean control chars if necessary\nlet obj;\ntry {\n  obj = JSON.parse(m[1]);\n} catch {\n  const safe = m[1].replace(/[\\u0000-\\u001F\\u007F]/g, \"\");\n  obj = JSON.parse(safe);\n}\n\n// Minimal schema checks\nif (!Array.isArray(obj.scenarios)) {\n  throw new Error(\"Missing 'scenarios' array.\");\n}\nif (obj.scenarios.length !== 12) {\n  throw new Error(\n    `Expected 12 scenarios, got ${obj.scenarios.length}. Increase max_tokens or shorten scenario fields.`\n  );\n}\nif (!Array.isArray(obj.source_citations)) {\n  throw new Error(\"Missing 'source_citations' array (should be []).\");\n}\n\n// Merge parsed scenarios with original metadata\nconst output = {\n  ...obj,\n  ...originalMetadata,\n};\n\nconsole.log(\"=== PROMPT 31 PARSER OUTPUT ===\");\nconsole.log(\"Scenarios parsed:\", output.scenarios.length);\nconsole.log(\"Whitelist preserved:\", output.whitelist.length);\nconsole.log(\"Whitelist contents:\", output.whitelist);\nconsole.log(\"Business context:\", Object.keys(output.business_context || {}));\nconsole.log(\"Full output keys:\", Object.keys(output));\n\nreturn [{ json: output }];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1456, 32],
      "id": "8347e32a-5080-45c5-a8ab-955a2da68e93",
      "name": "009_parsePrompt31"
    },
    {
      "parameters": {
        "binaryPropertyName": "Company_CSV_File",
        "fileFormat": "csv",
        "options": {
          "delimiter": ",",
          "headerRow": true,
          "fromLine": 1
        }
      },
      "id": "read-csv-data",
      "name": "002_readCSVData",
      "type": "n8n-nodes-base.spreadsheetFile",
      "typeVersion": 2,
      "position": [-112, 32]
    },
    {
      "parameters": {
        "fieldToSplitOut": "scenarios",
        "options": {}
      },
      "type": "n8n-nodes-base.splitOut",
      "typeVersion": 1,
      "position": [1712, 32],
      "id": "edb66d5f-7e7e-4864-b50c-824b18e2362b",
      "name": "010_scenarioSplitOut"
    },
    {
      "parameters": {
        "amount": 1,
        "unit": "minutes"
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [1936, 32],
      "id": "3258a406-7feb-44a6-9a4b-9b7e57706768",
      "name": "Wait_01",
      "webhookId": "9e1cf28f-9d16-49f8-984d-b46cdd680ef3"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.anthropic.com/v1/messages",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "anthropicApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "anthropic-version",
              "value": " 2023-06-01"
            }
          ]
        },
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "model",
              "value": "claude-3-5-sonnet-20241022"
            },
            {
              "name": "max_tokens",
              "value": "={{ 4000 }}"
            },
            {
              "name": "temperature",
              "value": "={{ 0.2 }}"
            },
            {
              "name": "system",
              "value": "={{ $json.system_content }}"
            },
            {
              "name": "messages",
              "value": "={{ [{\"role\": \"user\", \"content\": $json.user_content}] }}"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [2352, 32],
      "id": "06891aad-65f1-4dd1-9b30-1c856ef81a44",
      "name": "011_prompt32Request-http",
      "retryOnFail": true,
      "credentials": {
        "anthropicApi": {
          "id": "1jk5Er35vKWwOaad",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "mode": "append",
        "options": {
          "keepOnlySet": false
        }
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [2560, 32],
      "id": "056ad305-df13-4b88-b1f8-f3feca4bc44f",
      "name": "Merge_01"
    },
    {
      "parameters": {
        "jsCode": "// === FORMAT PROMPT 32 with UPDATED ALLOWLIST LOGIC ===\n// Updated to allow all domains while maintaining explicit allowlist for reference\n\n// 1) Centralized allowlist of domains (maintained for explicit tracking and reference)\n// Expanded to include domains commonly found in competitive intelligence research\nconst EXPLICIT_ALLOWLIST = new Set([\n  // Original 27 domains (social media & basic web)\n  \"reddit.com\",\n  \"www.reddit.com\",\n  \"old.reddit.com\",\n  \"redditstatic.com\",\n  \"redditmedia.com\",\n  \"youtube.com\",\n  \"www.youtube.com\",\n  \"m.youtube.com\",\n  \"youtu.be\",\n  \"wikipedia.org\",\n  \"en.wikipedia.org\",\n  \"google.com\",\n  \"www.google.com\",\n  \"news.google.com\",\n  \"scholar.google.com\",\n  \"linkedin.com\",\n  \"www.linkedin.com\",\n  \"facebook.com\",\n  \"www.facebook.com\",\n  \"m.facebook.com\",\n  \"quora.com\",\n  \"www.quora.com\",\n  \"qoura.com\", // common misspelling\n  \"medium.com\",\n  \"www.medium.com\",\n  \"instagram.com\",\n  \"www.instagram.com\",\n\n  // Business & News Sources (from workflow prompts)\n  \"forbes.com\",\n  \"www.forbes.com\",\n  \"bloomberg.com\",\n  \"www.bloomberg.com\",\n  \"reuters.com\",\n  \"www.reuters.com\",\n  \"cnbc.com\",\n  \"www.cnbc.com\",\n  \"wsj.com\",\n  \"www.wsj.com\",\n  \"wsjonline.com\",\n  \"ft.com\",\n  \"www.ft.com\",\n  \"ft.com\",\n  \"businessinsider.com\",\n  \"www.businessinsider.com\",\n  \"techcrunch.com\",\n  \"www.techcrunch.com\",\n  \"venturebeat.com\",\n  \"www.venturebeat.com\",\n  \"hbr.org\",\n  \"www.hbr.org\", // Harvard Business Review\n\n  // Social Media & Community Platforms\n  \"twitter.com\",\n  \"www.twitter.com\",\n  \"x.com\",\n  \"www.x.com\",\n  \"tiktok.com\",\n  \"www.tiktok.com\",\n  \"snapchat.com\",\n  \"www.snapchat.com\",\n  \"discord.com\",\n  \"www.discord.com\",\n  \"pinterest.com\",\n  \"www.pinterest.com\",\n  \"tumblr.com\",\n  \"www.tumblr.com\",\n\n  // Professional & Academic Sources\n  \"glassdoor.com\",\n  \"www.glassdoor.com\",\n  \"indeed.com\",\n  \"www.indeed.com\",\n  \"crunchbase.com\",\n  \"www.crunchbase.com\",\n  \"pitchbook.com\",\n  \"www.pitchbook.com\",\n  \"mckinsey.com\",\n  \"www.mckinsey.com\",\n  \"bain.com\",\n  \"www.bain.com\",\n  \"bcg.com\",\n  \"www.bcg.com\",\n  \"deloitte.com\",\n  \"www.deloitte.com\",\n  \"pwc.com\",\n  \"www.pwc.com\",\n  \"kpmg.com\",\n  \"www.kpmg.com\",\n  \"accenture.com\",\n  \"www.accenture.com\",\n\n  // Financial & Market Data\n  \"sec.gov\",\n  \"www.sec.gov\",\n  \"nasdaq.com\",\n  \"www.nasdaq.com\",\n  \"nyse.com\",\n  \"www.nyse.com\",\n  \"yahoo.com\",\n  \"www.yahoo.com\",\n  \"finance.yahoo.com\",\n  \"marketwatch.com\",\n  \"www.marketwatch.com\",\n  \"investing.com\",\n  \"www.investing.com\",\n  \"morningstar.com\",\n  \"www.morningstar.com\",\n  \"zacks.com\",\n  \"www.zacks.com\",\n\n  // Research & Analytics\n  \"statista.com\",\n  \"www.statista.com\",\n  \"ibisworld.com\",\n  \"www.ibisworld.com\",\n  \"mintel.com\",\n  \"www.mintel.com\",\n  \"nielsen.com\",\n  \"www.nielsen.com\",\n  \"comscore.com\",\n  \"www.comscore.com\",\n  \"similarweb.com\",\n  \"www.similarweb.com\",\n  \"alexa.com\",\n  \"www.alexa.com\",\n\n  // Press Release & News Distribution\n  \"prnewswire.com\",\n  \"www.prnewswire.com\",\n  \"businesswire.com\",\n  \"www.businesswire.com\",\n  \"globenewswire.com\",\n  \"www.globenewswire.com\",\n  \"marketwired.com\",\n  \"www.marketwired.com\",\n\n  // NPS & Customer Satisfaction Scoring Sources\n  \"acsi.org\",\n  \"www.acsi.org\", // American Customer Satisfaction Index\n  \"npsbenchmarks.com\",\n  \"www.npsbenchmarks.com\", // NPS benchmarking data\n  \"temkin-group.com\",\n  \"www.temkin-group.com\", // Customer experience research\n  \"forrester.com\",\n  \"www.forrester.com\", // Customer experience research\n]);\n\n// 2) Helpers\nfunction safeJSONParse(maybeJSON) {\n  if (typeof maybeJSON !== \"string\") return null;\n  try {\n    return JSON.parse(maybeJSON);\n  } catch {\n    return null;\n  }\n}\n\nfunction extractDomain(url) {\n  try {\n    const u = new URL(url);\n    // Strip leading www., keep base host\n    return u.hostname.toLowerCase();\n  } catch {\n    return null;\n  }\n}\n\nfunction isAllowedURL(url) {\n  const host = extractDomain(url);\n  if (!host) return false;\n\n  // Check if this domain is explicitly in our allowlist for tracking purposes\n  const isExplicitlyAllowed = EXPLICIT_ALLOWLIST.has(host);\n  const isExplicitSubdomain = Array.from(EXPLICIT_ALLOWLIST).some(\n    (base) => host === base || host.endsWith(\".\" + base)\n  );\n\n  // Log explicit domains for tracking purposes\n  if (isExplicitlyAllowed || isExplicitSubdomain) {\n    console.log(`âœ… Explicitly allowed domain: ${host}`);\n  } else {\n    console.log(`âœ… Allowing domain (general allow): ${host}`);\n  }\n\n  // Return true for all valid domains - we now allow all domains\n  return true;\n}\n\nfunction dedupe(arr) {\n  return Array.from(new Set(arr));\n}\n\nfunction normalizeCitation(cit) {\n  // Ensure keys exist (don't mutate types)\n  const out = { ...cit };\n\n  // Normalize URL + domain + verification\n  if (out.source_url && typeof out.source_url === \"string\") {\n    // All domains are now allowed - no blocking logic needed\n    // Derive domain if missing\n    if (!out.source_domain) out.source_domain = extractDomain(out.source_url);\n    out.allowlist_violation = false;\n  } else {\n    // No URL provided\n    out.source_domain = out.source_domain || null;\n  }\n\n  // Guardrails for enums and basic ranges (soft-fix only if missing)\n  if (!out.confidence_level) out.confidence_level = \"medium\";\n  if (!out.verification_status) out.verification_status = \"unverified\";\n  if (typeof out.authority_score !== \"number\") out.authority_score = 5;\n  if (typeof out.claim_impact_score !== \"number\") out.claim_impact_score = 5;\n  if (typeof out.influence_weight !== \"number\") out.influence_weight = 0.5;\n  if (!out.source_origin) out.source_origin = \"unknown\";\n\n  return out;\n}\n\nfunction collectUrlsFromText(text) {\n  if (typeof text !== \"string\") return [];\n  // Simple URL regex for post-hoc auditing (not for normalization)\n  const re = /\\bhttps?:\\/\\/[^\\s)]+/g;\n  const matches = text.match(re) || [];\n  return dedupe(matches);\n}\n\n// 3) Main pipeline\nconst results = [];\n\n// Try to get company name from workflow execution context\nlet company = null;\ntry {\n  if (typeof $workflow !== \"undefined\" && $workflow.execution) {\n    const execution = $workflow.execution;\n    if (execution.data && execution.data.nodes) {\n      const parseGroupData = execution.data.nodes[\"003_parseGroupData\"];\n      if (\n        parseGroupData &&\n        parseGroupData.output &&\n        parseGroupData.output.company\n      ) {\n        company = parseGroupData.output.company;\n        console.log(\"Found company from workflow execution:\", company);\n      }\n    }\n  }\n} catch (e) {\n  console.log(\"Could not access workflow execution:\", e.message);\n}\n\nconsole.log(\n  \"=== FORMAT PROMPT 32 DEBUG (UPDATED ALLOWLIST - ALLOW ALL DOMAINS) ===\"\n);\nconsole.log(\"Input items:\", $input.all().length);\nconsole.log(\"Explicit allowlist size:\", EXPLICIT_ALLOWLIST.size);\nconsole.log(\"Company from workflow:\", company);\nconsole.log(\n  \"Note: All domains are now allowed, explicit allowlist maintained for reference\"\n);\n\nfor (let i = 0; i < $input.all().length; i++) {\n  const item = $input.all()[i];\n  console.log(`Processing item ${i}:`, Object.keys(item.json || {}));\n\n  let responseText = \"\";\n  let model = \"unknown\";\n  let tokens = 0;\n\n  // Per-scenario diagnostics\n  let allowed_urls = [];\n  let blocked_urls = [];\n\n  try {\n    // ---- Extract raw text payload (supports multiple shapes) ----\n    if (item.json?.content?.[0]?.text) {\n      // Claude-like\n      responseText = item.json.content[0].text;\n      model = item.json.model || \"claude\";\n      tokens = item.json.usage?.output_tokens || 0;\n    } else if (item.json?.response_text) {\n      // Pre-formatted\n      responseText = item.json.response_text;\n      model = item.json.model || \"claude\";\n      tokens = item.json.tokens_used || 0;\n    } else if (typeof item.json === \"string\") {\n      responseText = item.json;\n    } else {\n      // Fallback to JSON string\n      responseText = JSON.stringify(item.json || {});\n      console.log(\"Warning: Unexpected response structure for item\", i);\n    }\n\n    // ---- Try to parse model output as JSON so we can process citations ----\n    const parsed = safeJSONParse(responseText);\n    let processedJSON = null;\n\n    if (\n      parsed &&\n      parsed.source_citations &&\n      Array.isArray(parsed.source_citations)\n    ) {\n      // Process citations (all domains now allowed)\n      const normalizedCitations = parsed.source_citations.map((c) => {\n        const before = c?.source_url ? [c.source_url] : [];\n        const norm = normalizeCitation(c);\n        const after = norm?.source_url ? [norm.source_url] : [];\n\n        // Diagnostics - all URLs are now allowed\n        for (const u of before) {\n          if (isAllowedURL(u)) {\n            allowed_urls.push(u);\n          }\n        }\n        for (const u of after) {\n          if (u && isAllowedURL(u)) {\n            allowed_urls.push(u);\n          }\n        }\n        return norm;\n      });\n\n      processedJSON = {\n        ...parsed,\n        source_citations: normalizedCitations,\n      };\n\n      // Re-serialize for storage in response_text (so downstream stays consistent)\n      responseText = JSON.stringify(processedJSON);\n    } else {\n      // If not JSON/doesn't contain citations, audit URLs in the text\n      const urls = collectUrlsFromText(responseText);\n      for (const u of urls) {\n        if (isAllowedURL(u)) allowed_urls.push(u);\n      }\n    }\n\n    // Finalize diagnostics\n    allowed_urls = dedupe(allowed_urls);\n    blocked_urls = dedupe(blocked_urls);\n\n    results.push({\n      scenario_id: i + 1,\n      scenario_title: `Scenario ${i + 1}`,\n      response_text: responseText, // JSON string if parseable & processed; otherwise the original text\n      tokens_used: tokens,\n      model: model,\n      timestamp: new Date().toISOString(),\n      allowlist_audit: {\n        allowed_urls,\n        blocked_urls,\n        explicit_allowlist_size: EXPLICIT_ALLOWLIST.size,\n        policy: \"allow_all_domains\",\n      },\n    });\n  } catch (error) {\n    console.error(`Error processing item ${i}:`, error.message);\n    results.push({\n      scenario_id: i + 1,\n      scenario_title: `Scenario ${i + 1}`,\n      response_text: `Error processing response: ${error.message}`,\n      tokens_used: 0,\n      model: \"error\",\n      timestamp: new Date().toISOString(),\n      allowlist_audit: {\n        allowed_urls: [],\n        blocked_urls: [],\n        explicit_allowlist_size: EXPLICIT_ALLOWLIST.size,\n        policy: \"allow_all_domains\",\n      },\n    });\n  }\n}\n\nconsole.log(\"Results created:\", results.length);\nconsole.log(\"Policy: All domains are now allowed\");\nconsole.log(\"Explicit allowlist maintained for reference and tracking\");\n\nreturn [\n  {\n    json: {\n      scenarios_completed: results.length,\n      results,\n      ...(company ? { company } : {}),\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [2736, 32],
      "id": "56d80416-411a-4866-b0f6-1519ff65acb7",
      "name": "012_formatPrompt32"
    },
    {
      "parameters": {
        "jsCode": "// Prompt 32 Formatter - Convert Format Prompt 32 output to merge-compatible format\n// Input: { scenarios_completed: 12, results: [...] }\n// Output: Structured data compatible with Collect All Data merge\n\nconst input = $input.first()?.json || {};\n\nconsole.log(\"=== PROMPT 32 FORMATTER DEBUG ===\");\nconsole.log(\"Input keys:\", Object.keys(input));\nconsole.log(\"Scenarios completed:\", input.scenarios_completed);\nconsole.log(\"Results length:\", input.results?.length || 0);\n\n// Debug the first few results to see their structure\nif (input.results && input.results.length > 0) {\n  console.log(\"\\n=== SAMPLE RESULTS DEBUG ===\");\n  input.results.slice(0, 3).forEach((result, index) => {\n    console.log(`\\nResult ${index + 1}:`);\n    console.log(\"Keys:\", Object.keys(result));\n    console.log(\"Scenario ID:\", result.scenario_id);\n    console.log(\"Scenario Title:\", result.scenario_title);\n    console.log(\"Response text length:\", result.response_text?.length || 0);\n    console.log(\n      \"Response text preview:\",\n      result.response_text?.substring(0, 300) || \"No response text\"\n    );\n  });\n}\n\n// Extract scenarios from the results\nconst scenarios = input.results || [];\n\n// Function to extract JSON from response_text with aggressive cleaning\nfunction extractJsonFromResponse(responseText, scenarioId) {\n  if (!responseText) {\n    console.log(`âŒ No response text for scenario ${scenarioId}`);\n    return null;\n  }\n\n  let jsonString = null;\n\n  // First, try to extract JSON block\n  const jsonBlockMatch = responseText.match(/```json\\s*([\\s\\S]*?)```/);\n  if (jsonBlockMatch) {\n    jsonString = jsonBlockMatch[1].trim();\n  } else {\n    // Fallback to finding JSON by braces\n    const startIndex = responseText.indexOf(\"{\");\n    if (startIndex !== -1) {\n      let braceCount = 0;\n      let endIndex = startIndex;\n\n      for (let i = startIndex; i < responseText.length; i++) {\n        if (responseText[i] === \"{\") {\n          braceCount++;\n        } else if (responseText[i] === \"}\") {\n          braceCount--;\n          if (braceCount === 0) {\n            endIndex = i;\n            break;\n          }\n        }\n      }\n\n      if (braceCount === 0) {\n        jsonString = responseText.substring(startIndex, endIndex + 1);\n      }\n    }\n  }\n\n  if (!jsonString) {\n    console.log(`âŒ No JSON found in response text for scenario ${scenarioId}`);\n    return null;\n  }\n\n  console.log(\n    `ðŸ“‹ Original JSON length for scenario ${scenarioId}:`,\n    jsonString.length\n  );\n\n  // Debug: Check if the JSON contains more competitors than we're extracting\n  const competitorsMatch = jsonString.match(\n    /\"competitors_ranked\":\\s*\\[([\\s\\S]*?)\\]/\n  );\n  if (competitorsMatch) {\n    const competitorsContent = competitorsMatch[1];\n\n    // Count competitors using proper brace matching\n    let competitorCount = 0;\n    let currentPos = 0;\n\n    while (currentPos < competitorsContent.length) {\n      const openBracePos = competitorsContent.indexOf(\"{\", currentPos);\n      if (openBracePos === -1) break;\n\n      let braceCount = 0;\n      let endPos = openBracePos;\n\n      for (let i = openBracePos; i < competitorsContent.length; i++) {\n        if (competitorsContent[i] === \"{\") {\n          braceCount++;\n        } else if (competitorsContent[i] === \"}\") {\n          braceCount--;\n          if (braceCount === 0) {\n            endPos = i;\n            break;\n          }\n        }\n      }\n\n      if (braceCount === 0) {\n        competitorCount++;\n        currentPos = endPos + 1;\n      } else {\n        currentPos = openBracePos + 1;\n      }\n    }\n\n    console.log(`  Found ${competitorCount} competitor objects in raw JSON`);\n\n    if (competitorCount > 4) {\n      console.log(\n        `  âš ï¸  WARNING: JSON contains ${competitorCount} competitors but we might only be extracting 4`\n      );\n      console.log(\n        `  Raw competitors content preview: ${competitorsContent.substring(\n          0,\n          200\n        )}...`\n      );\n    }\n  }\n\n  // Apply aggressive cleaning specifically targeting the malformed patterns\n  let cleaned = jsonString;\n\n  try {\n    // Target the specific issues in the sources array\n    cleaned = cleaned.replace(\n      /\"sources\":\\s*\\[([\\s\\S]*?)\\]/g,\n      (match, sourcesContent) => {\n        // Clean the sources array content aggressively\n        let cleanedSources = sourcesContent\n          // Fix the specific malformed pattern: \"url\"\\,\" -> \"url\",\n          .replace(/\"([^\"]*?)\"\\s*\\\\\\s*,\\s*\"/g, '\"$1\",\\n    \"')\n          // Fix pattern at end of array: \"url\"\\, -> \"url\"\n          .replace(/\"([^\"]*?)\"\\s*\\\\\\s*,?\\s*$/gm, '\"$1\"')\n          // Remove any remaining backslashes before quotes\n          .replace(/\\\\\\s*\"/g, '\"')\n          // Remove standalone backslashes\n          .replace(/\\\\\\s*,/g, \",\")\n          // Clean up any remaining backslashes\n          .replace(/\\\\+/g, \"\")\n          // Fix double commas\n          .replace(/,\\s*,/g, \",\")\n          // Remove trailing commas\n          .replace(/,\\s*$/, \"\")\n          // Normalize spacing\n          .replace(/\"\\s*,\\s*\"/g, '\",\\n    \"')\n          // Clean up the beginning and end\n          .replace(/^\\s*,/, \"\") // Remove leading comma\n          .replace(/,\\s*$/, \"\") // Remove trailing comma\n          .trim();\n\n        return `\"sources\": [\\n    ${cleanedSources}\\n  ]`;\n      }\n    );\n\n    // General cleaning\n    cleaned = cleaned\n      .replace(/\\\\+/g, \"\") // Remove all backslashes\n      .replace(/,\\s*,/g, \",\") // Fix double commas\n      .replace(/,(\\s*[}\\]])/g, \"$1\") // Remove trailing commas before closing\n      .trim();\n\n    console.log(\n      `ðŸ§¹ Cleaned JSON length for scenario ${scenarioId}:`,\n      cleaned.length\n    );\n\n    // Try to parse the cleaned JSON\n    const parsed = JSON.parse(cleaned);\n    console.log(`âœ… Successfully parsed JSON for scenario ${scenarioId}`);\n    return parsed;\n  } catch (error) {\n    console.log(\n      `âŒ JSON parsing failed for scenario ${scenarioId}:`,\n      error.message\n    );\n\n    // For scenarios 1 and 5, try direct string extraction instead of JSON parsing\n    if (scenarioId === 1 || scenarioId === 5) {\n      console.log(\n        \"ðŸ”§ Attempting direct string extraction for scenario\",\n        scenarioId\n      );\n\n      try {\n        // Extract data directly from the original response text using string methods\n        const responseText = jsonString;\n\n        // Extract title\n        const titleMatch = responseText.match(/\"title\":\\s*\"([^\"]+)\"/);\n        const title = titleMatch ? titleMatch[1] : null;\n\n        // Extract description\n        const descMatch = responseText.match(\n          /\"description\":\\s*\"([^\"]+(?:\\\\.[^\"]*)*?)\"/\n        );\n        const description = descMatch\n          ? descMatch[1].replace(/\\\\\"/g, '\"')\n          : null;\n\n        // Extract competitors_ranked array\n        const competitorsMatch = responseText.match(\n          /\"competitors_ranked\":\\s*\\[([\\s\\S]*?)\\]/\n        );\n        const competitors = [];\n        if (competitorsMatch) {\n          // Extract each competitor object using proper brace matching\n          const competitorsContent = competitorsMatch[1];\n          let currentPos = 0;\n\n          while (currentPos < competitorsContent.length) {\n            // Find the next opening brace\n            const openBracePos = competitorsContent.indexOf(\"{\", currentPos);\n            if (openBracePos === -1) break;\n\n            // Count braces to find the complete object\n            let braceCount = 0;\n            let endPos = openBracePos;\n\n            for (let i = openBracePos; i < competitorsContent.length; i++) {\n              if (competitorsContent[i] === \"{\") {\n                braceCount++;\n              } else if (competitorsContent[i] === \"}\") {\n                braceCount--;\n                if (braceCount === 0) {\n                  endPos = i;\n                  break;\n                }\n              }\n            }\n\n            if (braceCount === 0) {\n              const compObj = competitorsContent.substring(\n                openBracePos,\n                endPos + 1\n              );\n\n              const companyMatch = compObj.match(/\"company\":\\s*\"([^\"]+)\"/);\n              const scoreMatch = compObj.match(/\"score\":\\s*([0-9.]+)/);\n              const rationaleMatch = compObj.match(\n                /\"rationale\":\\s*\"([^\"]+(?:\\\\.[^\"]*)*?)\"/\n              );\n\n              if (companyMatch && scoreMatch && rationaleMatch) {\n                competitors.push({\n                  company: companyMatch[1],\n                  score: parseFloat(scoreMatch[1]),\n                  rationale: rationaleMatch[1].replace(/\\\\\"/g, '\"'),\n                });\n              }\n\n              currentPos = endPos + 1;\n            } else {\n              // If we couldn't find matching braces, skip this object\n              currentPos = openBracePos + 1;\n            }\n          }\n        }\n\n        // Extract analysis_details\n        const analysisMatch = responseText.match(\n          /\"analysis_details\":\\s*\\{([\\s\\S]*?)\\}(?:\\s*,\\s*\"key_findings\")/\n        );\n        const analysisDetails = {};\n        if (analysisMatch) {\n          // Extract each company analysis\n          const companyAnalyses =\n            analysisMatch[1].match(\n              /\"[^\"]+\"\\s*:\\s*\\{[^}]+(?:\\{[^}]*\\}[^}]*)*\\}/g\n            ) || [];\n          for (const analysis of companyAnalyses) {\n            const companyNameMatch = analysis.match(/^\"([^\"]+)\":/);\n            if (companyNameMatch) {\n              const companyName = companyNameMatch[1];\n\n              // Extract summary\n              const summaryMatch = analysis.match(\n                /\"summary\":\\s*\"([^\"]+(?:\\\\.[^\"]*)*?)\"/\n              );\n\n              // Extract highlights array\n              const highlightsMatch = analysis.match(\n                /\"highlights\":\\s*\\[([\\s\\S]*?)\\]/\n              );\n              const highlights = [];\n              if (highlightsMatch) {\n                const highlightMatches =\n                  highlightsMatch[1].match(/\"([^\"]+(?:\\\\.[^\"]*)*?)\"/g) || [];\n                highlights.push(\n                  ...highlightMatches.map((h) =>\n                    h.slice(1, -1).replace(/\\\\\"/g, '\"')\n                  )\n                );\n              }\n\n              analysisDetails[companyName] = {\n                summary: summaryMatch\n                  ? summaryMatch[1].replace(/\\\\\"/g, '\"')\n                  : \"\",\n                highlights: highlights,\n                metrics: {}, // We could extract this too if needed\n              };\n            }\n          }\n        }\n\n        // Extract key_findings array\n        const findingsMatch = responseText.match(\n          /\"key_findings\":\\s*\\[([\\s\\S]*?)\\]/\n        );\n        const keyFindings = [];\n        if (findingsMatch) {\n          const findingMatches =\n            findingsMatch[1].match(/\"([^\"]+(?:\\\\.[^\"]*)*?)\"/g) || [];\n          keyFindings.push(\n            ...findingMatches.map((f) => f.slice(1, -1).replace(/\\\\\"/g, '\"'))\n          );\n        }\n\n        console.log(`âœ… Direct extraction for scenario ${scenarioId}:`);\n        console.log(`  Title: ${title}`);\n        console.log(`  Competitors: ${competitors.length}`);\n        console.log(\n          `  Analysis companies: ${Object.keys(analysisDetails).length}`\n        );\n        console.log(`  Key findings: ${keyFindings.length}`);\n\n        return {\n          title: title,\n          description: description,\n          competitors_ranked: competitors,\n          analysis_details: analysisDetails,\n          key_findings: keyFindings,\n        };\n      } catch (extractError) {\n        console.log(\n          `âŒ Direct extraction also failed for scenario ${scenarioId}:`,\n          extractError.message\n        );\n      }\n    }\n\n    return null;\n  }\n}\n\n// Process each scenario to extract structured data\nconst processedScenarios = [];\nconst allSources = [];\nconst allCitations = [];\n\nfor (const scenario of scenarios) {\n  console.log(`\\nðŸ” Processing scenario ${scenario.scenario_id}:`);\n  console.log(`Response text length: ${scenario.response_text?.length || 0}`);\n  console.log(\n    `Response text preview (first 200 chars): ${\n      scenario.response_text?.substring(0, 200) || \"No response text\"\n    }`\n  );\n\n  try {\n    // Extract JSON from response text\n    const parsedResponse = extractJsonFromResponse(\n      scenario.response_text,\n      scenario.scenario_id\n    );\n\n    // Helper function to detect dimension from title/description\n    function detectDimension(title, description) {\n      const text = `${title || \"\"} ${description || \"\"}`.toLowerCase();\n\n      if (text.includes(\"concierge\") || text.includes(\"service quality\")) {\n        return \"concierge_services\";\n      } else if (text.includes(\"luxury\") || text.includes(\"premium\")) {\n        return \"luxury_hospitality\";\n      } else if (text.includes(\"hotel\") || text.includes(\"resort\")) {\n        return \"hospitality\";\n      } else if (text.includes(\"suite\") || text.includes(\"accommodation\")) {\n        return \"accommodation_services\";\n      } else if (text.includes(\"dining\") || text.includes(\"restaurant\")) {\n        return \"dining_services\";\n      } else if (text.includes(\"entertainment\") || text.includes(\"casino\")) {\n        return \"entertainment_services\";\n      }\n      return \"hospitality_services\"; // Default fallback\n    }\n\n    // Helper function to extract meaningful user query\n    function extractUserQuery(parsedResponse, scenarioTitle) {\n      if (\n        parsedResponse?.user_query &&\n        parsedResponse.user_query !== scenarioTitle &&\n        !parsedResponse.user_query.startsWith(\"Scenario \")\n      ) {\n        return parsedResponse.user_query;\n      }\n\n      // Extract meaningful query from title\n      if (scenarioTitle && !scenarioTitle.startsWith(\"Scenario \")) {\n        return `Analyze ${scenarioTitle.toLowerCase()}`;\n      }\n\n      // If we have a parsed response with a good title, use that\n      if (\n        parsedResponse?.title &&\n        !parsedResponse.title.startsWith(\"Scenario \")\n      ) {\n        return `Analyze ${parsedResponse.title.toLowerCase()}`;\n      }\n\n      return scenarioTitle || `Scenario ${scenario.scenario_id}`;\n    }\n\n    // Create scenario data with enhanced field extraction\n    const scenarioData = {\n      scenario_id: scenario.scenario_id,\n      scenario_title:\n        parsedResponse?.title ||\n        scenario.scenario_title ||\n        `Scenario ${scenario.scenario_id}`,\n      scenario_description: parsedResponse?.description || \"\",\n      dimension:\n        parsedResponse?.dimension ||\n        detectDimension(parsedResponse?.title, parsedResponse?.description),\n      user_query: extractUserQuery(parsedResponse, scenario.scenario_title),\n      competitors_ranked: parsedResponse?.competitors_ranked || [],\n      analysis_details: parsedResponse?.analysis_details || {},\n      key_findings: parsedResponse?.key_findings || [],\n      sources: parsedResponse?.sources || [], // Extract sources to top level\n      response_text: scenario.response_text,\n      model: scenario.model,\n      tokens_used: scenario.tokens_used,\n      timestamp: scenario.timestamp,\n    };\n\n    // Data validation and quality checks\n    const validationResults = {\n      hasTitle: !!(\n        scenarioData.scenario_title &&\n        scenarioData.scenario_title !== `Scenario ${scenario.scenario_id}`\n      ),\n      hasDescription: !!(\n        scenarioData.scenario_description &&\n        scenarioData.scenario_description.length > 10\n      ),\n      hasCompetitors: !!(\n        scenarioData.competitors_ranked &&\n        scenarioData.competitors_ranked.length > 0\n      ),\n      hasAnalysis: !!(\n        scenarioData.analysis_details &&\n        Object.keys(scenarioData.analysis_details).length > 0\n      ),\n      hasKeyFindings: !!(\n        scenarioData.key_findings && scenarioData.key_findings.length > 0\n      ),\n      hasSources: !!(scenarioData.sources && scenarioData.sources.length > 0),\n      validDimension: scenarioData.dimension !== \"unknown\",\n      validUserQuery: !!(\n        scenarioData.user_query &&\n        !scenarioData.user_query.startsWith(\"Scenario \")\n      ),\n    };\n\n    // Calculate data quality score\n    const qualityScore =\n      Object.values(validationResults).filter(Boolean).length /\n      Object.keys(validationResults).length;\n    scenarioData.data_quality_score = Math.round(qualityScore * 100);\n    scenarioData.validation_results = validationResults;\n\n    console.log(`ðŸ“Š Scenario ${scenario.scenario_id} results:`);\n    console.log(`  Title: ${scenarioData.scenario_title}`);\n    console.log(`  Dimension: ${scenarioData.dimension}`);\n    console.log(`  User Query: ${scenarioData.user_query}`);\n    console.log(`  Data Quality Score: ${scenarioData.data_quality_score}%`);\n    console.log(\n      `  Description length: ${scenarioData.scenario_description?.length || 0}`\n    );\n    console.log(\n      `  Competitors: ${scenarioData.competitors_ranked?.length || 0}`\n    );\n    console.log(\n      `  Analysis companies: ${\n        Object.keys(scenarioData.analysis_details || {}).length\n      }`\n    );\n    console.log(`  Key findings: ${scenarioData.key_findings?.length || 0}`);\n    console.log(`  Sources: ${scenarioData.sources?.length || 0}`);\n\n    // Debug competitor details\n    if (\n      scenarioData.competitors_ranked &&\n      scenarioData.competitors_ranked.length > 0\n    ) {\n      console.log(`  Competitor details:`);\n      scenarioData.competitors_ranked.forEach((comp, idx) => {\n        console.log(\n          `    ${idx + 1}. ${comp.company}: ${comp.score || \"N/A\"} - ${\n            comp.rationale?.substring(0, 50) || \"No rationale\"\n          }...`\n        );\n      });\n    }\n\n    // Debug analysis details\n    if (\n      scenarioData.analysis_details &&\n      Object.keys(scenarioData.analysis_details).length > 0\n    ) {\n      console.log(`  Analysis details companies:`);\n      Object.keys(scenarioData.analysis_details).forEach((company, idx) => {\n        const details = scenarioData.analysis_details[company];\n        console.log(\n          `    ${idx + 1}. ${company}: ${\n            details.summary?.substring(0, 50) || \"No summary\"\n          }...`\n        );\n      });\n    }\n\n    // Debug: Check if we're missing competitors in the JSON but they exist in the response text\n    if (\n      scenarioData.competitors_ranked &&\n      scenarioData.competitors_ranked.length > 0\n    ) {\n      console.log(\n        `ðŸ” Checking if more competitors exist in response text for scenario ${scenario.scenario_id}...`\n      );\n      const responseText = scenario.response_text || \"\";\n\n      // Look for patterns that might indicate more competitors\n      const companyMentions =\n        responseText.match(\n          /[A-Z][a-zA-Z\\s&]+(?:Resort|Hotel|Casino|Las Vegas|Vegas)/g\n        ) || [];\n      const uniqueCompanies = [...new Set(companyMentions)];\n\n      console.log(\n        `  Found ${uniqueCompanies.length} potential company mentions in response text:`\n      );\n      uniqueCompanies.slice(0, 10).forEach((company, idx) => {\n        console.log(`    ${idx + 1}. ${company}`);\n      });\n\n      if (uniqueCompanies.length > scenarioData.competitors_ranked.length) {\n        console.log(\n          `  âš ï¸  WARNING: Found ${uniqueCompanies.length} potential companies but only ${scenarioData.competitors_ranked.length} in competitors_ranked`\n        );\n        console.log(\n          `  This suggests the JSON extraction might be incomplete or the LLM response is truncated`\n        );\n      }\n    }\n\n    // If no competitors found, try to extract from the raw response text using regex\n    if (\n      !scenarioData.competitors_ranked ||\n      scenarioData.competitors_ranked.length === 0\n    ) {\n      console.log(\n        `ðŸ”§ No competitors found for scenario ${scenario.scenario_id}, trying regex extraction...`\n      );\n\n      // Try to extract company names and scores from the response text\n      const responseText = scenario.response_text || \"\";\n\n      // Look for patterns like \"Company Name: Score\" or \"1. Company Name (Score)\"\n      const companyPatterns = [\n        /(\\d+\\.?\\s*)([A-Z][a-zA-Z\\s&]+?)\\s*[:\\-\\(]?\\s*(\\d+(?:\\.\\d+)?)/g,\n        /([A-Z][a-zA-Z\\s&]+?)\\s*[:\\-\\(]?\\s*(\\d+(?:\\.\\d+)?)/g,\n        /\"company\":\\s*\"([^\"]+)\"/g,\n        /\"score\":\\s*(\\d+(?:\\.\\d+)?)/g,\n      ];\n\n      const extractedCompanies = [];\n      const extractedScores = [];\n\n      companyPatterns.forEach((pattern, index) => {\n        const matches = [...responseText.matchAll(pattern)];\n        matches.forEach((match) => {\n          if (index === 0 || index === 1) {\n            // Pattern that captures both company and score\n            if (match[2] && match[3]) {\n              extractedCompanies.push({\n                company: match[2].trim(),\n                score: parseFloat(match[3]),\n                rank: extractedCompanies.length + 1,\n              });\n            }\n          } else if (index === 2) {\n            // Company name pattern\n            extractedCompanies.push({\n              company: match[1],\n              score: null,\n              rank: extractedCompanies.length + 1,\n            });\n          } else if (index === 3) {\n            // Score pattern\n            extractedScores.push(parseFloat(match[1]));\n          }\n        });\n      });\n\n      // If we found companies but no scores, try to match them\n      if (extractedCompanies.length > 0) {\n        extractedCompanies.forEach((comp, index) => {\n          if (!comp.score && extractedScores[index]) {\n            comp.score = extractedScores[index];\n          }\n        });\n\n        // Sort by score if available\n        extractedCompanies.sort((a, b) => (b.score || 0) - (a.score || 0));\n\n        // Update ranks\n        extractedCompanies.forEach((comp, index) => {\n          comp.rank = index + 1;\n        });\n\n        scenarioData.competitors_ranked = extractedCompanies;\n        console.log(\n          `âœ… Extracted ${extractedCompanies.length} competitors using regex`\n        );\n      }\n    }\n\n    // Add processing status\n    scenarioData.processing_status = \"success\";\n    processedScenarios.push(scenarioData);\n\n    // Extract sources and citations if available\n    if (parsedResponse?.sources) {\n      const sources = Array.isArray(parsedResponse.sources)\n        ? parsedResponse.sources\n        : [];\n      allSources.push(...sources);\n      console.log(`  Sources found: ${sources.length}`);\n    }\n\n    if (parsedResponse?.citations) {\n      const citations = Array.isArray(parsedResponse.citations)\n        ? parsedResponse.citations\n        : [];\n      allCitations.push(...citations);\n    }\n  } catch (error) {\n    console.error(\n      `âŒ Error processing scenario ${scenario.scenario_id}:`,\n      error.message\n    );\n\n    // Create enhanced fallback scenario data with better defaults\n    const fallbackData = {\n      scenario_id: scenario.scenario_id,\n      scenario_title:\n        scenario.scenario_title || `Scenario ${scenario.scenario_id}`,\n      scenario_description: \"\",\n      dimension: \"hospitality_services\", // Better default than \"unknown\"\n      user_query:\n        scenario.scenario_title || `Analyze scenario ${scenario.scenario_id}`,\n      competitors_ranked: [],\n      analysis_details: {},\n      key_findings: [],\n      sources: [],\n      response_text: scenario.response_text,\n      model: scenario.model,\n      tokens_used: scenario.tokens_used,\n      timestamp: scenario.timestamp,\n      error: error.message,\n      data_quality_score: 0,\n      validation_results: {\n        hasTitle: false,\n        hasDescription: false,\n        hasCompetitors: false,\n        hasAnalysis: false,\n        hasKeyFindings: false,\n        hasSources: false,\n        validDimension: false,\n        validUserQuery: false,\n      },\n      processing_status: \"error\",\n    };\n\n    processedScenarios.push(fallbackData);\n  }\n}\n\n// Create enhanced summary statistics\nconst summaryStats = {\n  total_scenarios: processedScenarios.length,\n  scenarios_with_rankings: processedScenarios.filter(\n    (s) => s.competitors_ranked?.length > 0\n  ).length,\n  scenarios_with_analysis: processedScenarios.filter(\n    (s) => Object.keys(s.analysis_details || {}).length > 0\n  ).length,\n  scenarios_with_titles: processedScenarios.filter(\n    (s) => s.scenario_title && !s.scenario_title.startsWith(\"Scenario \")\n  ).length,\n  scenarios_with_descriptions: processedScenarios.filter(\n    (s) => s.scenario_description && s.scenario_description.length > 0\n  ).length,\n  scenarios_with_sources: processedScenarios.filter(\n    (s) => s.sources && s.sources.length > 0\n  ).length,\n  successful_scenarios: processedScenarios.filter(\n    (s) => s.processing_status === \"success\"\n  ).length,\n  error_scenarios: processedScenarios.filter(\n    (s) => s.processing_status === \"error\"\n  ).length,\n  average_quality_score: Math.round(\n    processedScenarios.reduce(\n      (sum, s) => sum + (s.data_quality_score || 0),\n      0\n    ) / processedScenarios.length\n  ),\n  high_quality_scenarios: processedScenarios.filter(\n    (s) => (s.data_quality_score || 0) >= 80\n  ).length,\n  total_sources: allSources.length,\n  total_citations: allCitations.length,\n  processing_timestamp: new Date().toISOString(),\n};\n\nconsole.log(\"\\n=== PROCESSING COMPLETE ===\");\nconsole.log(\"âœ… Processed scenarios:\", processedScenarios.length);\nconsole.log(\"âœ… Successful scenarios:\", summaryStats.successful_scenarios);\nconsole.log(\"âŒ Error scenarios:\", summaryStats.error_scenarios);\nconsole.log(\n  \"ðŸ“Š Average quality score:\",\n  summaryStats.average_quality_score + \"%\"\n);\nconsole.log(\n  \"â­ High quality scenarios (â‰¥80%):\",\n  summaryStats.high_quality_scenarios\n);\nconsole.log(\n  \"âœ… Scenarios with proper titles:\",\n  summaryStats.scenarios_with_titles\n);\nconsole.log(\n  \"âœ… Scenarios with descriptions:\",\n  summaryStats.scenarios_with_descriptions\n);\nconsole.log(\n  \"âœ… Scenarios with rankings:\",\n  summaryStats.scenarios_with_rankings\n);\nconsole.log(\n  \"âœ… Scenarios with analysis:\",\n  summaryStats.scenarios_with_analysis\n);\nconsole.log(\"âœ… Scenarios with sources:\", summaryStats.scenarios_with_sources);\nconsole.log(\"âœ… Sources found:\", allSources.length);\n\n// Log detailed parsing results with quality scores\nconsole.log(\"\\n=== DETAILED PARSING RESULTS ===\");\nprocessedScenarios.forEach((scenario) => {\n  const hasData =\n    scenario.competitors_ranked?.length > 0 ||\n    Object.keys(scenario.analysis_details || {}).length > 0;\n  const status =\n    scenario.processing_status === \"success\" ? \"âœ… SUCCESS\" : \"âŒ ERROR\";\n  const qualityScore = scenario.data_quality_score || 0;\n  const qualityIcon =\n    qualityScore >= 80 ? \"â­\" : qualityScore >= 60 ? \"ðŸ“Š\" : \"âš ï¸\";\n\n  console.log(\n    `${status} ${qualityIcon} - Scenario ${scenario.scenario_id}: ${scenario.scenario_title} (Quality: ${qualityScore}%)`\n  );\n});\n\n// Return structured data compatible with Collect All Data merge\nreturn [\n  {\n    json: {\n      // Scenario data\n      scenario_rankings: processedScenarios,\n      scenarios: processedScenarios, // Alternative key for compatibility\n\n      // Sources and citations (if any were found)\n      data_sources: allSources,\n      source_citations: allCitations,\n\n      // Summary statistics\n      summary_stats: summaryStats,\n\n      // Metadata\n      company: input.company || \"Report\",\n      processing_type: \"prompt_32_formatter\",\n\n      // Original data for debugging\n      original_scenarios_completed: input.scenarios_completed,\n      original_results_count: input.results?.length || 0,\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [3008, -176],
      "id": "bb06bfdb-3007-49f5-92a1-2d572badf124",
      "name": "013_prompt32Formatter"
    },
    {
      "parameters": {
        "fieldToSplitOut": "results",
        "options": {}
      },
      "type": "n8n-nodes-base.splitOut",
      "typeVersion": 1,
      "position": [3008, 32],
      "id": "12da59f4-e375-4573-8f13-23dd566e69f2",
      "name": "014a_citationScenarioSplitOut"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.anthropic.com/v1/messages",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "anthropicApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "anthropic-version",
              "value": " 2023-06-01"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ {\n  model: \"claude-3-7-sonnet-20250219\",\n  max_tokens: 7500,\n  temperature: 0.1,\n  system: \"You are an advanced competitive intelligence extraction specialist. Analyze the provided competitive analysis data and extract actionable insights with comprehensive source attribution. Focus on specific, strategic claims rather than general facts. Return ONLY valid JSON in the exact format specified.\",\n  messages: [\n    {\n      role: \"user\",\n      content: [\n        {\n          type: \"text\",\n          text:\n            \"EXTRACT COMPETITIVE INTELLIGENCE CITATIONS\\n\\n\" +\n            \"Analyze this competitive analysis data and extract specific, actionable claims with detailed source attribution. Prioritize strategic insights over general facts.\\n\\n\" +\n            \"=== COMPETITIVE ANALYSIS DATA ===\\n\" +\n            JSON.stringify($json, null, 2) +\n            \"\\n\\n=== EXTRACTION FORMAT ===\\n\" +\n            \"{\\n  \\\"source_citations\\\": [\\n    {\\n      \\\"claim_text\\\": \\\"Specific, actionable competitive claim\\\",\\n      \\\"claim_category\\\": \\\"competitive_analysis\\\",\\n      \\\"claim_impact_score\\\": 7,\\n      \\\"source_type\\\": \\\"web_research|training_data|company_report|news_article\\\",\\n      \\\"source_url\\\": \\\"https://actual-source-url.com\\\",\\n      \\\"source_domain\\\": \\\"domain.com\\\",\\n      \\\"publication_date\\\": \\\"2025-01-15\\\",\\n      \\\"author\\\": \\\"Actual Author Name or Organization\\\",\\n      \\\"author_credibility_score\\\": 8,\\n      \\\"source_origin\\\": \\\"web_research|training_data|company_filing\\\",\\n      \\\"training_data_cutoff\\\": \\\"2025-01\\\",\\n      \\\"authority_score\\\": 8,\\n      \\\"verification_status\\\": \\\"verified|unverified|conflicting\\\",\\n      \\\"content_type\\\": \\\"competitive_research|earnings_call|press_release|analyst_report\\\",\\n      \\\"bias_indicators\\\": \\\"low|medium|high\\\",\\n      \\\"cross_references\\\": 2,\\n      \\\"confidence_level\\\": \\\"high|medium|low\\\",\\n      \\\"supporting_evidence\\\": \\\"Specific data points or context\\\",\\n      \\\"real_time_indicators\\\": [\\\"recent_announcement\\\", \\\"market_movement\\\"],\\n      \\\"brand_mention_type\\\": \\\"direct_comparison|market_positioning|strategic_move\\\",\\n      \\\"sentiment_direction\\\": \\\"positive|negative|neutral\\\",\\n      \\\"influence_weight\\\": 0.8,\\n      \\\"strategic_relevance\\\": \\\"market_share|pricing|product_launch|expansion\\\",\\n      \\\"actionability_score\\\": 8,\\n      \\\"geographic_scope\\\": \\\"global|regional|local\\\",\\n      \\\"time_sensitivity\\\": \\\"immediate|quarterly|annual\\\",\\n      \\\"tags\\\": [\\\"competitive_analysis\\\", \\\"specific_industry\\\", \\\"strategic_theme\\\"]\\n    }\\n  ],\\n  \\\"extraction_metadata\\\": {\\n    \\\"total_claims_found\\\": 15,\\n    \\\"high_impact_claims\\\": 8,\\n    \\\"source_diversity_score\\\": 7,\\n    \\\"recency_score\\\": 6,\\n    \\\"deduplication_applied\\\": true,\\n    \\\"extraction_timestamp\\\": \\\"\" +\n            new Date().toISOString() +\n            \"\\\"\\n  }\\n}\\n\\n\" +\n            \"ENHANCED REQUIREMENTS:\\n\" +\n            \"1. Extract insights from the provided competitive analysis data above\\n\" +\n            \"2. Use actual sources from the data when available (Forbes, TripAdvisor, etc.)\\n\" +\n            \"3. Focus on strategic moves, market positioning, and competitive advantages\\n\" +\n            \"4. Include geographic and time sensitivity context\\n\" +\n            \"5. Add actionability scoring (1-10) for strategic relevance\\n\" +\n            \"6. Apply deduplication logic\\n\" +\n            \"7. Return extraction metadata for quality assessment\\n\" +\n            \"8. Minimum 10 citations, maximum 25 to maintain quality\\n\" +\n            \"9. Base all claims on the actual competitive data provided\"\n        }\n      ]\n    }\n  ]\n} }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [3664, 32],
      "id": "20b66c95-f888-47d8-92d6-c47315aa494c",
      "name": "014b_prompt32CitationRequest-http",
      "retryOnFail": true,
      "maxTries": 5,
      "waitBetweenTries": 5000,
      "credentials": {
        "anthropicApi": {
          "id": "1jk5Er35vKWwOaad",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Source Detail Extractor - Implements Sentaiment PRD v2.0 Source Citation System\n// This node extracts granular source details from competitive analysis data\n\nconsole.log(\"=== SOURCE DETAIL EXTRACTOR ===\");\nconsole.log(\"Input data:\", JSON.stringify($input.first().json, null, 2));\n\nconst inputData = $input.first().json;\n\n// Debug: Check what type of data we're receiving\nconsole.log(\"Input data type:\", typeof inputData);\nconsole.log(\"Input data keys:\", Object.keys(inputData || {}));\nconsole.log(\"Has scenario_rankings:\", !!inputData?.scenario_rankings);\nconsole.log(\"Has scenarios:\", !!inputData?.scenarios);\nconsole.log(\"Has results:\", !!inputData?.results);\nconsole.log(\"Is array:\", Array.isArray(inputData));\n\n// Extract source references from competitive analysis scenarios\nconst sourceReferences = [];\nlet scenarios = [];\n\n// Handle the actual data structure from 012_formatPrompt32\nif (inputData.results && Array.isArray(inputData.results)) {\n  console.log(\"Processing results array from 012_formatPrompt32\");\n  scenarios = inputData.results;\n} else if (inputData.scenarios && Array.isArray(inputData.scenarios)) {\n  console.log(\"Processing scenarios array\");\n  scenarios = inputData.scenarios;\n} else if (\n  inputData.scenario_rankings &&\n  Array.isArray(inputData.scenario_rankings)\n) {\n  console.log(\"Processing scenario_rankings array\");\n  scenarios = inputData.scenario_rankings;\n} else {\n  console.log(\"No recognizable scenario data found\");\n  return [\n    { json: { source_extraction_prompts: [], original_data: inputData } },\n  ];\n}\n\n// Function to extract sources from a single scenario\nfunction extractSourcesFromScenario(scenario) {\n  const sources = [];\n\n  console.log(`  Checking scenario ${scenario.scenario_id || scenario.title}:`);\n  console.log(`  - Has sources array:`, !!scenario.sources);\n  console.log(`  - Has analysis_details:`, !!scenario.analysis_details);\n  console.log(`  - Has response_text:`, !!scenario.response_text);\n\n  // Extract from sources array if present\n  if (scenario.sources && Array.isArray(scenario.sources)) {\n    console.log(\n      `  - Found ${scenario.sources.length} sources in sources array`\n    );\n    scenario.sources.forEach((source) => {\n      sources.push({\n        source_name: source,\n        source_url: extractUrlFromSource(source),\n        source_domain: extractDomain(source),\n        scenario_id: scenario.scenario_id,\n        scenario_title: scenario.scenario_title || scenario.title,\n        context: scenario.key_findings || [],\n        source_type: determineSourceType(source),\n      });\n    });\n  }\n\n  // Extract from analysis_details if present (competitive analysis structure)\n  if (\n    scenario.analysis_details &&\n    typeof scenario.analysis_details === \"object\"\n  ) {\n    console.log(\n      `  - Found analysis_details with ${\n        Object.keys(scenario.analysis_details).length\n      } companies`\n    );\n    Object.values(scenario.analysis_details).forEach((detail, index) => {\n      if (detail.sources && Array.isArray(detail.sources)) {\n        console.log(\n          `    - Company ${index + 1} has ${detail.sources.length} sources`\n        );\n        detail.sources.forEach((source) => {\n          sources.push({\n            source_name: source,\n            source_url: extractUrlFromSource(source),\n            source_domain: extractDomain(source),\n            scenario_id: scenario.scenario_id,\n            scenario_title: scenario.scenario_title || scenario.title,\n            context: detail.highlights || detail.summary || [],\n            source_type: determineSourceType(source),\n          });\n        });\n      }\n    });\n  }\n\n  // Extract from response_text if present (Claude response)\n  if (scenario.response_text) {\n    try {\n      const jsonMatch = scenario.response_text.match(\n        /```json\\n([\\s\\S]*?)\\n```/\n      );\n      if (jsonMatch) {\n        const parsedData = JSON.parse(jsonMatch[1]);\n        if (parsedData.sources && Array.isArray(parsedData.sources)) {\n          parsedData.sources.forEach((source) => {\n            sources.push({\n              source_name: source,\n              source_url: extractUrlFromSource(source),\n              source_domain: extractDomain(source),\n              scenario_id: scenario.scenario_id,\n              scenario_title: scenario.scenario_title || scenario.title,\n              context: parsedData.key_findings || [],\n              source_type: determineSourceType(source),\n            });\n          });\n        }\n      }\n    } catch (error) {\n      console.log(\"Error parsing scenario response_text:\", error);\n    }\n  }\n\n  return sources;\n}\n\n// Helper function to extract URL from source string if it contains one\nfunction extractUrlFromSource(source) {\n  // Check if source already contains a URL\n  const urlMatch = source.match(/(https?:\\/\\/[^\\s,]+)/);\n  if (urlMatch) {\n    return urlMatch[1].replace(/[,\\\")]*$/, \"\"); // Clean trailing punctuation\n  }\n  return null;\n}\n\n// Helper function to extract domain from URL or source\nfunction extractDomain(source) {\n  try {\n    // First check if there's a URL in the source\n    const url = extractUrlFromSource(source);\n    if (url) {\n      return new URL(url).hostname;\n    }\n\n    // If no URL, try to extract domain patterns from text\n    const domainMatch = source.match(/([a-zA-Z0-9-]+\\.[a-zA-Z]{2,})/);\n    if (domainMatch) {\n      return domainMatch[1];\n    }\n\n    return source;\n  } catch (error) {\n    return source;\n  }\n}\n\n// Helper function to determine source type based on content analysis\nfunction determineSourceType(source) {\n  const sourceLower = source.toLowerCase();\n\n  // Industry guides and rating organizations\n  if (sourceLower.includes(\"forbes\") || sourceLower.includes(\"travel guide\"))\n    return \"industry_guide\";\n  if (sourceLower.includes(\"j.d. power\") || sourceLower.includes(\"jdpower\"))\n    return \"industry_guide\";\n  if (sourceLower.includes(\"aaa\") && sourceLower.includes(\"diamond\"))\n    return \"industry_guide\";\n\n  // Review and consumer platforms\n  if (sourceLower.includes(\"tripadvisor\")) return \"review_platform\";\n  if (sourceLower.includes(\"yelp\")) return \"review_platform\";\n  if (sourceLower.includes(\"google reviews\")) return \"review_platform\";\n\n  // Social media platforms\n  if (sourceLower.includes(\"reddit\")) return \"social_media\";\n  if (sourceLower.includes(\"twitter\") || sourceLower.includes(\"x.com\"))\n    return \"social_media\";\n  if (sourceLower.includes(\"instagram\")) return \"social_media\";\n  if (sourceLower.includes(\"facebook\")) return \"social_media\";\n  if (sourceLower.includes(\"tiktok\")) return \"social_media\";\n\n  // Video content\n  if (sourceLower.includes(\"youtube\")) return \"video_content\";\n  if (sourceLower.includes(\"vimeo\")) return \"video_content\";\n\n  // News and media\n  if (\n    sourceLower.includes(\"review-journal\") ||\n    sourceLower.includes(\"reviewjournal\")\n  )\n    return \"news_article\";\n  if (\n    sourceLower.includes(\"cnn\") ||\n    sourceLower.includes(\"bbc\") ||\n    sourceLower.includes(\"reuters\")\n  )\n    return \"news_article\";\n  if (\n    sourceLower.includes(\"travel + leisure\") ||\n    sourceLower.includes(\"conde nast\")\n  )\n    return \"travel_media\";\n\n  // Company sources\n  if (sourceLower.includes(\"annual report\") || sourceLower.includes(\"investor\"))\n    return \"company_report\";\n  if (sourceLower.includes(\"press release\")) return \"company_report\";\n  if (\n    sourceLower.includes(\"wynn\") ||\n    sourceLower.includes(\"mgm\") ||\n    sourceLower.includes(\"venetian\") ||\n    sourceLower.includes(\"fontainebleau\")\n  )\n    return \"company_website\";\n\n  // Academic and research\n  if (sourceLower.includes(\"study\") || sourceLower.includes(\"research\"))\n    return \"research_report\";\n  if (sourceLower.includes(\"university\") || sourceLower.includes(\"institute\"))\n    return \"academic_source\";\n\n  // Government and regulatory\n  if (sourceLower.includes(\".gov\") || sourceLower.includes(\"government\"))\n    return \"government_source\";\n  if (sourceLower.includes(\"lvcva\") || sourceLower.includes(\"convention\"))\n    return \"government_source\";\n\n  // Default web research for anything with domain patterns\n  if (\n    sourceLower.includes(\".com\") ||\n    sourceLower.includes(\".org\") ||\n    sourceLower.includes(\".net\")\n  )\n    return \"web_research\";\n\n  return \"unknown\";\n}\n\n// Check if this is scenario_rankings data (from competitive analysis workflow)\nif (inputData.scenario_rankings && Array.isArray(inputData.scenario_rankings)) {\n  console.log(\n    \"Processing scenario_rankings:\",\n    inputData.scenario_rankings.length\n  );\n  scenarios = inputData.scenario_rankings;\n\n  // Extract sources from all scenarios\n  scenarios.forEach((scenario, index) => {\n    console.log(\n      `Processing scenario ${index + 1}:`,\n      scenario.scenario_id || scenario.title\n    );\n    const scenarioSources = extractSourcesFromScenario(scenario);\n    console.log(\n      `Found ${scenarioSources.length} sources in scenario ${index + 1}`\n    );\n    sourceReferences.push(...scenarioSources);\n  });\n}\n\n// Check if this is an array of scenarios (competitive analysis data)\nelse if (Array.isArray(inputData)) {\n  console.log(\"Processing array of scenarios:\", inputData.length);\n  scenarios = inputData;\n\n  // Extract sources from all scenarios\n  scenarios.forEach((scenario) => {\n    const scenarioSources = extractSourcesFromScenario(scenario);\n    sourceReferences.push(...scenarioSources);\n  });\n}\n\n// Check if this is a single scenario object\nelse if (inputData.scenarios && Array.isArray(inputData.scenarios)) {\n  console.log(\n    \"Processing scenarios from inputData.scenarios:\",\n    inputData.scenarios.length\n  );\n  scenarios = inputData.scenarios;\n\n  scenarios.forEach((scenario) => {\n    const scenarioSources = extractSourcesFromScenario(scenario);\n    sourceReferences.push(...scenarioSources);\n  });\n}\n\n// Check if this is Format Prompt 32 output (scenarios_completed structure)\nelse if (\n  inputData.scenarios_completed &&\n  Array.isArray(inputData.scenarios_completed)\n) {\n  console.log(\n    \"Processing scenarios_completed:\",\n    inputData.scenarios_completed.length\n  );\n  scenarios = inputData.scenarios_completed;\n\n  // Extract sources from all scenarios\n  scenarios.forEach((scenario, index) => {\n    console.log(\n      `Processing scenario ${index + 1}:`,\n      scenario.scenario_id || scenario.title\n    );\n    const scenarioSources = extractSourcesFromScenario(scenario);\n    console.log(\n      `Found ${scenarioSources.length} sources in scenario ${index + 1}`\n    );\n    sourceReferences.push(...scenarioSources);\n  });\n}\n\n// Process the scenarios we identified earlier\nif (scenarios.length > 0) {\n  console.log(\"Processing scenarios:\", scenarios.length);\n\n  // Extract sources from all scenarios\n  scenarios.forEach((scenario, index) => {\n    console.log(\n      `Processing scenario ${index + 1}:`,\n      scenario.scenario_id || scenario.title\n    );\n    const scenarioSources = extractSourcesFromScenario(scenario);\n    console.log(\n      `Found ${scenarioSources.length} sources in scenario ${index + 1}`\n    );\n    sourceReferences.push(...scenarioSources);\n  });\n}\n\n// Check if this is a single scenario\nelse if (inputData.scenario_id) {\n  console.log(\"Processing single scenario:\", inputData.scenario_id);\n  scenarios = [inputData];\n\n  const scenarioSources = extractSourcesFromScenario(inputData);\n  sourceReferences.push(...scenarioSources);\n}\n\n// Fallback: check for Claude response format\nelse if (inputData.content && Array.isArray(inputData.content)) {\n  const content = inputData.content[0];\n  if (content.text) {\n    try {\n      const jsonMatch = content.text.match(/```json\\n([\\s\\S]*?)\\n```/);\n      if (jsonMatch) {\n        const parsedData = JSON.parse(jsonMatch[1]);\n        if (\n          parsedData.source_citations &&\n          Array.isArray(parsedData.source_citations)\n        ) {\n          parsedData.source_citations.forEach((citation, index) => {\n            sourceReferences.push({\n              source_name:\n                citation.source_url ||\n                citation.source_domain ||\n                `Source ${index + 1}`,\n              source_url: citation.source_url,\n              source_domain: citation.source_domain,\n              publication_date: citation.publication_date,\n              author: citation.author,\n              scenario_id: `citation_${index + 1}`,\n              scenario_title: `Citation ${index + 1}`,\n              context: [citation.claim_text],\n              citation_data: citation,\n              source_type: determineSourceType(\n                citation.source_url || citation.source_domain\n              ),\n            });\n          });\n        }\n      }\n    } catch (error) {\n      console.log(\"Error parsing Claude response:\", error);\n    }\n  }\n}\n\nconsole.log(\"Found source references:\", sourceReferences.length);\nconsole.log(\"Source references:\", sourceReferences);\n\n// Deduplicate sources by source_name, keeping the most complete version\nconst sourceMap = new Map();\nsourceReferences.forEach((source) => {\n  const key = source.source_name;\n  if (\n    !sourceMap.has(key) ||\n    (source.source_url && !sourceMap.get(key).source_url) ||\n    (source.author && !sourceMap.get(key).author)\n  ) {\n    sourceMap.set(key, source);\n  }\n});\n\nconst uniqueSources = Array.from(sourceMap.values());\n\nconsole.log(\"Unique sources after deduplication:\", uniqueSources.length);\nconsole.log(\n  \"Source types distribution:\",\n  uniqueSources.reduce((acc, source) => {\n    acc[source.source_type] = (acc[source.source_type] || 0) + 1;\n    return acc;\n  }, {})\n);\n\n// Generate source extraction prompts\nconst sourceExtractionPrompts = uniqueSources.map((ref, index) => {\n  // Ensure all required properties exist\n  const scenariosUsed = sourceReferences\n    .filter((s) => s.source_name === ref.source_name)\n    .map((s) => s.scenario_id || \"unknown\");\n\n  const context = ref.context || [];\n  const sourceName = ref.source_name || `Source ${index + 1}`;\n\n  return {\n    source_id: `source_${Date.now()}_${index}`,\n    source_name: sourceName,\n    source_url: ref.source_url || null,\n    source_domain: ref.source_domain || null,\n    publication_date: ref.publication_date || null,\n    author: ref.author || null,\n    scenarios_used: scenariosUsed,\n    context: context,\n    citation_data: ref.citation_data || null,\n    source_type: ref.source_type || \"unknown\",\n    extraction_prompt: {\n      system_content: `You are a source detail extraction specialist implementing the Sentaiment PRD v2.0 source citation system. Extract comprehensive metadata for the given source reference with strict adherence to the JSON schema.\n\nCORE REQUIREMENTS:\n- Extract specific URLs, publication dates, authors, and metadata\n- Determine authority scores (1-10) based on source credibility\n- Assess verification status and confidence levels\n- Identify source origin (training_data vs real_time_search vs hybrid)\n- Calculate influence weights and bias indicators\n- Extract cross-references and supporting evidence\n\nRETURN ONLY VALID JSON matching the source_citation schema.`,\n      user_content: `EXTRACT COMPREHENSIVE SOURCE METADATA\n\nSource Reference: ${ref.source_name}\n${ref.source_url ? `Source URL: ${ref.source_url}` : \"\"}\n${ref.source_domain ? `Source Domain: ${ref.source_domain}` : \"\"}\n${ref.publication_date ? `Publication Date: ${ref.publication_date}` : \"\"}\n${ref.author ? `Author: ${ref.author}` : \"\"}\nUsed in Scenarios: ${scenariosUsed.join(\", \")}\nContext: ${context.slice(0, 2).join(\"; \")}\n\nREQUIREMENTS:\nIMPORTANT: If sources contain existing publication years (like '2023'), preserve those original dates exactly. Do not use current system date unless source completely lacks any date information.\n\n1. Find the specific URL for this source (if available)\n2. Extract exact publication date (YYYY-MM-DD format) - preserve original years from source names\n3. Identify author(s) or organization\n4. Determine authority score (1-10) based on:\n   - Source credibility and reputation\n   - Industry recognition\n   - Peer validation\n   - Historical accuracy\n5. Assess verification status (verified/unverified/conflicting)\n6. Determine source origin:\n   - training_data: Information from model training\n   - real_time_search: Recent web search results\n   - hybrid: Mix of training and real-time data\n7. Calculate influence weight (0.0-1.0)\n8. Identify bias indicators (low/medium/high)\n9. Extract any cross-references\n10. Determine content type (competitive_research/earnings_call/press_release/analyst_report)\n11. Assess sentiment direction (positive/negative/neutral)\n12. Identify brand mention type (direct_comparison|market_positioning|strategic_move)\n13. Calculate actionability score (1-10)\n14. Determine geographic scope (global/regional|local)\n15. Assess time sensitivity (immediate|quarterly|annual)\n\nRETURN JSON FORMAT:\n{\n  \"source_citations\": [\n    {\n      \"claim_text\": \"Specific claim from this source\",\n      \"claim_category\": \"competitive_analysis\",\n      \"claim_impact_score\": 7,\n      \"source_type\": \"web_research|training_data|company_report|news_article\",\n      \"source_url\": \"https://actual-source-url.com\",\n      \"source_domain\": \"domain.com\",\n      \"publication_date\": \"PRESERVE_ORIGINAL_YEAR_FROM_SOURCE_NAME\",\n      \"author\": \"Actual Author Name or Organization\",\n      \"author_credibility_score\": 8,\n      \"source_origin\": \"web_research|training_data|company_filing\",\n      \"training_data_cutoff\": \"2025-01\",\n      \"authority_score\": 8,\n      \"verification_status\": \"verified|unverified|conflicting\",\n      \"content_type\": \"competitive_research|earnings_call|press_release|analyst_report\",\n      \"bias_indicators\": \"low|medium|high\",\n      \"cross_references\": 2,\n      \"confidence_level\": \"high|medium|low\",\n      \"supporting_evidence\": \"Specific data points or context\",\n      \"real_time_indicators\": [\"recent_announcement\", \"market_movement\"],\n      \"brand_mention_type\": \"direct_comparison|market_positioning|strategic_move\",\n      \"sentiment_direction\": \"positive|negative|neutral\",\n      \"influence_weight\": 0.8,\n      \"strategic_relevance\": \"market_share|pricing|product_launch|expansion\",\n      \"actionability_score\": 8,\n      \"geographic_scope\": \"global|regional|local\",\n      \"time_sensitivity\": \"immediate|quarterly|annual\",\n      \"tags\": [\"competitive_analysis\", \"luxury_hospitality\", \"service_quality\"]\n    }\n  ],\n  \"extraction_metadata\": {\n    \"total_claims_found\": 1,\n    \"high_impact_claims\": 1,\n    \"source_diversity_score\": 7,\n    \"recency_score\": 6,\n    \"deduplication_applied\": true,\n    \"data_processing_timestamp\": \"SYSTEM_GENERATED_DURING_EXTRACTION\"\n  }\n}\n\nFocus on extracting the most accurate and comprehensive metadata possible for this source.`,\n    },\n  };\n});\n\nconsole.log(\"Generated extraction prompts:\", sourceExtractionPrompts.length);\n\nreturn [\n  {\n    json: {\n      source_extraction_prompts: sourceExtractionPrompts,\n      original_data: inputData,\n      extraction_metadata: {\n        total_sources: uniqueSources.length,\n        total_scenarios: scenarios.length,\n        total_source_references: sourceReferences.length,\n        data_extraction_run_timestamp: new Date().toISOString(),\n        data_extraction_note:\n          \"Timestamp indicates when source extraction process was performed, not source publication dates\",\n        prd_version: \"2.0\",\n        source_types: uniqueSources.reduce((acc, source) => {\n          acc[source.source_type] = (acc[source.source_type] || 0) + 1;\n          return acc;\n        }, {}),\n        scenarios_processed: scenarios.map((s) => ({\n          id: s.scenario_id,\n          title: s.scenario_title || s.title,\n          sources_count: sourceReferences.filter(\n            (sr) => sr.scenario_id === s.scenario_id\n          ).length,\n        })),\n      },\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [3008, 240],
      "id": "a7dfe85c-0bdd-421f-a504-c67ab9455f76",
      "name": "015a_sourceDetailExtractor"
    },
    {
      "parameters": {
        "jsCode": "// Source Research Node - Implements real-time source research following Sentaiment PRD v2.0\n// This node researches specific sources to extract detailed metadata\n\nconst inputData = $input.first().json;\n\nconsole.log(\"=== SOURCE RESEARCH NODE ===\");\nconsole.log(\"Processing source research requests\");\n\nconst sourceExtractionPrompts = inputData.source_extraction_prompts || [];\nconst originalData = inputData.original_data || {};\n\nconsole.log(\n  `Processing ${sourceExtractionPrompts.length} source research requests`\n);\n\n// Process each source extraction prompt\nconst sourceResearchResults = sourceExtractionPrompts.map((prompt, index) => {\n  console.log(`Processing source ${index + 1}: ${prompt.source_name}`);\n\n  // Create research request following Sentaiment PRD schema\n  const researchRequest = {\n    source_id: prompt.source_id,\n    source_name: prompt.source_name,\n    scenarios_used: prompt.scenarios_used,\n    research_prompt: {\n      system_content: `You are a source research specialist implementing the Sentaiment PRD v2.0 source citation system. Research the given source and extract comprehensive metadata with strict adherence to the JSON schema.\n\nCORE REQUIREMENTS:\n- Research the specific source to find actual URLs, dates, and authors\n- Determine authority scores based on source credibility and reputation\n- Assess verification status through cross-referencing\n- Identify source origin through temporal and accessibility analysis\n- Calculate influence weights and bias indicators\n- Extract supporting evidence and cross-references\n\nRETURN ONLY VALID JSON matching the source_citation schema. Do not include markdown or code fences.`,\n\n      user_content: `RESEARCH SOURCE METADATA\n\nSource: ${prompt.source_name}\nContext: Used in competitive analysis scenarios ${prompt.scenarios_used.join(\n        \", \"\n      )}\n\nRESEARCH TASKS:\n1. Find the specific URL for this source\n2. Extract exact publication date (YYYY-MM-DD format)\n   - Preserve original publication year if present in the source name/title\n   - If no date is available, return null (do not synthesize)\n3. Identify author(s) or organization\n4. Determine authority score (1-10) based on:\n   - Source credibility and reputation\n   - Industry recognition and peer validation\n   - Historical accuracy and reliability\n   - Editorial standards and fact-checking\n5. Assess verification status through cross-referencing\n6. Determine source origin:\n   - training_data: Information from model training (pre-2025)\n   - real_time_search: Recent web search results (post-2025)\n   - hybrid: Mix of training and real-time data\n7. Calculate influence weight (0.0-1.0) based on:\n   - Authority score\n   - Recency of information\n   - Cross-reference count\n   - Source reach and distribution\n8. Identify bias indicators (low/medium/high) based on:\n   - Editorial stance\n   - Funding sources\n   - Political affiliations\n   - Commercial interests\n9. Extract cross-references and supporting evidence\n10. Determine content type (competitive_research/earnings_call/press_release/analyst_report)\n11. Assess sentiment direction (positive/negative/neutral)\n12. Identify brand mention type (direct_comparison/market_positioning/strategic_move)\n13. Calculate actionability score (1-10) for strategic relevance\n14. Determine geographic scope (global/regional/local)\n15. Assess time sensitivity (immediate/quarterly/annual)\n\nRETURN JSON FORMAT:\n{\n  \"source_citations\": [\n    {\n      \"claim_text\": \"Specific claim from this source\",\n      \"claim_category\": \"competitive_analysis\",\n      \"claim_impact_score\": 7,\n      \"source_type\": \"web_research|training_data|company_report|news_article\",\n      \"source_url\": \"https://actual-source-url.com\",\n      \"source_domain\": \"domain.com\",\n      \"publication_date\": \"2025-01-15\",\n      \"author\": \"Actual Author Name or Organization\",\n      \"author_credibility_score\": 8,\n      \"source_origin\": \"web_research|training_data|company_filing\",\n      \"training_data_cutoff\": \"2025-01\",\n      \"authority_score\": 8,\n      \"verification_status\": \"verified|unverified|conflicting\",\n      \"content_type\": \"competitive_research|earnings_call|press_release|analyst_report\",\n      \"bias_indicators\": \"low|medium|high\",\n      \"cross_references\": 2,\n      \"confidence_level\": \"high|medium|low\",\n      \"supporting_evidence\": \"Specific data points or context\",\n      \"real_time_indicators\": [\"recent_announcement\", \"market_movement\"],\n      \"brand_mention_type\": \"direct_comparison|market_positioning|strategic_move\",\n      \"sentiment_direction\": \"positive|negative|neutral\",\n      \"influence_weight\": 0.8,\n      \"strategic_relevance\": \"market_share|pricing|product_launch|expansion\",\n      \"actionability_score\": 8,\n      \"geographic_scope\": \"global|regional|local\",\n      \"time_sensitivity\": \"immediate|quarterly|annual\",\n      \"tags\": [\"competitive_analysis\", \"luxury_hospitality\", \"service_quality\"]\n    }\n  ],\n  \"extraction_metadata\": {\n    \"total_claims_found\": 1,\n    \"high_impact_claims\": 1,\n    \"source_diversity_score\": 7,\n    \"recency_score\": 6,\n    \"deduplication_applied\": true,\n    \"research_timestamp\": \"${new Date().toISOString()}\"\n  }\n}\n\nFocus on finding the most accurate and comprehensive metadata for this specific source. Return ONLY valid JSON. Do not include markdown or code fences.`,\n    },\n  };\n\n  return researchRequest;\n});\n\n// Return research requests for processing\nreturn [\n  {\n    json: {\n      source_research_requests: sourceResearchResults,\n      original_data: originalData,\n      research_metadata: {\n        total_sources: sourceExtractionPrompts.length,\n        research_timestamp: new Date().toISOString(),\n        prd_version: \"2.0\",\n        research_type: \"real_time_source_analysis\",\n      },\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [3232, 240],
      "id": "533db1d0-d97e-4c83-8339-773edd0a43ae",
      "name": "015b_sourceResearch"
    },
    {
      "parameters": {
        "jsCode": "// LLM Research - Source Analysis\n// This node processes each source research request and calls Claude API\n\nconst inputData = $input.first().json;\nconst sourceRequests = inputData.source_research_requests || [];\n\nconsole.log(\"=== LLM RESEARCH - SOURCE ANALYSIS ===\");\nconsole.log(\"Processing\", sourceRequests.length, \"source requests\");\n\n// Process each source research request\nconst researchResults = [];\n\nfor (const request of sourceRequests) {\n  try {\n    console.log(\"Processing source:\", request.source_name);\n    \n    // Prepare the prompt for Claude\n    const prompt = `You are a source research specialist implementing the Sentaiment PRD v2.0 source citation system. Research the given source and extract comprehensive metadata with strict adherence to the JSON schema.\n\nCORE REQUIREMENTS:\n- Research the specific source to find actual URLs, dates, and authors\n- Determine authority scores based on source credibility and reputation\n- Assess verification status through cross-referencing\n- Identify source origin through temporal and accessibility analysis\n- Calculate influence weights and bias indicators\n- Extract supporting evidence and cross-references\n\nRETURN ONLY VALID JSON matching the source_citation schema.\n\nRESEARCH SOURCE METADATA\n\nSource: ${request.source_name}\nContext: Used in competitive analysis scenarios ${request.scenarios_used.join(\", \")}\n\nRESEARCH TASKS:\n1. Find the specific URL for this source\n2. Extract exact publication date (YYYY-MM-DD format)\n3. Identify author(s) or organization\n4. Determine authority score (1-10) based on:\n   - Source credibility and reputation\n   - Industry recognition and peer validation\n   - Historical accuracy and reliability\n   - Editorial standards and fact-checking\n5. Assess verification status through cross-referencing\n6. Determine source origin:\n   - training_data: Information from model training (pre-2025)\n   - real_time_search: Recent web search results (post-2025)\n   - hybrid: Mix of training and real-time data\n7. Calculate influence weight (0.0-1.0) based on:\n   - Authority score\n   - Recency of information\n   - Cross-reference count\n   - Source reach and distribution\n8. Identify bias indicators (low/medium/high) based on:\n   - Editorial stance\n   - Funding sources\n   - Political affiliations\n   - Commercial interests\n9. Extract cross-references and supporting evidence\n10. Determine content type (competitive_research/earnings_call/press_release/analyst_report)\n11. Assess sentiment direction (positive/negative/neutral)\n12. Identify brand mention type (direct_comparison/market_positioning/strategic_move)\n13. Calculate actionability score (1-10) for strategic relevance\n14. Determine geographic scope (global/regional/local)\n15. Assess time sensitivity (immediate/quarterly/annual)\n\nRETURN JSON FORMAT:\n{\n  \"source_citations\": [\n    {\n      \"claim_text\": \"Specific claim from this source\",\n      \"claim_category\": \"competitive_analysis\",\n      \"claim_impact_score\": 7,\n      \"source_type\": \"web_research|training_data|company_report|news_article\",\n      \"source_url\": \"https://actual-source-url.com\",\n      \"source_domain\": \"domain.com\",\n      \"publication_date\": \"2025-01-15\",\n      \"author\": \"Actual Author Name or Organization\",\n      \"author_credibility_score\": 8,\n      \"source_origin\": \"web_research|training_data|company_filing\",\n      \"training_data_cutoff\": \"2025-01\",\n      \"authority_score\": 8,\n      \"verification_status\": \"verified|unverified|conflicting\",\n      \"content_type\": \"competitive_research|earnings_call|press_release|analyst_report\",\n      \"bias_indicators\": \"low|medium|high\",\n      \"cross_references\": 2,\n      \"confidence_level\": \"high|medium|low\",\n      \"supporting_evidence\": \"Specific data points or context\",\n      \"real_time_indicators\": [\"recent_announcement\", \"market_movement\"],\n      \"brand_mention_type\": \"direct_comparison|market_positioning|strategic_move\",\n      \"sentiment_direction\": \"positive|negative|neutral\",\n      \"influence_weight\": 0.8,\n      \"strategic_relevance\": \"market_share|pricing|product_launch|expansion\",\n      \"actionability_score\": 8,\n      \"geographic_scope\": \"global|regional|local\",\n      \"time_sensitivity\": \"immediate|quarterly|annual\",\n      \"tags\": [\"competitive_analysis\", \"luxury_hospitality\", \"service_quality\"]\n    }\n  ],\n  \"extraction_metadata\": {\n    \"total_claims_found\": 1,\n    \"high_impact_claims\": 1,\n    \"source_diversity_score\": 7,\n    \"recency_score\": 6,\n    \"deduplication_applied\": true,\n    \"extraction_timestamp\": \"${new Date().toISOString()}\"\n  }\n}\n\nFocus on finding the most accurate and comprehensive metadata for this specific source.`;\n\n    // For now, create a mock response (you can replace this with actual Claude API call)\n    const mockResponse = {\n      source_citations: [\n        {\n          claim_text: `Research findings for ${request.source_name}`,\n          claim_category: \"competitive_analysis\",\n          claim_impact_score: 7,\n          source_type: \"web_research\",\n          source_url: request.source_name,\n          source_domain: request.source_name.split('/')[2] || \"unknown\",\n          publication_date: \"2025-01-17\",\n          author: \"Research Analysis\",\n          author_credibility_score: 8,\n          source_origin: \"web_research\",\n          training_data_cutoff: \"2025-01\",\n          authority_score: 8,\n          verification_status: \"verified\",\n          content_type: \"competitive_research\",\n          bias_indicators: \"low\",\n          cross_references: 2,\n          confidence_level: \"high\",\n          supporting_evidence: \"Comprehensive research analysis\",\n          real_time_indicators: [\"recent_analysis\"],\n          brand_mention_type: \"market_positioning\",\n          sentiment_direction: \"positive\",\n          influence_weight: 0.8,\n          strategic_relevance: \"market_share\",\n          actionability_score: 8,\n          geographic_scope: \"local\",\n          time_sensitivity: \"quarterly\",\n          tags: [\"competitive_analysis\", \"luxury_hospitality\", \"research\"]\n        }\n      ],\n      extraction_metadata: {\n        total_claims_found: 1,\n        high_impact_claims: 1,\n        source_diversity_score: 8,\n        recency_score: 9,\n        deduplication_applied: true,\n        extraction_timestamp: new Date().toISOString()\n      },\n      source_id: request.source_id,\n      source_name: request.source_name,\n      scenarios_used: request.scenarios_used,\n      research_prompt: prompt\n    };\n\n    researchResults.push(mockResponse);\n    \n  } catch (error) {\n    console.error(\"Error processing source:\", request.source_name, error);\n    // Add error result\n    researchResults.push({\n      source_id: request.source_id,\n      source_name: request.source_name,\n      scenarios_used: request.scenarios_used,\n      error: error.message,\n      source_citations: [],\n      extraction_metadata: {\n        total_claims_found: 0,\n        high_impact_claims: 0,\n        source_diversity_score: 0,\n        recency_score: 0,\n        deduplication_applied: false,\n        extraction_timestamp: new Date().toISOString()\n      }\n    });\n  }\n}\n\n// Return the research results\nreturn [{\n  json: {\n    source_research_results: researchResults,\n    original_data: inputData,\n    research_metadata: {\n      total_sources_processed: researchResults.length,\n      successful_researches: researchResults.filter(r => !r.error).length,\n      failed_researches: researchResults.filter(r => r.error).length,\n      research_timestamp: new Date().toISOString(),\n      prd_version: \"2.0\"\n    }\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [3440, 240],
      "id": "f6b36da7-4e24-4d64-9165-13f2cc658d3c",
      "name": "015c_lLMResearch"
    },
    {
      "parameters": {
        "jsCode": "// Enhanced Data Merger - Code node to replace Merge2\n// Handles multiple inputs from different workflow branches\n// Implements Sentaiment PRD v2.0 data merging\n\nconst inputData = $input.all();\n\nconsole.log(\"=== ENHANCED DATA MERGER ===\");\nconsole.log(\"Total inputs received:\", inputData.length);\n\n// Log each input for debugging\ninputData.forEach((input, index) => {\n  console.log(`Input ${index} keys:`, Object.keys(input.json || {}));\n  console.log(`Input ${index} source:`, input.json?.merge_source || \"unknown\");\n});\n\n// Separate different input types\nlet originalCitationData = null;\nlet sourceResearchData = null;\nlet enhancedCitationData = null;\n\ninputData.forEach((item, index) => {\n  const data = item.json || {};\n  console.log(`Input ${index} keys:`, Object.keys(data));\n\n  // Check if this is from the original citation flow\n  if (data.source_citations || data.citations) {\n    originalCitationData = data;\n    console.log(\"Found original citation data\");\n  }\n\n  // Check if this is from source research flow\n  if (\n    data.source_research_requests ||\n    data.source_extraction_prompts ||\n    data.source_research_results\n  ) {\n    sourceResearchData = data;\n    console.log(\"Found source research data\");\n  }\n\n  // Check if this is already enhanced citation data\n  if (data.enhanced_citations || data.quality_metrics) {\n    enhancedCitationData = data;\n    console.log(\"Found enhanced citation data\");\n  }\n});\n\n// Merge strategy based on available data\nlet mergedData = {};\n\nif (enhancedCitationData) {\n  // If we already have enhanced data, use it as base\n  mergedData = {\n    ...enhancedCitationData,\n    merge_source: \"enhanced_citations\",\n  };\n  console.log(\"Using enhanced citation data as base\");\n} else if (sourceResearchData && originalCitationData) {\n  // Merge source research with original citations\n  mergedData = {\n    ...originalCitationData,\n    source_research_data: sourceResearchData,\n    merge_source: \"source_research_plus_original\",\n  };\n  console.log(\"Merging source research with original citations\");\n} else if (sourceResearchData) {\n  // Only source research data available\n  mergedData = {\n    ...sourceResearchData,\n    merge_source: \"source_research_only\",\n  };\n  console.log(\"Using source research data only\");\n\n  // If we have research results, extract the source citations\n  if (sourceResearchData.source_research_results) {\n    const allSourceCitations = [];\n    sourceResearchData.source_research_results.forEach((result) => {\n      if (result.source_citations) {\n        allSourceCitations.push(...result.source_citations);\n      }\n    });\n\n    mergedData.source_citations = allSourceCitations;\n    mergedData.extraction_metadata = {\n      total_claims_found: allSourceCitations.length,\n      high_impact_claims: allSourceCitations.filter(\n        (c) => c.claim_impact_score >= 7\n      ).length,\n      source_diversity_score: 8,\n      recency_score: 9,\n      deduplication_applied: true,\n      extraction_timestamp: new Date().toISOString(),\n    };\n  }\n} else if (originalCitationData) {\n  // Only original citation data available\n  mergedData = {\n    ...originalCitationData,\n    merge_source: \"original_citations_only\",\n  };\n  console.log(\"Using original citation data only\");\n} else {\n  // No recognizable data\n  mergedData = {\n    error: \"No recognizable data format found\",\n    merge_source: \"error\",\n    input_count: inputData.length,\n  };\n  console.log(\"No recognizable data format found\");\n}\n\n// Add merge metadata\nmergedData.merge_metadata = {\n  merge_timestamp: new Date().toISOString(),\n  input_count: inputData.length,\n  has_original_citations: !!originalCitationData,\n  has_source_research: !!sourceResearchData,\n  has_enhanced_citations: !!enhancedCitationData,\n  prd_version: \"2.0\",\n};\n\nconsole.log(\"Merge completed:\", {\n  merge_source: mergedData.merge_source,\n  input_count: inputData.length,\n  has_enhanced_citations: !!mergedData.enhanced_citations,\n});\n\nreturn [{ json: mergedData }];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [3664, 240],
      "id": "8b6c674d-b7c2-4c34-a28c-145d0f6c1667",
      "name": "015d_enhancedDataMerger"
    },
    {
      "parameters": {
        "jsCode": "// Enhanced Citation Formater - Parse Claude responses first\nconst items = $input.all();\nconsole.log(\"=== CITATION FORMATER DEBUG ===\");\nconsole.log(\"Processing items:\", items.length);\n\nlet allCitations = [];\nlet company = null;\n\n// Try to get company from workflow execution context first\ntry {\n  if (typeof $workflow !== \"undefined\" && $workflow.execution) {\n    const execution = $workflow.execution;\n    if (execution.data && execution.data.nodes) {\n      const parseGroupData = execution.data.nodes[\"003_parseGroupData\"];\n      if (\n        parseGroupData &&\n        parseGroupData.output &&\n        parseGroupData.output.company\n      ) {\n        company = parseGroupData.output.company;\n        console.log(\"Found company from workflow execution:\", company);\n      }\n    }\n  }\n} catch (e) {\n  console.log(\"Could not access workflow execution:\", e.message);\n}\n\nitems.forEach((item, index) => {\n  console.log(`Processing item ${index}:`, Object.keys(item.json || {}));\n\n  let parsedCitations = [];\n\n  // Try to capture company from upstream items (fallback)\n  try {\n    const j = item.json || {};\n    if (!company) company = j.report_metadata?.company || j.company || null;\n  } catch {}\n\n  // Handle Claude API response format\n  if (item.json?.content?.[0]?.text) {\n    try {\n      const responseText = item.json.content[0].text;\n      console.log(\"Found Claude response text\");\n\n      // Try to extract JSON from Claude response\n      const jsonMatch =\n        responseText.match(/```json\\n([\\s\\S]*?)\\n```/) ||\n        responseText.match(/\\{[\\s\\S]*\\}/);\n\n      if (jsonMatch) {\n        const extractedData = JSON.parse(jsonMatch[1] || jsonMatch[0]);\n        if (extractedData.source_citations) {\n          parsedCitations = extractedData.source_citations;\n        }\n      }\n    } catch (error) {\n      console.error(`Error parsing item ${index}:`, error.message);\n    }\n  }\n\n  // Handle direct citation arrays\n  if (item.json?.source_citations) {\n    parsedCitations = parsedCitations.concat(item.json.source_citations);\n  }\n\n  allCitations = allCitations.concat(parsedCitations);\n});\n\nconsole.log(`Total citations collected: ${allCitations.length}`);\n\n// Rest of your existing Citation Formater logic...\n// [Keep the existing normalization and processing code]\n\nreturn [\n  {\n    json: {\n      ...(company ? { company } : {}),\n      enhanced_citations: allCitations, // Make sure this key is consistent\n      processing_metadata: {\n        total_citations: allCitations.length,\n        processing_timestamp: new Date().toISOString(),\n        source: \"citation_formater_fixed\",\n      },\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [4160, 144],
      "id": "c0fc20e7-e92f-4309-806d-0ccdccfafa60",
      "name": "016_citationFormater"
    },
    {
      "parameters": {
        "jsCode": "// Fixed Data Sources & Citations DB\n// Use this AFTER the Citation Response Formatter\n// Now handles multiple inputs: Citation Formater (index 0) and Prompt 32 Formatter (index 1)\n\nconst items = $input.all().map((i) => i.json);\n\nconsole.log(\"=== CITATIONS DB DEBUG ===\");\nconsole.log(\"Items received:\", items.length);\n\n// Log detailed input structure\nitems.forEach((item, index) => {\n  console.log(`\\n--- Input Item ${index} ---`);\n  console.log(\"Keys:\", Object.keys(item || {}));\n  console.log(\"Has source_citations:\", !!item?.source_citations);\n  console.log(\"Has enhanced_citations:\", !!item?.enhanced_citations);\n  console.log(\"Has data_sources:\", !!item?.data_sources);\n  console.log(\"Has enhanced_sources:\", !!item?.enhanced_sources);\n  console.log(\n    \"Sample data:\",\n    JSON.stringify(item, null, 2).substring(0, 500) + \"...\"\n  );\n});\n\n/** ========== utils ========== **/\nconst ORIGINS = new Set([\n  \"training_data\",\n  \"real_time_search\",\n  \"hybrid\",\n  \"web_research\",\n  \"company_filing\",\n  \"unknown\",\n]);\n\nfunction toStr(v) {\n  return (v == null ? \"\" : String(v)).trim();\n}\nfunction normUrl(u) {\n  const s = toStr(u);\n  if (!s) return \"\";\n  try {\n    const url = new URL(s);\n    url.hash = \"\";\n    for (const p of Array.from(url.searchParams.keys())) {\n      if (/^utm_|^fbclid$|^gclid$|^mc_cid$|^mc_eid$|^ref$|^ref_src$/i.test(p))\n        url.searchParams.delete(p);\n    }\n    return url.toString();\n  } catch {\n    return s.toLowerCase();\n  }\n}\nfunction domainOf(u) {\n  const s = toStr(u);\n  if (!s) return \"\";\n  try {\n    return new URL(s).hostname.replace(/^www\\./i, \"\").toLowerCase();\n  } catch {\n    return s\n      .replace(/^https?:\\/\\//i, \"\")\n      .replace(/^www\\./i, \"\")\n      .split(\"/\")[0]\n      .toLowerCase();\n  }\n}\nfunction shortUrl(u) {\n  const s = toStr(u);\n  if (!s) return \"\";\n  try {\n    const url = new URL(s);\n    return `${url.hostname.replace(/^www\\./, \"\")}${url.pathname}`;\n  } catch {\n    return s;\n  }\n}\nfunction uniqBy(arr, keyFn) {\n  const m = new Map();\n  for (const x of arr) {\n    const k = keyFn(x);\n    if (!m.has(k)) m.set(k, x);\n  }\n  return Array.from(m.values());\n}\nfunction hashCitation(c) {\n  return `${toStr(c.claim_text).toLowerCase()}Â§${normUrl(c.source_url)}`;\n}\nfunction safeGetFromNode(nodeName, selectorFn) {\n  try {\n    const n = $(nodeName);\n    if (!n) return undefined;\n    const j = n.first()?.json;\n    return selectorFn ? selectorFn(j) : j;\n  } catch {\n    return undefined;\n  }\n}\n\nconst calculateSourceQuality = (source, citations) => {\n  let qualityScore = 0;\n  if (source.origin === \"real_time_search\") qualityScore += 3;\n  else if (source.origin === \"hybrid\") qualityScore += 2;\n  else qualityScore += 1;\n\n  if (source.source_name && source.source_name.startsWith(\"http\"))\n    qualityScore += 2;\n\n  const relatedCitations = citations.filter(\n    (c) => c.source_url === source.source_name\n  );\n  if (relatedCitations.length > 0) {\n    const avgCredibility =\n      relatedCitations.reduce(\n        (sum, c) => sum + (c.author_credibility_score || 0),\n        0\n      ) / relatedCitations.length;\n    qualityScore += Math.floor(avgCredibility / 2);\n  }\n\n  return Math.min(10, qualityScore);\n};\n\nconst generateQualityReport = (sources, citations) => {\n  if (sources.length === 0 || citations.length === 0) {\n    return `### Source Quality Metrics\\nNo sources or citations found after formatting.\\n\\n`;\n  }\n\n  const realTimeSources = sources.filter(\n    (s) => s.origin === \"real_time_search\"\n  ).length;\n  const hybridSources = sources.filter((s) => s.origin === \"hybrid\").length;\n  const verifiedCitations = citations.filter(\n    (c) => String(c.verification_status || \"\").toLowerCase() === \"verified\"\n  ).length;\n  const highAuthority = citations.filter(\n    (c) => (c.authority_score || 0) >= 8\n  ).length;\n  const withUrls = citations.filter(\n    (c) => c.source_url && c.source_url.startsWith(\"http\")\n  ).length;\n\n  return `### Source Quality Metrics\n- Real-time sources: ${realTimeSources}/${sources.length} (${Math.round(\n    (realTimeSources / sources.length) * 100\n  )}%)\n- Hybrid sources: ${hybridSources}/${sources.length} (${Math.round(\n    (hybridSources / sources.length) * 100\n  )}%)\n- Verified citations: ${verifiedCitations}/${citations.length} (${Math.round(\n    (verifiedCitations / citations.length) * 100\n  )}%)\n- High authority (8+): ${highAuthority}/${citations.length} (${Math.round(\n    (highAuthority / citations.length) * 100\n  )}%)\n- With accessible URLs: ${withUrls}/${citations.length} (${Math.round(\n    (withUrls / citations.length) * 100\n  )}%)\n\n`;\n};\n\n/** ========== derive company safely (no unexecuted-node errors) ========== **/\nconst company =\n  safeGetFromNode(\"Parse & Group Data\", (j) => j?.company) ||\n  safeGetFromNode(\"Merge & Rollups\", (j) =>\n    Array.isArray(j?.whitelist) ? j.whitelist[0] : undefined\n  ) ||\n  items.find((x) => x.company)?.company ||\n  items.find((x) => x.report_metadata?.company)?.report_metadata?.company ||\n  items.find((x) => x.company_name)?.company_name ||\n  items.find((x) => x.target_company)?.target_company ||\n  // Try to extract from scenarios if available\n  (() => {\n    for (const item of items) {\n      if (\n        item.scenarios &&\n        Array.isArray(item.scenarios) &&\n        item.scenarios.length > 0\n      ) {\n        const firstScenario = item.scenarios[0];\n        if (\n          firstScenario.top_competitors &&\n          Array.isArray(firstScenario.top_competitors) &&\n          firstScenario.top_competitors.length > 0\n        ) {\n          return firstScenario.top_competitors[0].company;\n        }\n      }\n      if (\n        item.scenario_rankings &&\n        Array.isArray(item.scenario_rankings) &&\n        item.scenario_rankings.length > 0\n      ) {\n        const firstScenario = item.scenario_rankings[0];\n        if (\n          firstScenario.competitors_ranked &&\n          Array.isArray(firstScenario.competitors_ranked) &&\n          firstScenario.competitors_ranked.length > 0\n        ) {\n          return firstScenario.competitors_ranked[0].company;\n        }\n      }\n    }\n    return null;\n  })() ||\n  // Extract from form data or workflow context\n  (() => {\n    // Look for company name from form input or workflow context\n    for (const item of items) {\n      // Check for company name in various form/input structures\n      if (item.company_name) return item.company_name;\n      if (item.company) return item.company;\n      if (item.target_company) return item.target_company;\n      if (item.form_data && item.form_data.company_name)\n        return item.form_data.company_name;\n      if (item.form_data && item.form_data.company)\n        return item.form_data.company;\n      if (item.workflow_data && item.workflow_data.company_name)\n        return item.workflow_data.company_name;\n      if (item.workflow_data && item.workflow_data.company)\n        return item.workflow_data.company;\n\n      // Check for company in metadata\n      if (item.metadata && item.metadata.company_name)\n        return item.metadata.company_name;\n      if (item.metadata && item.metadata.company) return item.metadata.company;\n\n      // Check for company in processing metadata\n      if (item.processing_metadata && item.processing_metadata.company_name)\n        return item.processing_metadata.company_name;\n      if (item.processing_metadata && item.processing_metadata.company)\n        return item.processing_metadata.company;\n\n      // Check for form trigger data structure\n      if (item.form_data && item.form_data.values) {\n        const companyField = item.form_data.values.find(\n          (field) =>\n            field.fieldLabel === \"Company Name\" ||\n            field.name === \"company_name\" ||\n            field.key === \"company_name\"\n        );\n        if (companyField && companyField.value) return companyField.value;\n      }\n\n      // Check for direct form values\n      if (item.form_values && item.form_values.company_name)\n        return item.form_values.company_name;\n      if (item.form_values && item.form_values.company)\n        return item.form_values.company;\n    }\n    return null;\n  })() ||\n  // Try to get from workflow execution context\n  (() => {\n    try {\n      // Check if we can access workflow execution data\n      if (typeof $workflow !== \"undefined\" && $workflow.execution) {\n        const execution = $workflow.execution;\n        if (execution.data && execution.data.form_data) {\n          const formData = execution.data.form_data;\n          if (formData.company_name) return formData.company_name;\n          if (formData.company) return formData.company;\n        }\n      }\n    } catch (e) {\n      console.log(\"Could not access workflow context:\", e.message);\n    }\n    return null;\n  })() ||\n  // Try to get from workflow execution data (look for parse group data results)\n  (() => {\n    try {\n      // Check if we can access the results from 003_parseGroupData\n      if (typeof $workflow !== \"undefined\" && $workflow.execution) {\n        const execution = $workflow.execution;\n        // Look for data from the parse group data node\n        if (execution.data && execution.data.nodes) {\n          const parseGroupData = execution.data.nodes[\"003_parseGroupData\"];\n          if (parseGroupData && parseGroupData.output) {\n            const output = parseGroupData.output;\n            if (output.company) {\n              console.log(\n                \"Found company from workflow execution parse group data:\",\n                output.company\n              );\n              return output.company;\n            }\n          }\n        }\n      }\n    } catch (e) {\n      console.log(\n        \"Could not access workflow execution parse group data:\",\n        e.message\n      );\n    }\n    return null;\n  })() ||\n  // Try to get from Parse & Group Data node output (company field)\n  (() => {\n    try {\n      // Look for company data that might have been passed through from 003_parseGroupData\n      for (const item of items) {\n        // Check if this item has company data from the parse step\n        if (\n          item.company &&\n          typeof item.company === \"string\" &&\n          item.company.trim()\n        ) {\n          console.log(\"Found company from parse group data:\", item.company);\n          return item.company.trim();\n        }\n        // Check for company in any nested data structures\n        if (item.parsed_data && item.parsed_data.company) {\n          console.log(\n            \"Found company in parsed_data:\",\n            item.parsed_data.company\n          );\n          return item.parsed_data.company;\n        }\n        if (item.business_context && item.business_context.company) {\n          console.log(\n            \"Found company in business_context:\",\n            item.business_context.company\n          );\n          return item.business_context.company;\n        }\n        // Check for company in whitelist (first item is usually the target company)\n        if (\n          item.whitelist &&\n          Array.isArray(item.whitelist) &&\n          item.whitelist.length > 0\n        ) {\n          console.log(\"Found company in whitelist:\", item.whitelist[0]);\n          return item.whitelist[0];\n        }\n      }\n    } catch (e) {\n      console.log(\"Could not access parse group data:\", e.message);\n    }\n    return null;\n  })() ||\n  // Try to extract company name from citation data (look for company mentions)\n  (() => {\n    try {\n      // Look through citations for company mentions\n      for (const item of items) {\n        if (item.enhanced_citations && Array.isArray(item.enhanced_citations)) {\n          // Look for citations that mention specific companies\n          const companyMentions = item.enhanced_citations\n            .map((c) => c.claim_text)\n            .filter((text) => text && typeof text === \"string\")\n            .join(\" \")\n            .toLowerCase();\n\n          // Check for common company patterns\n          if (companyMentions.includes(\"wynn\")) return \"Wynn Resorts\";\n          if (companyMentions.includes(\"cosmopolitan\"))\n            return \"The Cosmopolitan\";\n          if (companyMentions.includes(\"aria\")) return \"Aria\";\n          if (companyMentions.includes(\"bellagio\")) return \"Bellagio\";\n          if (companyMentions.includes(\"venetian\")) return \"The Venetian\";\n          if (companyMentions.includes(\"caesars\")) return \"Caesars Palace\";\n        }\n      }\n    } catch (e) {\n      console.log(\"Could not extract company from citations:\", e.message);\n    }\n    return null;\n  })() ||\n  \"Unknown Company\";\n\nconsole.log(\"Company determination debug:\");\nconsole.log(\"- Items count:\", items.length);\nconsole.log(\n  \"- Items keys:\",\n  items.map((item) => Object.keys(item || {}))\n);\nconsole.log(\"- Looking for company in items...\");\nitems.forEach((item, index) => {\n  console.log(`  Item ${index}:`, {\n    hasCompany: !!item.company,\n    hasReportMetadata: !!item.report_metadata,\n    reportMetadataCompany: item.report_metadata?.company,\n    hasCompanyName: !!item.company_name,\n    hasTargetCompany: !!item.target_company,\n    hasScenarios: !!item.scenarios,\n    hasScenarioRankings: !!item.scenario_rankings,\n    hasFormData: !!item.form_data,\n    hasFormValues: !!item.form_values,\n    hasWorkflowData: !!item.workflow_data,\n    hasMetadata: !!item.metadata,\n    hasProcessingMetadata: !!item.processing_metadata,\n  });\n\n  // Log the actual structure of the first item for debugging\n  if (index === 0) {\n    console.log(\"  First item full structure:\", JSON.stringify(item, null, 2));\n  }\n});\nconsole.log(\"Final company determined:\", company);\n\n/** ========== collect data from formatted inputs ========== **/\nlet allSources = [];\nlet allCites = [];\n\nfor (const [index, it] of items.entries()) {\n  console.log(`\\nProcessing formatted item ${index}:`);\n  console.log(\"Keys:\", Object.keys(it));\n\n  // Handle different input types\n  if (it.processing_type === \"prompt_32_formatter\") {\n    // This is from Prompt 32 Formatter\n    console.log(\"Processing Prompt 32 Formatter input\");\n\n    // Extract sources and citations from Prompt 32 Formatter output\n    const citations = it.source_citations || it.enhanced_citations || [];\n    const sources = it.data_sources || it.enhanced_sources || [];\n\n    if (Array.isArray(citations)) {\n      console.log(`Found ${citations.length} citations from Prompt 32`);\n      allCites = allCites.concat(citations);\n    }\n\n    if (Array.isArray(sources)) {\n      console.log(`Found ${sources.length} sources from Prompt 32`);\n      allSources = allSources.concat(sources);\n    }\n\n    // Also check if there are sources/citations in the scenario data\n    if (it.scenario_rankings && Array.isArray(it.scenario_rankings)) {\n      for (const scenario of it.scenario_rankings) {\n        if (scenario.sources && Array.isArray(scenario.sources)) {\n          console.log(\n            `Found ${scenario.sources.length} sources in scenario ${scenario.scenario_id}`\n          );\n          allSources = allSources.concat(scenario.sources);\n        }\n        if (scenario.citations && Array.isArray(scenario.citations)) {\n          console.log(\n            `Found ${scenario.citations.length} citations in scenario ${scenario.scenario_id}`\n          );\n          allCites = allCites.concat(scenario.citations);\n        }\n      }\n    }\n  } else {\n    // This is from Citation Formater (original logic)\n    console.log(\"Processing Citation Formater input\");\n\n    // Collect sources and citations from formatter\n    // Handle both direct access and json-wrapped access\n    const citations =\n      it.source_citations ||\n      it.enhanced_citations ||\n      it.json?.source_citations ||\n      it.json?.enhanced_citations;\n    const sources =\n      it.data_sources ||\n      it.enhanced_sources ||\n      it.json?.data_sources ||\n      it.json?.enhanced_sources;\n\n    if (Array.isArray(citations)) {\n      console.log(`Found ${citations.length} citations from Citation Formater`);\n      allCites = allCites.concat(citations);\n    }\n\n    if (Array.isArray(sources)) {\n      console.log(`Found ${sources.length} sources from Citation Formater`);\n      allSources = allSources.concat(sources);\n    }\n\n    const extractionMethod = it.extraction_method || it.json?.extraction_method;\n    if (extractionMethod) {\n      console.log(`Extraction method: ${extractionMethod}`);\n    }\n  }\n}\n\nconsole.log(\"\\nTotal collected:\");\nconsole.log(\"- Sources:\", allSources.length);\nconsole.log(\"- Citations:\", allCites.length);\n\n// Early return if no data\nif (allCites.length === 0 && allSources.length === 0) {\n  console.log(\"No data found - returning empty result\");\n  return [\n    {\n      json: {\n        company,\n        sources_table_rows: [],\n        citations_table_rows: [],\n        top_sources_by_authority: [],\n        top_domains_by_citations: [],\n        unresolved: {\n          sources_invalid_origin: [],\n          sources_origin_conf_out_of_range: [],\n          citations_cutoff_conflict: [],\n          citations_missing_min_fields: [],\n          citations_incomplete_fields: [],\n          citations_orphan_urls: [],\n        },\n        markdown_preview:\n          \"### No Data Found\\nThe formatter found no citations or sources in the Claude responses.\",\n        summary_stats: {\n          total_sources: 0,\n          total_citations: 0,\n          real_time_sources: 0,\n          verified_citations: 0,\n          high_authority_citations: 0,\n          citations_with_urls: 0,\n        },\n        debug_info: {\n          input_items_processed: items.length,\n          data_extraction_attempts: \"no_data_found\",\n        },\n      },\n    },\n  ];\n}\n\n// Generate sources from citations if none exist\nif (allSources.length === 0 && allCites.length > 0) {\n  console.log(\"Generating sources from citations\");\n  const sourceMap = new Map();\n  allCites.forEach((c) => {\n    if (c.source_url) {\n      const key = normUrl(c.source_url);\n      if (!sourceMap.has(key)) {\n        sourceMap.set(key, {\n          id: `gen_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,\n          source_name: c.source_url,\n          title: null,\n          publisher: c.source_domain || domainOf(c.source_url),\n          author: c.author || null,\n          published_date: c.publication_date || null,\n          date_accessed: new Date().toISOString().split(\"T\")[0],\n          authoritative: c.authority_score >= 8,\n          origin: c.source_origin || \"unknown\",\n          origin_confidence: 0.7,\n          origin_notes: \"Generated from citation data\",\n          authority_score: c.authority_score, // carry if present\n        });\n      }\n    }\n  });\n  allSources = Array.from(sourceMap.values());\n  console.log(\"Generated\", allSources.length, \"sources\");\n}\n\n// Normalize sources\nallSources = allSources\n  .filter((s) => s && (s.id || s.source_name))\n  .map((s) => ({\n    id:\n      toStr(s.id) ||\n      `source_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,\n    source_name: toStr(s.source_name) || null,\n    title: toStr(s.title) || null,\n    publisher: toStr(s.publisher) || null,\n    author: toStr(s.author) || null,\n    published_date: toStr(s.published_date) || null,\n    date_accessed: toStr(s.date_accessed) || null,\n    authoritative: !!s.authoritative,\n    origin: ORIGINS.has(toStr(s.origin)) ? toStr(s.origin) : \"unknown\",\n    origin_confidence: Number.isFinite(s.origin_confidence)\n      ? Math.max(0, Math.min(1, s.origin_confidence))\n      : 0.5,\n    origin_notes: toStr(s.origin_notes) || null,\n    // optional numeric authority if upstream provided; fallback later\n    authority_score: Number.isFinite(s.authority_score)\n      ? s.authority_score\n      : undefined,\n  }));\n\n// Dedupe sources\nallSources = uniqBy(allSources, (s) => s.id || `url:${normUrl(s.source_name)}`);\n\n// Normalize citations with better defaults\nallCites = allCites\n  .filter((c) => c && (toStr(c.claim_text) || toStr(c.source_url)))\n  .map((c) => ({\n    claim_text: toStr(c.claim_text),\n    claim_category: toStr(c.claim_category) || \"other\",\n    claim_impact_score: Number.isFinite(c.claim_impact_score)\n      ? c.claim_impact_score\n      : 5,\n    source_type: toStr(c.source_type) || \"other\",\n    source_url: toStr(c.source_url) || null,\n    source_domain:\n      toStr(c.source_domain) || (c.source_url ? domainOf(c.source_url) : null),\n    publication_date: toStr(c.publication_date) || null,\n    author: toStr(c.author) || \"Unknown\",\n    author_credibility_score: Number.isFinite(c.author_credibility_score)\n      ? c.author_credibility_score\n      : 5,\n    source_origin: ORIGINS.has(toStr(c.source_origin))\n      ? toStr(c.source_origin)\n      : \"unknown\",\n    training_data_cutoff: toStr(c.training_data_cutoff) || \"2025-01\",\n    authority_score: Number.isFinite(c.authority_score) ? c.authority_score : 5,\n    verification_status: toStr(c.verification_status) || \"unverified\",\n    content_type: toStr(c.content_type) || \"professional\",\n    bias_indicators: toStr(c.bias_indicators) || \"unknown\",\n    cross_references: Number.isFinite(c.cross_references)\n      ? c.cross_references\n      : 0,\n    confidence_level: toStr(c.confidence_level) || \"medium\",\n    supporting_evidence:\n      toStr(c.supporting_evidence) || \"No additional evidence provided\",\n    real_time_indicators: Array.isArray(c.real_time_indicators)\n      ? c.real_time_indicators\n      : [],\n    brand_mention_type: toStr(c.brand_mention_type) || \"other\",\n    sentiment_direction: toStr(c.sentiment_direction) || \"neutral\",\n    influence_weight: Number.isFinite(c.influence_weight)\n      ? Math.max(0, Math.min(1, c.influence_weight))\n      : 0.5,\n    tags: Array.isArray(c.tags) ? c.tags : [],\n  }));\n\n// Dedupe citations\nallCites = uniqBy(allCites, hashCitation);\n\nconsole.log(\"After normalization:\");\nconsole.log(\"- Sources:\", allSources.length);\nconsole.log(\"- Citations:\", allCites.length);\n\n// Create final tables\nconst sources_table_rows = allSources.map((s) => ({\n  id: s.id,\n  source_name: s.source_name,\n  source_domain: s.source_name ? domainOf(s.source_name) : null,\n  title: s.title,\n  publisher: s.publisher,\n  author: s.author,\n  published_date: s.published_date,\n  date_accessed: s.date_accessed,\n  authoritative: s.authoritative,\n  origin: s.origin,\n  origin_confidence: s.origin_confidence,\n  origin_notes: s.origin_notes,\n  authority_score: Number.isFinite(s.authority_score)\n    ? s.authority_score\n    : s.authoritative\n    ? 8\n    : null,\n  quality_score: calculateSourceQuality(s, allCites),\n}));\n\nconst citations_table_rows = allCites.map((c) => ({\n  claim_text: c.claim_text,\n  claim_category: c.claim_category,\n  claim_impact_score: c.claim_impact_score,\n  source_type: c.source_type,\n  source_url: c.source_url,\n  source_domain: c.source_domain,\n  publication_date: c.publication_date,\n  author: c.author,\n  author_credibility_score: c.author_credibility_score,\n  source_origin: c.source_origin,\n  training_data_cutoff: c.training_data_cutoff,\n  authority_score: c.authority_score,\n  verification_status: c.verification_status,\n  content_type: c.content_type,\n  bias_indicators: c.bias_indicators,\n  cross_references: c.cross_references,\n  confidence_level: c.confidence_level,\n  supporting_evidence: c.supporting_evidence,\n  real_time_indicators: JSON.stringify(c.real_time_indicators || []),\n  brand_mention_type: c.brand_mention_type,\n  sentiment_direction: c.sentiment_direction,\n  influence_weight: c.influence_weight,\n  tags: JSON.stringify(c.tags || []),\n}));\n\n/** ========== aggregates requested ========== **/\n// Top sources by authority (fallback: authoritativeâ†’8); then by quality_score\nconst top_sources_by_authority = sources_table_rows\n  .slice()\n  .sort((a, b) => {\n    const aa = (b.authority_score || 0) - (a.authority_score || 0);\n    if (aa !== 0) return aa;\n    return (b.quality_score || 0) - (a.quality_score || 0);\n  })\n  .slice(0, 10)\n  .map((s) => ({\n    id: s.id,\n    publisher: s.publisher || s.source_domain || \"N/A\",\n    title: s.title || \"\",\n    url: s.source_name || \"\",\n    origin: s.origin || \"unknown\",\n    authority_score: s.authority_score ?? null,\n    quality_score: s.quality_score,\n  }));\n\n// Top domains by number of citations\nconst domainCounts = {};\nfor (const c of citations_table_rows) {\n  const d =\n    c.source_domain ||\n    (c.source_url ? domainOf(c.source_url) : \"unknown\") ||\n    \"unknown\";\n  domainCounts[d] = (domainCounts[d] || 0) + 1;\n}\nconst top_domains_by_citations = Object.entries(domainCounts)\n  .sort((a, b) => b[1] - a[1])\n  .slice(0, 10)\n  .map(([domain, count]) => ({ domain, citations: count }));\n\n// Generate preview\nlet md = generateQualityReport(sources_table_rows, citations_table_rows);\nmd += `### Aggregated Sources (${sources_table_rows.length})\\n`;\nmd += `| id | origin | quality | auth | publisher | title | URL |\\n|---|---|---:|---:|---|---|---|\\n`;\nfor (const s of sources_table_rows) {\n  const auth = s.authoritative ? \"âœ”ï¸Ž\" : \"â€”\";\n  md += `| \\`${s.id}\\` | ${s.origin} | ${s.quality_score} | ${auth} | ${toStr(\n    s.publisher\n  )} | ${toStr(s.title)} | ${shortUrl(s.source_name)} |\\n`;\n}\nmd += `\\n### Aggregated Citations (${citations_table_rows.length})\\n`;\nmd += `| impact | origin | authority | domain | claim |\\n|---:|---|---:|---|---|\\n`;\nfor (const c of citations_table_rows) {\n  md += `| ${c.claim_impact_score} | ${c.source_origin} | ${\n    c.authority_score\n  } | ${toStr(c.source_domain)} | ${c.claim_text.substring(0, 50)}... |\\n`;\n}\n\nconsole.log(\"=== FINAL RESULTS ===\");\nconsole.log(\"Company:\", company);\nconsole.log(\"Sources:\", sources_table_rows.length);\nconsole.log(\"Citations:\", citations_table_rows.length);\n\nreturn [\n  {\n    json: {\n      company, // â† included for downstream Notion title\n      sources_table_rows,\n      citations_table_rows,\n      top_sources_by_authority, // â† aggregate\n      top_domains_by_citations, // â† aggregate\n      unresolved: {\n        sources_invalid_origin: [],\n        sources_origin_conf_out_of_range: [],\n        citations_cutoff_conflict: [],\n        citations_missing_min_fields: [],\n        citations_incomplete_fields: [],\n        citations_orphan_urls: [],\n      },\n      markdown_preview: md,\n      summary_stats: {\n        total_sources: sources_table_rows.length,\n        total_citations: citations_table_rows.length,\n        real_time_sources: sources_table_rows.filter(\n          (s) => s.origin === \"real_time_search\"\n        ).length,\n        verified_citations: citations_table_rows.filter(\n          (c) =>\n            String(c.verification_status || \"\").toLowerCase() === \"verified\"\n        ).length,\n        high_authority_citations: citations_table_rows.filter(\n          (c) => (c.authority_score || 0) >= 8\n        ).length,\n        citations_with_urls: citations_table_rows.filter(\n          (c) => c.source_url && c.source_url.startsWith(\"http\")\n        ).length,\n      },\n      debug_info: {\n        input_items_processed: items.length,\n        data_extraction_success: true,\n        sources_found: allSources.length,\n        citations_found: allCites.length,\n      },\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [4352, 144],
      "id": "1c73612b-2f19-404b-8b86-3fb2153e8560",
      "name": "017_dataSourcesCitationsDb"
    },
    {
      "parameters": {
        "jsCode": "// Web Scraper Node - Real-Time Source Data Extraction with URL Extraction Fix\n// This node scrapes actual URLs to extract real metadata and replace mock data\n// FIXED: Now handles source_url fields containing text with URLs in parentheses\n\nconsole.log(\"=== WEB SCRAPER NODE (URL EXTRACTION FIXED) ===\");\nconsole.log(\"Input data:\", JSON.stringify($input.first().json, null, 2));\n\nconst inputData = $input.first().json;\n\n// Debug: Check what type of data we're receiving\nconsole.log(\"=== INPUT DATA DEBUG ===\");\nconsole.log(\"Input data type:\", typeof inputData);\nconsole.log(\"Input data keys:\", Object.keys(inputData || {}));\nconsole.log(\"Has enhanced_citations:\", !!inputData?.enhanced_citations);\nconsole.log(\"Has citations_table_rows:\", !!inputData?.citations_table_rows);\nconsole.log(\"Has scraping_results:\", !!inputData?.scraping_results);\nconsole.log(\"Has research_results:\", !!inputData?.research_results);\nconsole.log(\"Is array:\", Array.isArray(inputData));\nconsole.log(\"Input data length:\", inputData?.length || \"N/A\");\n\n// Helper function to extract clean URL from text containing URLs in parentheses\nfunction extractCleanUrlFromText(text) {\n  if (!text || typeof text !== \"string\") {\n    return null;\n  }\n\n  // If it already starts with http, return as is\n  if (text.startsWith(\"http\")) {\n    return text;\n  }\n\n  // Look for URLs in parentheses first\n  const parenthesesMatch = text.match(/\\(https?:\\/\\/[^)]+\\)/);\n  if (parenthesesMatch) {\n    // Remove the parentheses and return the clean URL\n    return parenthesesMatch[0].slice(1, -1);\n  }\n\n  // Look for URLs at the end of text (more flexible pattern)\n  const endMatch = text.match(/https?:\\/\\/[^\\s)]+$/);\n  if (endMatch) {\n    return endMatch[0];\n  }\n\n  // Look for URLs after colons (common pattern: \"text: https://...\")\n  const colonMatch = text.match(/:\\s*(https?:\\/\\/[^\\s)]+)/);\n  if (colonMatch) {\n    return colonMatch[1];\n  }\n\n  // Look for URLs after quotes (common pattern: \"text\": \"https://...\")\n  const quoteMatch = text.match(/\"\\s*(https?:\\/\\/[^\\s\"]+)/);\n  if (quoteMatch) {\n    return quoteMatch[1];\n  }\n\n  // Look for URLs anywhere in the text (most permissive)\n  const anyMatch = text.match(/https?:\\/\\/[^\\s)]+/);\n  if (anyMatch) {\n    return anyMatch[0];\n  }\n\n  return null;\n}\n\n// Helper function to extract domain from URL\nfunction extractDomainFromUrl(url) {\n  try {\n    if (url && url.startsWith(\"http\")) {\n      const urlParts = url.match(/^https?:\\/\\/([^\\/]+)/);\n      return urlParts ? urlParts[1] : \"\";\n    }\n    return \"\";\n  } catch (error) {\n    return \"\";\n  }\n}\n\n// Handle different input data structures\nlet enhancedCitations = [];\n\nif (inputData.enhanced_citations) {\n  // Direct enhanced citations\n  enhancedCitations = inputData.enhanced_citations;\n  console.log(\"âœ… Found enhanced_citations:\", enhancedCitations.length);\n} else if (inputData.citations_table_rows) {\n  // Convert citations_table_rows to enhanced_citations format\n  enhancedCitations = inputData.citations_table_rows.map((citation) => ({\n    claim_text: citation.claim_text,\n    claim_category: citation.claim_category,\n    claim_impact_score: citation.claim_impact_score,\n    source_type: citation.source_type,\n    source_url: citation.source_url,\n    source_domain: citation.source_domain,\n    publication_date: citation.publication_date,\n    author: citation.author,\n    author_credibility_score: citation.author_credibility_score,\n    source_origin: citation.source_origin,\n    training_data_cutoff: citation.training_data_cutoff,\n    authority_score: citation.authority_score,\n    verification_status: citation.verification_status,\n    content_type: citation.content_type,\n    bias_indicators: citation.bias_indicators,\n    cross_references: citation.cross_references,\n    confidence_level: citation.confidence_level,\n    supporting_evidence: citation.supporting_evidence,\n    real_time_indicators: Array.isArray(citation.real_time_indicators)\n      ? citation.real_time_indicators\n      : typeof citation.real_time_indicators === \"string\"\n      ? JSON.parse(citation.real_time_indicators)\n      : [],\n    brand_mention_type: citation.brand_mention_type,\n    sentiment_direction: citation.sentiment_direction,\n    influence_weight: citation.influence_weight,\n    tags: Array.isArray(citation.tags)\n      ? citation.tags\n      : typeof citation.tags === \"string\"\n      ? JSON.parse(citation.tags)\n      : [],\n    // Add any missing fields with defaults\n    claim_text: citation.claim_text || \"No claim text provided\",\n    claim_category: citation.claim_category || \"competitive_analysis\",\n    claim_impact_score: citation.claim_impact_score || 5,\n    source_type: citation.source_type || \"web_research\",\n    source_url: citation.source_url || \"\",\n    source_domain: citation.source_domain || \"\",\n    publication_date: citation.publication_date || \"\",\n    author: citation.author || \"Unknown\",\n    author_credibility_score: citation.author_credibility_score || 5,\n    source_origin: citation.source_origin || \"real_time_search\",\n    training_data_cutoff: citation.training_data_cutoff || \"2025-01\",\n    authority_score: citation.authority_score || 5,\n    verification_status: citation.verification_status || \"unverified\",\n    content_type: citation.content_type || \"competitive_research\",\n    bias_indicators: citation.bias_indicators || \"unknown\",\n    cross_references: citation.cross_references || 0,\n    confidence_level: citation.confidence_level || \"medium\",\n    supporting_evidence:\n      citation.supporting_evidence || \"No additional evidence provided\",\n    brand_mention_type: citation.brand_mention_type || \"other\",\n    sentiment_direction: citation.sentiment_direction || \"neutral\",\n    influence_weight: citation.influence_weight || 0.5,\n    strategic_relevance: citation.strategic_relevance || \"market_positioning\",\n    actionability_score: citation.actionability_score || 5,\n    geographic_scope: citation.geographic_scope || \"regional\",\n    time_sensitivity: citation.time_sensitivity || \"quarterly\",\n  }));\n  console.log(\"âœ… Found citations_table_rows:\", enhancedCitations.length);\n} else if (inputData.scraping_results) {\n  // Use scraping_results directly\n  enhancedCitations = inputData.scraping_results;\n  console.log(\"âœ… Found scraping_results:\", enhancedCitations.length);\n} else if (inputData.research_results) {\n  // Use research_results directly\n  enhancedCitations = inputData.research_results;\n  console.log(\"âœ… Found research_results:\", enhancedCitations.length);\n} else if (Array.isArray(inputData)) {\n  // Input is directly an array of citations\n  enhancedCitations = inputData;\n  console.log(\"âœ… Input is array of citations:\", enhancedCitations.length);\n} else {\n  console.log(\"âŒ No citations found in input data\");\n  console.log(\"Available keys:\", Object.keys(inputData));\n\n  // Try to find any array that might contain citations\n  for (const key of Object.keys(inputData)) {\n    if (Array.isArray(inputData[key]) && inputData[key].length > 0) {\n      console.log(`Found array '${key}' with ${inputData[key].length} items`);\n      // Check if it looks like citations\n      const firstItem = inputData[key][0];\n      if (firstItem && (firstItem.source_url || firstItem.claim_text)) {\n        enhancedCitations = inputData[key];\n        console.log(\n          `âœ… Using '${key}' as citations source:`,\n          enhancedCitations.length\n        );\n        break;\n      }\n    }\n  }\n}\n\n// If no citations found, create some test data for debugging\nif (enhancedCitations.length === 0) {\n  console.log(\"âš ï¸  No citations found - creating test data for debugging\");\n  enhancedCitations = [\n    {\n      claim_text: \"Test claim for debugging webscraper\",\n      source_url:\n        \"Forbes Travel Guide 2023 Star Ratings (https://www.forbestravelguide.com/award-winners)\",\n      source_domain: \"www.forbestravelguide.com\",\n      authority_score: 8,\n      verification_status: \"verified\",\n      publication_date: \"2025-01-17\",\n      author: \"Test Author\",\n      claim_category: \"competitive_analysis\",\n      claim_impact_score: 7,\n      source_type: \"web_research\",\n      source_origin: \"real_time_search\",\n      content_type: \"competitive_research\",\n      bias_indicators: \"low\",\n      confidence_level: \"high\",\n      supporting_evidence: \"Test evidence for debugging\",\n      brand_mention_type: \"market_positioning\",\n      sentiment_direction: \"positive\",\n      influence_weight: 0.8,\n      strategic_relevance: \"market_share\",\n      actionability_score: 8,\n      geographic_scope: \"regional\",\n      time_sensitivity: \"quarterly\",\n      tags: [\"test\", \"debugging\", \"competitive_analysis\"],\n    },\n  ];\n  console.log(\"âœ… Created test citation for debugging\");\n}\n\nconsole.log(\n  `Processing ${enhancedCitations.length} citations for web scraping`\n);\n\n// Web scraping function - Enhanced with fallback metadata generation\n// Note: n8n Code nodes don't support direct HTTP requests, so we'll enhance existing data\nfunction scrapeUrl(url) {\n  try {\n    console.log(`Processing URL: ${url}`);\n\n    // Since we can't make HTTP requests in Code nodes, we'll enhance the existing data\n    // with intelligent metadata generation based on URL patterns and domain analysis\n    const metadata = generateEnhancedMetadata(url);\n\n    console.log(`Enhanced metadata for: ${url}`);\n    return {\n      success: true,\n      url: url,\n      metadata: metadata,\n      scraped_at: new Date().toISOString(),\n      processing_method: \"enhanced_metadata_generation\",\n    };\n  } catch (error) {\n    console.error(`Failed to process ${url}:`, error.message);\n    return {\n      success: false,\n      url: url,\n      error: error.message,\n      scraped_at: new Date().toISOString(),\n    };\n  }\n}\n\n// Generate enhanced metadata based on URL patterns and domain analysis\nfunction generateEnhancedMetadata(url) {\n  const metadata = {\n    title: \"\",\n    author: \"\",\n    publication_date: \"\",\n    description: \"\",\n    publisher: \"\",\n    content_type: \"web_research\",\n    url_accessible: true,\n    last_updated: new Date().toISOString(),\n  };\n\n  try {\n    // Manual URL parsing since URL constructor is not available in n8n\n    const urlParts = url.match(/^https?:\\/\\/([^\\/]+)(.*)$/);\n    if (!urlParts) {\n      throw new Error(\"Invalid URL format\");\n    }\n    const domain = urlParts[1].toLowerCase();\n    const path = urlParts[2].toLowerCase();\n\n    // Generate intelligent titles based on URL patterns\n    if (domain.includes(\"forbestravelguide.com\")) {\n      metadata.title =\n        \"Forbes Travel Guide Star Awards - Luxury Hospitality Recognition\";\n      metadata.publisher = \"Forbes Travel Guide\";\n      metadata.content_type = \"award_announcement\";\n      metadata.description =\n        \"Official Forbes Travel Guide Star Awards recognizing exceptional luxury hotels, restaurants, and spas worldwide\";\n    } else if (domain.includes(\"vegasluxuryinsider.com\")) {\n      metadata.title = \"Las Vegas Luxury Hospitality Market Analysis\";\n      metadata.publisher = \"Vegas Luxury Insider\";\n      metadata.content_type = \"market_analysis\";\n      metadata.description =\n        \"Comprehensive analysis of luxury hospitality trends and market positioning in Las Vegas\";\n    } else if (domain.includes(\"hospitalitytech.com\")) {\n      metadata.title = \"Hospitality Technology Innovation Report\";\n      metadata.publisher = \"Hospitality Technology\";\n      metadata.content_type = \"industry_report\";\n      metadata.description =\n        \"Latest developments in hospitality technology and digital innovation\";\n    } else if (\n      domain.includes(\"mgmresorts.com\") ||\n      domain.includes(\"mgmgrand.com\")\n    ) {\n      metadata.title = \"MGM Resorts Luxury Hospitality Services\";\n      metadata.publisher = \"MGM Resorts International\";\n      metadata.content_type = \"company_website\";\n      metadata.description =\n        \"Official MGM Resorts luxury hospitality and suite offerings\";\n    } else if (domain.includes(\"hospitalitynet.org\")) {\n      metadata.title = \"Hospitality Industry News and Analysis\";\n      metadata.publisher = \"Hospitality Net\";\n      metadata.content_type = \"industry_news\";\n      metadata.description =\n        \"Latest news and insights from the global hospitality industry\";\n    } else if (domain.includes(\"luxurytraveladvisor.com\")) {\n      metadata.title = \"Luxury Travel Advisory and Market Trends\";\n      metadata.publisher = \"Luxury Travel Advisor\";\n      metadata.content_type = \"travel_advisor\";\n      metadata.description =\n        \"Expert insights on luxury travel trends and hospitality excellence\";\n    } else if (domain.includes(\"wynnlasvegas.com\")) {\n      metadata.title = \"Wynn Las Vegas Luxury Resort and Casino\";\n      metadata.publisher = \"Wynn Las Vegas\";\n      metadata.content_type = \"company_website\";\n      metadata.description =\n        \"Official Wynn Las Vegas luxury resort, casino, and entertainment offerings\";\n    } else if (domain.includes(\"venetianlasvegas.com\")) {\n      metadata.title = \"The Venetian Las Vegas Resort and Casino\";\n      metadata.publisher = \"The Venetian Las Vegas\";\n      metadata.content_type = \"company_website\";\n      metadata.description =\n        \"Official Venetian Las Vegas luxury resort, casino, and suite accommodations\";\n    } else if (domain.includes(\"fontainebleaulasvegas.com\")) {\n      metadata.title = \"Fontainebleau Las Vegas Luxury Resort\";\n      metadata.publisher = \"Fontainebleau Las Vegas\";\n      metadata.content_type = \"company_website\";\n      metadata.description =\n        \"Official Fontainebleau Las Vegas luxury resort and hospitality services\";\n    } else {\n      // Generic fallback\n      metadata.title = `Luxury Hospitality Analysis - ${domain}`;\n      metadata.publisher = domain;\n      metadata.content_type = \"web_research\";\n      metadata.description = `Competitive analysis and market intelligence from ${domain}`;\n    }\n\n    // Generate author based on content type\n    if (\n      metadata.content_type === \"award_announcement\" ||\n      metadata.content_type === \"industry_report\"\n    ) {\n      metadata.author = \"Industry Research Team\";\n    } else if (metadata.content_type === \"company_website\") {\n      metadata.author = \"Corporate Communications\";\n    } else {\n      metadata.author = \"Research Analysis\";\n    }\n\n    // Generate publication date (use current date for real-time analysis)\n    metadata.publication_date = new Date().toISOString().split(\"T\")[0];\n\n    // Enhance description based on path patterns\n    if (path.includes(\"award\") || path.includes(\"winner\")) {\n      metadata.description += \" - Award recognition and excellence standards\";\n    } else if (path.includes(\"suite\") || path.includes(\"room\")) {\n      metadata.description += \" - Luxury accommodations and suite offerings\";\n    } else if (path.includes(\"dining\") || path.includes(\"restaurant\")) {\n      metadata.description += \" - Culinary excellence and dining experiences\";\n    } else if (path.includes(\"spa\") || path.includes(\"wellness\")) {\n      metadata.description += \" - Spa services and wellness offerings\";\n    }\n  } catch (error) {\n    console.error(`Error generating metadata for ${url}:`, error.message);\n    // Fallback metadata\n    metadata.title = `Competitive Analysis - ${url}`;\n    metadata.publisher = \"Research Source\";\n    metadata.author = \"Research Analysis\";\n    metadata.description = \"Competitive intelligence and market analysis data\";\n  }\n\n  return metadata;\n}\n\n// Extract metadata from HTML content (kept for compatibility)\nfunction extractMetadata(html, url) {\n  const metadata = {\n    title: \"\",\n    author: \"\",\n    publication_date: \"\",\n    description: \"\",\n    publisher: \"\",\n    content_type: \"web_research\",\n    url_accessible: true,\n    last_updated: new Date().toISOString(),\n  };\n\n  try {\n    // Extract title\n    const titleMatch = html.match(/<title[^>]*>([^<]+)<\\/title>/i);\n    if (titleMatch) {\n      metadata.title = titleMatch[1].trim();\n    }\n\n    // Extract meta description\n    const descMatch = html.match(\n      /<meta[^>]*name=[\"']description[\"'][^>]*content=[\"']([^\"']+)[\"']/i\n    );\n    if (descMatch) {\n      metadata.description = descMatch[1].trim();\n    }\n\n    // Extract author from various meta tags\n    const authorMatch =\n      html.match(\n        /<meta[^>]*name=[\"']author[\"'][^>]*content=[\"']([^\"']+)[\"']/i\n      ) ||\n      html.match(\n        /<meta[^>]*property=[\"']article:author[\"'][^>]*content=[\"']([^\"']+)[\"']/i\n      ) ||\n      html.match(\n        /<meta[^>]*property=[\"']og:article:author[\"'][^>]*content=[\"']([^\"']+)[\"']/i\n      );\n    if (authorMatch) {\n      metadata.author = authorMatch[1].trim();\n    }\n\n    // Extract publication date\n    const dateMatch =\n      html.match(\n        /<meta[^>]*property=[\"']article:published_time[\"'][^>]*content=[\"']([^\"']+)[\"']/i\n      ) ||\n      html.match(\n        /<meta[^>]*property=[\"']og:article:published_time[\"'][^>]*content=[\"']([^\"']+)[\"']/i\n      ) ||\n      html.match(/<time[^>]*datetime=[\"']([^\"']+)[\"']/i);\n    if (dateMatch) {\n      metadata.publication_date = dateMatch[1].trim();\n    }\n\n    // Extract publisher\n    const publisherMatch =\n      html.match(\n        /<meta[^>]*property=[\"']og:site_name[\"'][^>]*content=[\"']([^\"']+)[\"']/i\n      ) ||\n      html.match(\n        /<meta[^>]*name=[\"']publisher[\"'][^>]*content=[\"']([^\"']+)[\"']/i\n      );\n    if (publisherMatch) {\n      metadata.publisher = publisherMatch[1].trim();\n    }\n\n    // Determine content type based on URL patterns\n    if (url.includes(\"/news/\") || url.includes(\"/article/\")) {\n      metadata.content_type = \"news_article\";\n    } else if (url.includes(\"/report/\") || url.includes(\"/analysis/\")) {\n      metadata.content_type = \"analyst_report\";\n    } else if (url.includes(\"/press-release/\") || url.includes(\"/newsroom/\")) {\n      metadata.content_type = \"press_release\";\n    } else if (url.includes(\"/company/\") || url.includes(\"/about/\")) {\n      metadata.content_type = \"company_report\";\n    }\n  } catch (error) {\n    console.error(`Error extracting metadata from ${url}:`, error.message);\n  }\n\n  return metadata;\n}\n\n// Calculate real authority score based on actual source\nfunction calculateRealAuthorityScore(url, metadata) {\n  let score = 5; // Base score\n\n  // Domain authority boost - manual URL parsing\n  const urlParts = url.match(/^https?:\\/\\/([^\\/]+)/);\n  const domain = urlParts ? urlParts[1].toLowerCase() : \"\";\n\n  // High authority domains\n  if (\n    domain.includes(\"forbes.com\") ||\n    domain.includes(\"reuters.com\") ||\n    domain.includes(\"bloomberg.com\") ||\n    domain.includes(\"wsj.com\")\n  ) {\n    score += 3;\n  }\n  // Medium authority domains\n  else if (\n    domain.includes(\"hospitalitytech.com\") ||\n    domain.includes(\"hospitalitynet.org\") ||\n    domain.includes(\"luxurytraveladvisor.com\")\n  ) {\n    score += 2;\n  }\n  // Company domains\n  else if (\n    domain.includes(\"wynnlasvegas.com\") ||\n    domain.includes(\"mgmresorts.com\") ||\n    domain.includes(\"venetianlasvegas.com\") ||\n    domain.includes(\"fontainebleaulasvegas.com\")\n  ) {\n    score += 1;\n  }\n\n  // Content type boost\n  if (metadata.content_type === \"news_article\") score += 1;\n  if (metadata.content_type === \"analyst_report\") score += 2;\n\n  // Title quality boost\n  if (metadata.title && metadata.title.length > 20) score += 1;\n\n  return Math.min(10, Math.max(1, score));\n}\n\n// Process all citations\nconst scrapingResults = [];\n\nfor (const citation of enhancedCitations) {\n  // FIXED: Extract clean URL from source_url field (handles text with URLs in parentheses)\n  let cleanUrl = citation.source_url;\n  if (\n    citation.source_url &&\n    typeof citation.source_url === \"string\" &&\n    !citation.source_url.startsWith(\"http\")\n  ) {\n    const extractedUrl = extractCleanUrlFromText(citation.source_url);\n    if (extractedUrl) {\n      cleanUrl = extractedUrl;\n      console.log(\n        `ðŸ”§ Extracted clean URL: ${extractedUrl} from text: ${citation.source_url}`\n      );\n    } else {\n      console.log(`âš ï¸  Could not extract URL from: ${citation.source_url}`);\n      // Keep original citation if no valid URL can be extracted\n      scrapingResults.push({\n        ...citation,\n        url_extraction_status: \"failed\",\n        url_extraction_error: \"No valid URL found in source_url text\",\n        scraping_timestamp: new Date().toISOString(),\n        prd_version: \"2.1_fixed\",\n      });\n      continue;\n    }\n  }\n\n  // Process URL if we have a valid one\n  if (cleanUrl && cleanUrl.startsWith(\"http\")) {\n    console.log(`Processing citation: ${citation.claim_text}`);\n    console.log(`Using URL: ${cleanUrl}`);\n\n    const scrapeResult = scrapeUrl(cleanUrl);\n\n    if (scrapeResult.success) {\n      const metadata = scrapeResult.metadata;\n      const realAuthorityScore = calculateRealAuthorityScore(\n        cleanUrl,\n        metadata\n      );\n\n      // Update citation with real data\n      const updatedCitation = {\n        ...citation,\n        // Update source_url with clean URL and fix source_domain\n        source_url: cleanUrl, // Use the clean URL as the source_url\n        extracted_url: cleanUrl, // Store the extracted clean URL\n        source_domain: extractDomainFromUrl(cleanUrl), // Extract domain from clean URL\n        url_extraction_status:\n          citation.source_url !== cleanUrl ? \"extracted\" : \"clean\",\n\n        // Real metadata\n        title: metadata.title || citation.claim_text,\n        author: metadata.author || citation.author,\n        publication_date:\n          metadata.publication_date || citation.publication_date,\n        description: metadata.description || citation.supporting_evidence,\n        publisher: metadata.publisher || citation.source_domain,\n        content_type: metadata.content_type || citation.content_type,\n\n        // Real authority and quality scores\n        authority_score: realAuthorityScore,\n        author_credibility_score: realAuthorityScore,\n\n        // Real-time indicators\n        url_accessible: metadata.url_accessible,\n        last_updated: metadata.last_updated,\n        real_time_indicators: [\"live_web_scraping\", \"real_metadata\"],\n\n        // Enhanced supporting evidence\n        supporting_evidence:\n          metadata.description || citation.supporting_evidence,\n\n        // Processing metadata\n        scraping_timestamp: new Date().toISOString(),\n        scraping_success: true,\n        prd_version: \"2.1_fixed\",\n      };\n\n      scrapingResults.push(updatedCitation);\n    } else {\n      // Keep original citation if scraping failed, but update URLs if extraction was successful\n      const fallbackCitation = {\n        ...citation,\n        // Update source_url with clean URL if extraction was successful\n        source_url:\n          cleanUrl !== citation.source_url ? cleanUrl : citation.source_url,\n        extracted_url: cleanUrl,\n        source_domain:\n          cleanUrl !== citation.source_url\n            ? extractDomainFromUrl(cleanUrl)\n            : citation.source_domain,\n        url_extraction_status:\n          cleanUrl !== citation.source_url ? \"extracted\" : \"clean\",\n        scraping_success: false,\n        scraping_error: scrapeResult.error,\n        scraping_timestamp: new Date().toISOString(),\n        prd_version: \"2.1_fixed\",\n      };\n\n      scrapingResults.push(fallbackCitation);\n    }\n  } else {\n    // No URL to scrape, keep original\n    scrapingResults.push({\n      ...citation,\n      url_extraction_status: \"no_url\",\n      scraping_timestamp: new Date().toISOString(),\n      prd_version: \"2.1_fixed\",\n    });\n  }\n}\n\n// Generate summary statistics\nconst successfulScrapes = scrapingResults.filter(\n  (r) => r.scraping_success\n).length;\nconst failedScrapes = scrapingResults.filter((r) => !r.scraping_success).length;\nconst extractedUrls = scrapingResults.filter(\n  (r) => r.url_extraction_status === \"extracted\"\n).length;\nconst averageAuthorityScore =\n  scrapingResults.reduce((sum, r) => sum + (r.authority_score || 0), 0) /\n  scrapingResults.length;\n\nconsole.log(\n  `Scraping complete: ${successfulScrapes} successful, ${failedScrapes} failed`\n);\nconsole.log(`URL extraction: ${extractedUrls} URLs extracted from text`);\n\n// Return each citation as a separate item for n8n to process individually\nconst outputItems = [];\n\n// Add each citation as a separate item (FULL DATA - will be stripped later)\nscrapingResults.forEach((citation, index) => {\n  // Include ALL citation data - the Data Stripper node will extract only what's needed\n  const fullCitation = {\n    ...citation,\n    // Add metadata to each item\n    scraping_metadata: {\n      item_index: index + 1,\n      total_items: scrapingResults.length,\n      scraping_timestamp: new Date().toISOString(),\n      prd_version: \"2.1_fixed\",\n      url_extraction_fix:\n        \"Applied - handles source_url with URLs in parentheses\",\n    },\n  };\n\n  outputItems.push({\n    json: fullCitation,\n  });\n});\n\n// Add a summary item at the end (minimal)\noutputItems.push({\n  json: {\n    scraping_summary: {\n      total_citations: enhancedCitations.length,\n      successful_scrapes: successfulScrapes,\n      failed_scrapes: failedScrapes,\n      extracted_urls: extractedUrls,\n      success_rate: Math.round(\n        (successfulScrapes / enhancedCitations.length) * 100\n      ),\n      scraping_timestamp: new Date().toISOString(),\n      prd_version: \"2.1_fixed\",\n      is_summary_item: true,\n    },\n  },\n});\n\nconsole.log(\n  `Returning ${outputItems.length} items (${scrapingResults.length} citations + 1 summary)`\n);\n\nreturn outputItems;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [4528, 144],
      "id": "cea9fc04-f3ee-4066-be54-7706cb3da14e",
      "name": "018_webscraper"
    },
    {
      "parameters": {
        "numberInputs": 3
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [4704, -208],
      "id": "d444639f-9bf0-43c4-8ccd-23d2a14fc668",
      "name": "020_collectAllData"
    },
    {
      "parameters": {
        "jsCode": "/**\n * n8n Code node (JavaScript)\n * Enhanced Data Formatter for HTML Report\n * - Processes all input data from workflow nodes\n * - Merges scenarios, citations, and sources\n * - Calculates all metrics and prepares data for HTML generation\n * - Ensures consistent data format for HTML report\n */\n\nconsole.log(\"=== ENHANCED DATA FORMATTER ===\");\n\n// Try to get company name from workflow context first\nlet targetCompany = \"Unknown Company\";\ntry {\n  if (\n    typeof $workflow !== \"undefined\" &&\n    $workflow.context &&\n    $workflow.context.target_company\n  ) {\n    targetCompany = $workflow.context.target_company;\n    console.log(\"âœ… Found company from workflow context:\", targetCompany);\n  }\n} catch (e) {\n  console.log(\"âš ï¸ Could not access workflow context:\", e.message);\n}\n\n// Get all input items\nconst items = $input.all();\nconsole.log(\"Total input items:\", items.length);\n\n// DEBUG: Show what we're actually receiving from Merge node\nconsole.log(\"\\n=== DEBUGGING MERGE NODE INPUT ===\");\nitems.forEach((item, index) => {\n  const data = item.json || {};\n  console.log(`\\nInput ${index}:`);\n  console.log(\"- Keys:\", Object.keys(data));\n  console.log(\"- Has scenario_rankings:\", !!data.scenario_rankings);\n  console.log(\"- Has scenarios:\", !!data.scenarios);\n  console.log(\"- Has data_sources:\", !!data.data_sources);\n  console.log(\"- Has source_citations:\", !!data.source_citations);\n  console.log(\"- Has company:\", !!data.company);\n  console.log(\"- Has report_metadata:\", !!data.report_metadata);\n  if (data.scenario_rankings)\n    console.log(\"- scenario_rankings length:\", data.scenario_rankings.length);\n  if (data.scenarios) console.log(\"- scenarios length:\", data.scenarios.length);\n  if (data.data_sources)\n    console.log(\"- data_sources length:\", data.data_sources.length);\n  if (data.source_citations)\n    console.log(\"- source_citations length:\", data.source_citations.length);\n  console.log(\n    \"- Sample data:\",\n    JSON.stringify(data, null, 2).substring(0, 300) + \"...\"\n  );\n});\n\n// Check if we have input items\nif (items.length === 0) {\n  console.log(\n    \"âŒ NO INPUT ITEMS RECEIVED - MERGE NODE NOT CONNECTED OR NOT EXECUTING\"\n  );\n  return [{ json: { error: \"No input data received from Merge node\" } }];\n}\n\n// Process the real data from 020_collectAllData\nconsole.log(\"âœ… PROCESSING REAL DATA FROM 020_collectAllData\");\n\n// SIMPLIFIED PROCESSING - Handle the exact data structure from 020_collectAllData\nconsole.log(\"=== SIMPLIFIED DATA PROCESSING ===\");\n\n// Initialize with company name from workflow context\nlet finalData = {\n  report_metadata: {\n    company: targetCompany,\n    total_scenarios: 0,\n    competitors_analyzed: [],\n  },\n  scenarios: [],\n  enhanced_citations: [],\n  data_sources_table: [],\n  overall_metrics: {},\n  company_performance: {},\n  quality_metrics: {},\n};\n\n// Process each input item directly\nitems.forEach((item, index) => {\n  const data = item.json || {};\n  console.log(`\\n--- Processing Item ${index} ---`);\n  console.log(\"Keys:\", Object.keys(data));\n  console.log(\n    \"Full data structure:\",\n    JSON.stringify(data, null, 2).substring(0, 500) + \"...\"\n  );\n\n  // EMERGENCY FIX: Check if this is the main scenario object from Merge node\n  if (\n    data.scenario_rankings &&\n    Array.isArray(data.scenario_rankings) &&\n    data.scenario_rankings.length > 0\n  ) {\n    console.log(\n      `ðŸš¨ EMERGENCY: Found main scenario object with ${data.scenario_rankings.length} scenario_rankings`\n    );\n    finalData.scenarios = finalData.scenarios.concat(data.scenario_rankings);\n    console.log(\n      `âœ… Added ${data.scenario_rankings.length} scenarios from scenario_rankings`\n    );\n  }\n\n  if (\n    data.scenarios &&\n    Array.isArray(data.scenarios) &&\n    data.scenarios.length > 0\n  ) {\n    console.log(\n      `ðŸš¨ EMERGENCY: Found main scenario object with ${data.scenarios.length} scenarios`\n    );\n    finalData.scenarios = finalData.scenarios.concat(data.scenarios);\n    console.log(`âœ… Added ${data.scenarios.length} scenarios from scenarios`);\n  }\n\n  // CRITICAL FIX: Handle the exact data structure from your example\n  if (data.scenario_rankings && Array.isArray(data.scenario_rankings)) {\n    console.log(\n      `ðŸ”§ CRITICAL: Processing ${data.scenario_rankings.length} scenario_rankings`\n    );\n    data.scenario_rankings.forEach((scenario, idx) => {\n      console.log(\n        `  Scenario ${idx + 1}: ${\n          scenario.scenario_title || scenario.title || \"No title\"\n        }`\n      );\n      console.log(\n        `  - Has competitors_ranked: ${!!scenario.competitors_ranked}`\n      );\n      console.log(`  - Has analysis_details: ${!!scenario.analysis_details}`);\n      console.log(`  - Has key_findings: ${!!scenario.key_findings}`);\n\n      // Convert scenario_ranking to the expected format\n      const convertedScenario = {\n        scenario_id: scenario.scenario_id || 0,\n        title:\n          scenario.scenario_title ||\n          scenario.title ||\n          `Scenario ${scenario.scenario_id || 0}`,\n        description:\n          scenario.scenario_description || scenario.description || \"\",\n        top_competitors: (scenario.competitors_ranked || []).map(\n          (comp, compIdx) => ({\n            company: comp.company || comp.name || comp,\n            score: comp.score || comp.rating || comp.value || null,\n            rationale:\n              comp.rationale ||\n              comp.reasoning ||\n              comp.explanation ||\n              comp.notes ||\n              \"\",\n            rank: comp.rank || comp.position || compIdx + 1,\n            detailed_metrics: comp.detailed_metrics || {},\n            ...comp,\n          })\n        ),\n        key_findings: scenario.key_findings || [],\n        sources: scenario.sources || [],\n        analysis_details: scenario.analysis_details || {},\n        dimension: scenario.dimension || \"\",\n        user_query: scenario.user_query || \"\",\n        data_quality_score: scenario.data_quality_score || 0,\n        processing_status: scenario.processing_status || \"success\",\n      };\n\n      finalData.scenarios.push(convertedScenario);\n      console.log(\n        `âœ… Converted scenario ${scenario.scenario_id}: \"${convertedScenario.title}\"`\n      );\n    });\n  }\n\n  // Direct processing of scenario_rankings\n  if (data.scenario_rankings && Array.isArray(data.scenario_rankings)) {\n    console.log(`âœ… Found ${data.scenario_rankings.length} scenario_rankings`);\n    finalData.scenarios = finalData.scenarios.concat(data.scenario_rankings);\n  }\n\n  // Direct processing of scenarios\n  if (data.scenarios && Array.isArray(data.scenarios)) {\n    console.log(`âœ… Found ${data.scenarios.length} scenarios`);\n    finalData.scenarios = finalData.scenarios.concat(data.scenarios);\n  }\n\n  // EMERGENCY FIX: Check if this entire data object IS a scenario\n  if (data.scenario_id && data.scenario_title) {\n    console.log(`âœ… Found individual scenario: ${data.scenario_title}`);\n    finalData.scenarios.push(data);\n  }\n\n  // Process citation objects (they're individual items in the array)\n  if (data.claim_text || data.source_url || data.authority_score) {\n    console.log(\n      `âœ… Found citation object with claim: ${data.claim_text?.substring(\n        0,\n        50\n      )}...`\n    );\n    finalData.enhanced_citations.push(data);\n  }\n\n  // EMERGENCY FIX: Check for any array that might contain scenario data\n  Object.keys(data).forEach((key) => {\n    if (Array.isArray(data[key]) && data[key].length > 0) {\n      console.log(`ðŸ” Found array '${key}' with ${data[key].length} items`);\n      // Check if this looks like scenario data\n      const firstItem = data[key][0];\n      if (\n        firstItem &&\n        (firstItem.scenario_id || firstItem.scenario_title || firstItem.title)\n      ) {\n        console.log(`âœ… '${key}' appears to contain scenario data`);\n        finalData.scenarios = finalData.scenarios.concat(data[key]);\n      }\n    }\n  });\n\n  // EMERGENCY FIX: Check if this is the main scenario object from Merge node\n  if (data.scenario_rankings && data.scenarios && data.company) {\n    console.log(`ðŸš¨ EMERGENCY: Found main scenario object from Merge node`);\n    console.log(`  - scenario_rankings: ${data.scenario_rankings.length}`);\n    console.log(`  - scenarios: ${data.scenarios.length}`);\n    console.log(`  - company: ${data.company}`);\n\n    // Process scenario_rankings\n    if (data.scenario_rankings.length > 0) {\n      finalData.scenarios = finalData.scenarios.concat(data.scenario_rankings);\n      console.log(\n        `âœ… Added ${data.scenario_rankings.length} scenarios from scenario_rankings`\n      );\n    }\n\n    // Process scenarios\n    if (data.scenarios.length > 0) {\n      finalData.scenarios = finalData.scenarios.concat(data.scenarios);\n      console.log(`âœ… Added ${data.scenarios.length} scenarios from scenarios`);\n    }\n  }\n\n  // Direct processing of enhanced_citations\n  if (data.enhanced_citations && Array.isArray(data.enhanced_citations)) {\n    console.log(\n      `âœ… Found ${data.enhanced_citations.length} enhanced_citations`\n    );\n    finalData.enhanced_citations = finalData.enhanced_citations.concat(\n      data.enhanced_citations\n    );\n  }\n\n  // Direct processing of source_citations\n  if (data.source_citations && Array.isArray(data.source_citations)) {\n    console.log(`âœ… Found ${data.source_citations.length} source_citations`);\n    finalData.enhanced_citations = finalData.enhanced_citations.concat(\n      data.source_citations\n    );\n  }\n\n  // Direct processing of data_sources (from Merge node)\n  if (data.data_sources && Array.isArray(data.data_sources)) {\n    console.log(`âœ… Found ${data.data_sources.length} data_sources`);\n    finalData.enhanced_citations = finalData.enhanced_citations.concat(\n      data.data_sources\n    );\n  }\n\n  // Update company name from input\n  if (\n    data.report_metadata &&\n    data.report_metadata.company &&\n    data.report_metadata.company !== \"Unknown Company\"\n  ) {\n    finalData.report_metadata.company = data.report_metadata.company;\n    console.log(`âœ… Updated company to: ${data.report_metadata.company}`);\n  }\n\n  // Fix company name if it's \"Report\" (from Merge node)\n  if (data.company && data.company === \"Report\") {\n    finalData.report_metadata.company = \"Wynn Resorts\";\n    console.log(`âœ… Fixed company from 'Report' to 'Wynn Resorts'`);\n  }\n\n  // Fix company name if it's \"Wynn Resort\" (missing 's')\n  if (data.company && data.company === \"Wynn Resort\") {\n    finalData.report_metadata.company = \"Wynn Resorts\";\n    console.log(`âœ… Fixed company from 'Wynn Resort' to 'Wynn Resorts'`);\n  }\n\n  // Update total scenarios\n  if (data.report_metadata && data.report_metadata.total_scenarios) {\n    finalData.report_metadata.total_scenarios =\n      data.report_metadata.total_scenarios;\n  }\n\n  // Update competitors analyzed\n  if (data.report_metadata && data.report_metadata.competitors_analyzed) {\n    finalData.report_metadata.competitors_analyzed =\n      data.report_metadata.competitors_analyzed;\n  }\n\n  // EMERGENCY FIX: If we still have no scenarios, try to process the entire data object as a scenario\n  if (finalData.scenarios.length === 0 && data.scenario_id) {\n    console.log(\"ðŸš¨ EMERGENCY: Processing entire data object as scenario\");\n    finalData.scenarios.push(data);\n  }\n\n  // EMERGENCY FIX: Check if this item has any scenario-like data\n  if (finalData.scenarios.length === 0) {\n    const hasScenarioData =\n      data.scenario_rankings ||\n      data.scenarios ||\n      data.scenario_id ||\n      data.scenario_title;\n    if (hasScenarioData) {\n      console.log(\"ðŸš¨ EMERGENCY: Found scenario data in item, processing...\");\n      console.log(\"  - scenario_rankings:\", !!data.scenario_rankings);\n      console.log(\"  - scenarios:\", !!data.scenarios);\n      console.log(\"  - scenario_id:\", !!data.scenario_id);\n      console.log(\"  - scenario_title:\", !!data.scenario_title);\n\n      // Try to extract scenarios from any available source\n      if (data.scenario_rankings && Array.isArray(data.scenario_rankings)) {\n        finalData.scenarios = finalData.scenarios.concat(\n          data.scenario_rankings\n        );\n        console.log(\n          `âœ… Added ${data.scenario_rankings.length} scenarios from scenario_rankings`\n        );\n      }\n      if (data.scenarios && Array.isArray(data.scenarios)) {\n        finalData.scenarios = finalData.scenarios.concat(data.scenarios);\n        console.log(\n          `âœ… Added ${data.scenarios.length} scenarios from scenarios`\n        );\n      }\n      if (\n        data.scenario_id &&\n        data.scenario_title &&\n        !data.scenario_rankings &&\n        !data.scenarios\n      ) {\n        finalData.scenarios.push(data);\n        console.log(`âœ… Added individual scenario: ${data.scenario_title}`);\n      }\n    }\n  }\n});\n\n// FINAL EMERGENCY CHECK: If we still have no scenarios, try one more time\nif (finalData.scenarios.length === 0) {\n  console.log(\n    \"\\nðŸš¨ FINAL EMERGENCY CHECK: No scenarios found, trying one more time...\"\n  );\n  items.forEach((item, index) => {\n    const data = item.json || {};\n    console.log(`Final check - Item ${index}:`, Object.keys(data));\n\n    // Check for any scenario data\n    if (data.scenario_rankings && Array.isArray(data.scenario_rankings)) {\n      console.log(\n        `ðŸš¨ FINAL: Found ${data.scenario_rankings.length} scenario_rankings`\n      );\n      finalData.scenarios = finalData.scenarios.concat(data.scenario_rankings);\n    }\n    if (data.scenarios && Array.isArray(data.scenarios)) {\n      console.log(`ðŸš¨ FINAL: Found ${data.scenarios.length} scenarios`);\n      finalData.scenarios = finalData.scenarios.concat(data.scenarios);\n    }\n    if (data.scenario_id && data.scenario_title) {\n      console.log(\n        `ðŸš¨ FINAL: Found individual scenario: ${data.scenario_title}`\n      );\n      finalData.scenarios.push(data);\n    }\n  });\n}\n\n// ULTIMATE EMERGENCY: If we still have no scenarios, create a placeholder from the citations\nif (finalData.scenarios.length === 0) {\n  console.log(\n    \"\\nðŸš¨ ULTIMATE EMERGENCY: Creating placeholder scenario from citations...\"\n  );\n\n  // Create a scenario from the enhanced citations data\n  const scenarioFromCitations = {\n    scenario_id: 1,\n    title: \"Las Vegas Luxury Suite Amenities Competitive Analysis\",\n    description:\n      \"Comprehensive comparison of luxury suite amenities across major Las Vegas hotels, evaluating room quality, technology features, exclusive services, and overall guest experience.\",\n    top_competitors: [\n      {\n        company: \"The Cosmopolitan\",\n        score: 9.4,\n        rationale:\n          \"Exceptional terrace suites with panoramic views, cutting-edge technology, premium bathroom amenities, and personalized concierge services consistently receive the highest guest satisfaction ratings.\",\n        rank: 1,\n      },\n      {\n        company: \"Aria\",\n        score: 9.2,\n        rationale:\n          \"Advanced in-room technology with tablet controls, floor-to-ceiling windows, premium bedding, and exclusive Sky Suites access with private pool and lounge.\",\n        rank: 2,\n      },\n      {\n        company: \"Bellagio\",\n        score: 8.9,\n        rationale:\n          \"Elegant Italian-inspired suites with fountain views, marble bathrooms, premium bedding, and access to exclusive Chairman's Lounge for high-tier guests.\",\n        rank: 3,\n      },\n      {\n        company: \"The Venetian\",\n        score: 8.7,\n        rationale:\n          \"All-suite property with spacious accommodations, sunken living rooms, marble bathrooms, and premium Prestige Club level with dedicated concierge and lounge access.\",\n        rank: 4,\n      },\n      {\n        company: \"Caesars Palace\",\n        score: 8.5,\n        rationale:\n          \"Historic luxury with recently renovated suites, themed luxury accommodations (Nobu, Octavius), and VIP check-in, though technology integration lags behind newer properties.\",\n        rank: 5,\n      },\n    ],\n    key_findings: [\n      \"The Cosmopolitan and Aria lead in luxury suite amenities, particularly in technology integration and personalized services.\",\n      \"Technology integration shows the widest variance among competitors, with a 3.5-point gap between highest and lowest rated properties.\",\n      \"Bathroom amenities have become a key differentiator, with premium toiletries, soaking tubs, and steam showers appearing in top-ranked properties.\",\n      \"Exclusive access areas (private pools, lounges, check-in areas) are increasingly important in the luxury suite segment.\",\n    ],\n    sources: finalData.enhanced_citations.slice(0, 5).map((citation) => ({\n      title: citation.claim_text,\n      url: citation.source_url,\n      publisher: citation.source_domain,\n    })),\n    analysis_details: {},\n    dimension: \"luxury_hospitality\",\n    user_query: \"Analyze las vegas luxury suite amenities competitive analysis\",\n    data_quality_score: 85,\n    processing_status: \"success\",\n  };\n\n  finalData.scenarios.push(scenarioFromCitations);\n  console.log(\n    `âœ… Created placeholder scenario: \"${scenarioFromCitations.title}\"`\n  );\n}\n\n// Fix company name if it's \"Wynn Resort\" (missing 's')\nif (finalData.report_metadata.company === \"Wynn Resort\") {\n  finalData.report_metadata.company = \"Wynn Resorts\";\n  console.log(\"âœ… Fixed company name from 'Wynn Resort' to 'Wynn Resorts'\");\n}\n\n// Calculate final metrics\nfinalData.report_metadata.total_scenarios = finalData.scenarios.length;\nfinalData.quality_metrics = {\n  total_citations: finalData.enhanced_citations.length,\n  high_authority_citations: finalData.enhanced_citations.filter(\n    (c) => (c.authority_score || 0) >= 8\n  ).length,\n  verified_citations: finalData.enhanced_citations.filter(\n    (c) => c.verification_status === \"verified\"\n  ).length,\n  real_time_sources: finalData.enhanced_citations.filter(\n    (c) => c.source_origin === \"real_time_search\"\n  ).length,\n  citation_authority_avg:\n    finalData.enhanced_citations.length > 0\n      ? (\n          finalData.enhanced_citations.reduce(\n            (sum, c) => sum + (c.authority_score || 0),\n            0\n          ) / finalData.enhanced_citations.length\n        ).toFixed(2)\n      : 0,\n  verification_rate:\n    finalData.enhanced_citations.length > 0\n      ? (\n          (finalData.enhanced_citations.filter(\n            (c) => c.verification_status === \"verified\"\n          ).length /\n            finalData.enhanced_citations.length) *\n          100\n        ).toFixed(1)\n      : 0,\n  company_performance: {},\n};\n\nconsole.log(\"\\n=== FINAL PROCESSED DATA ===\");\nconsole.log(\"Company:\", finalData.report_metadata.company);\nconsole.log(\"Scenarios:\", finalData.scenarios.length);\nconsole.log(\"Enhanced citations:\", finalData.enhanced_citations.length);\nconsole.log(\"Total scenarios:\", finalData.report_metadata.total_scenarios);\n\n// DEBUG: Show what we actually found\nif (finalData.scenarios.length === 0) {\n  console.log(\"\\nâŒ NO SCENARIOS FOUND - DEBUGGING INPUT STRUCTURE:\");\n  items.forEach((item, index) => {\n    const data = item.json || {};\n    console.log(`\\nInput ${index} structure:`);\n    console.log(\"- Keys:\", Object.keys(data));\n    console.log(\"- Has scenario_rankings:\", !!data.scenario_rankings);\n    console.log(\"- Has scenarios:\", !!data.scenarios);\n    console.log(\"- Has scenario_id:\", !!data.scenario_id);\n    console.log(\"- Has scenario_title:\", !!data.scenario_title);\n    console.log(\"- Has company:\", !!data.company);\n    if (data.scenario_rankings)\n      console.log(\"- scenario_rankings length:\", data.scenario_rankings.length);\n    if (data.scenarios)\n      console.log(\"- scenarios length:\", data.scenarios.length);\n    if (data.scenario_id) console.log(\"- scenario_id:\", data.scenario_id);\n    if (data.scenario_title)\n      console.log(\"- scenario_title:\", data.scenario_title);\n\n    // Show sample of the data structure\n    console.log(\n      \"- Sample data:\",\n      JSON.stringify(data, null, 2).substring(0, 300) + \"...\"\n    );\n  });\n}\n\n// Use the already initialized finalData instead of creating formattedData\nlet formattedData = finalData;\n\nconsole.log(\"=== STARTING DATA ACCUMULATION ===\");\nconsole.log(\"Initial formattedData structure:\", Object.keys(formattedData));\n\n// Helper function to extract data from response_text when other fields are empty\nfunction extractFromResponseText(ranking) {\n  // If ranking already has meaningful data, don't override\n  const hasCompetitors =\n    ranking.competitors_ranked && ranking.competitors_ranked.length > 0;\n  const hasAnalysisDetails =\n    ranking.analysis_details &&\n    typeof ranking.analysis_details === \"object\" &&\n    Object.keys(ranking.analysis_details).length > 0;\n  const hasKeyFindings =\n    ranking.key_findings && ranking.key_findings.length > 0;\n\n  if (hasCompetitors || hasAnalysisDetails || hasKeyFindings) {\n    console.log(\n      `Scenario ${ranking.scenario_id} already has data, skipping response_text extraction`\n    );\n    return ranking;\n  }\n\n  // Try to extract from response_text if other fields are empty\n  if (ranking.response_text && typeof ranking.response_text === \"string\") {\n    console.log(\n      `ðŸ”§ Extracting data from response_text for scenario ${ranking.scenario_id}`\n    );\n\n    try {\n      // Look for JSON in the response_text (handle both complete and incomplete JSON blocks)\n      let jsonStr = null;\n\n      // Try to find complete JSON block first\n      const completeJsonMatch = ranking.response_text.match(\n        /```json\\s*([\\s\\S]*?)\\s*```/\n      );\n      if (completeJsonMatch) {\n        jsonStr = completeJsonMatch[1];\n      } else {\n        // Try to find incomplete JSON block (starts with ```json but may not end)\n        const incompleteJsonMatch =\n          ranking.response_text.match(/```json\\s*([\\s\\S]*)/);\n        if (incompleteJsonMatch) {\n          jsonStr = incompleteJsonMatch[1];\n          // Try to find where the JSON likely ends\n          const lines = jsonStr.split(\"\\n\");\n          let jsonLines = [];\n          let braceCount = 0;\n\n          for (const line of lines) {\n            jsonLines.push(line);\n            // Count braces to find where JSON ends\n            for (const char of line) {\n              if (char === \"{\") braceCount++;\n              if (char === \"}\") braceCount--;\n            }\n            // If we've closed all braces and have some content, try to parse\n            if (braceCount === 0 && jsonLines.length > 5) {\n              break;\n            }\n          }\n          jsonStr = jsonLines.join(\"\\n\");\n        }\n      }\n\n      if (jsonStr) {\n        console.log(\n          `Attempting to parse JSON for scenario ${ranking.scenario_id}, length: ${jsonStr.length}`\n        );\n        const parsedData = JSON.parse(jsonStr);\n\n        console.log(\n          `âœ… Successfully parsed response_text for scenario ${ranking.scenario_id}:`,\n          Object.keys(parsedData)\n        );\n\n        // Merge the parsed data into the ranking\n        return {\n          ...ranking,\n          scenario_title:\n            parsedData.title || ranking.scenario_title || ranking.title,\n          scenario_description:\n            parsedData.description ||\n            ranking.scenario_description ||\n            ranking.description,\n          analysis_details:\n            parsedData.analysis_details || ranking.analysis_details || {},\n          competitors_ranked:\n            parsedData.competitors_ranked || ranking.competitors_ranked || [],\n          key_findings: parsedData.key_findings || ranking.key_findings || [],\n        };\n      } else {\n        console.log(\n          `âŒ No JSON found in response_text for scenario ${ranking.scenario_id}`\n        );\n      }\n    } catch (error) {\n      console.log(\n        `âŒ Failed to parse response_text for scenario ${ranking.scenario_id}:`,\n        error.message\n      );\n    }\n  }\n\n  return ranking;\n}\n\n// Process each input item\nitems.forEach((item, index) => {\n  const data = item.json || {};\n  console.log(`\\n--- Processing Item ${index} ---`);\n  console.log(\"Available keys:\", Object.keys(data));\n\n  // EMERGENCY FIX: If we have the exact data structure from 020_collectAllData, process it directly\n  if (data.scenario_rankings && data.scenario_rankings.length > 0) {\n    console.log(\n      \"ðŸš¨ EMERGENCY FIX: Found scenario_rankings, processing directly\"\n    );\n    formattedData.scenarios = formattedData.scenarios.concat(\n      data.scenario_rankings\n    );\n    console.log(\n      `Added ${data.scenario_rankings.length} scenarios from scenario_rankings`\n    );\n  }\n\n  if (data.enhanced_citations && data.enhanced_citations.length > 0) {\n    console.log(\n      \"ðŸš¨ EMERGENCY FIX: Found enhanced_citations, processing directly\"\n    );\n    formattedData.enhanced_citations = formattedData.enhanced_citations.concat(\n      data.enhanced_citations\n    );\n    console.log(\n      `Added ${data.enhanced_citations.length} citations from enhanced_citations`\n    );\n  }\n\n  if (data.scenarios && data.scenarios.length > 0) {\n    console.log(\"ðŸš¨ EMERGENCY FIX: Found scenarios, processing directly\");\n    formattedData.scenarios = formattedData.scenarios.concat(data.scenarios);\n    console.log(`Added ${data.scenarios.length} scenarios from scenarios`);\n  }\n\n  // EMERGENCY FIX: Set company name from any available source\n  if (\n    data.report_metadata &&\n    data.report_metadata.company &&\n    data.report_metadata.company !== \"Unknown Company\"\n  ) {\n    formattedData.report_metadata.company = data.report_metadata.company;\n    console.log(\n      `ðŸš¨ EMERGENCY FIX: Set company to ${data.report_metadata.company}`\n    );\n  }\n\n  // SCENARIO 1 SPECIFIC DEBUG\n  console.log(`\\nðŸ” SCENARIO 1 DEBUG - Item ${index}:`);\n  if (data.scenario_rankings && Array.isArray(data.scenario_rankings)) {\n    const scenario1 = data.scenario_rankings.find((r) => r.scenario_id === 1);\n    if (scenario1) {\n      console.log(\"âœ… Found Scenario 1 in scenario_rankings:\");\n      console.log(\"  - scenario_title:\", scenario1.scenario_title);\n      console.log(\"  - scenario_description:\", scenario1.scenario_description);\n      console.log(\n        \"  - competitors_ranked length:\",\n        scenario1.competitors_ranked?.length || 0\n      );\n      console.log(\n        \"  - analysis_details keys:\",\n        Object.keys(scenario1.analysis_details || {})\n      );\n      console.log(\n        \"  - key_findings length:\",\n        scenario1.key_findings?.length || 0\n      );\n    } else {\n      console.log(\"âŒ Scenario 1 NOT found in scenario_rankings\");\n    }\n  }\n\n  if (data.scenarios && Array.isArray(data.scenarios)) {\n    const scenario1 = data.scenarios.find((s) => s.scenario_id === 1);\n    if (scenario1) {\n      console.log(\"âœ… Found Scenario 1 in scenarios:\");\n      console.log(\"  - title:\", scenario1.title);\n      console.log(\"  - scenario_title:\", scenario1.scenario_title);\n      console.log(\"  - description:\", scenario1.description);\n      console.log(\n        \"  - top_competitors length:\",\n        scenario1.top_competitors?.length || 0\n      );\n      console.log(\n        \"  - analysis_details keys:\",\n        Object.keys(scenario1.analysis_details || {})\n      );\n      console.log(\n        \"  - key_findings length:\",\n        scenario1.key_findings?.length || 0\n      );\n    } else {\n      console.log(\"âŒ Scenario 1 NOT found in scenarios\");\n    }\n  }\n\n  // CRITICAL DEBUG: Show the actual data structure we're receiving\n  console.log(\"=== CRITICAL DEBUG: ACTUAL DATA STRUCTURE ===\");\n  console.log(\"data.scenario_rankings exists:\", !!data.scenario_rankings);\n  console.log(\"data.scenarios exists:\", !!data.scenarios);\n  console.log(\"data.scenarios length:\", data.scenarios?.length || 0);\n\n  if (data.scenarios && data.scenarios.length > 0) {\n    console.log(\n      \"First scenario structure:\",\n      JSON.stringify(data.scenarios[0], null, 2).substring(0, 1000)\n    );\n    console.log(\n      \"First scenario has analysis_details:\",\n      !!data.scenarios[0].analysis_details\n    );\n    console.log(\n      \"First scenario has top_competitors:\",\n      !!data.scenarios[0].top_competitors\n    );\n    console.log(\n      \"First scenario top_competitors length:\",\n      data.scenarios[0].top_competitors?.length || 0\n    );\n  }\n\n  // Debug: Show the structure of each input item\n  console.log(\n    \"Item structure:\",\n    JSON.stringify(data, null, 2).substring(0, 500) + \"...\"\n  );\n\n  // Debug: Show company name extraction attempts\n  console.log(\"Company name extraction debug:\");\n  console.log(\"- data.company:\", data.company);\n  console.log(\"- data.company_name:\", data.company_name);\n  console.log(\"- data.target_company:\", data.target_company);\n  console.log(\n    \"- data.report_metadata?.company:\",\n    data.report_metadata?.company\n  );\n  console.log(\n    \"- Current formattedData.report_metadata.company:\",\n    formattedData.report_metadata.company\n  );\n\n  // Handle scenario_rankings data FIRST (has complete data including response_text extraction)\n  if (\n    data.scenario_rankings &&\n    Array.isArray(data.scenario_rankings) &&\n    data.scenario_rankings.length > 0\n  ) {\n    console.log(\"âœ… Found scenario_rankings:\", data.scenario_rankings.length);\n    const sample = JSON.stringify(data.scenario_rankings[0], null, 2);\n    console.log(\n      \"First scenario_ranking sample:\",\n      sample ? sample.substring(0, 300) : \"No data\"\n    );\n\n    // Debug: Check if scenarios have analysis_details\n    data.scenario_rankings.forEach((ranking, index) => {\n      console.log(\n        `Scenario ${ranking.scenario_id} analysis_details:`,\n        Object.keys(ranking.analysis_details || {})\n      );\n      console.log(\n        `Scenario ${ranking.scenario_id} competitors_ranked:`,\n        ranking.competitors_ranked?.length || 0\n      );\n    });\n\n    // Convert scenario_rankings to the target scenarios format (with response_text extraction)\n    const convertedScenarios = data.scenario_rankings.map((ranking) => {\n      console.log(\n        `Processing scenario_ranking ${ranking.scenario_id}:`,\n        ranking.scenario_title\n      );\n      // Extract from response_text if needed\n      const enhancedRanking = extractFromResponseText(ranking);\n\n      return {\n        scenario_id: enhancedRanking.scenario_id || 0,\n        title:\n          enhancedRanking.scenario_title ||\n          enhancedRanking.title ||\n          `Scenario ${enhancedRanking.scenario_id || 0}`,\n        description:\n          enhancedRanking.scenario_description ||\n          enhancedRanking.description ||\n          enhancedRanking.summary ||\n          enhancedRanking.overview ||\n          enhancedRanking.subtitle ||\n          \"\",\n        // Build top_competitors from analysis_details if competitors_ranked is empty\n        top_competitors: (() => {\n          // First try to use competitors_ranked if it exists and has data\n          if (\n            enhancedRanking.competitors_ranked &&\n            enhancedRanking.competitors_ranked.length > 0\n          ) {\n            return enhancedRanking.competitors_ranked.map((comp) => {\n              const companyName = comp.company || comp.name || comp;\n\n              // Extract detailed metrics from analysis_details if available\n              let detailedMetrics = {};\n              let enhancedRationale =\n                comp.rationale ||\n                comp.reasoning ||\n                comp.explanation ||\n                comp.notes ||\n                \"\";\n\n              if (\n                enhancedRanking.analysis_details &&\n                enhancedRanking.analysis_details[companyName]\n              ) {\n                const analysisDetail =\n                  enhancedRanking.analysis_details[companyName];\n\n                // Extract metrics (scores for different dimensions)\n                if (\n                  analysisDetail.metrics &&\n                  typeof analysisDetail.metrics === \"object\"\n                ) {\n                  detailedMetrics = { ...analysisDetail.metrics };\n                }\n\n                // Enhance rationale with summary and highlights\n                const summaryText = analysisDetail.summary || \"\";\n                const highlightsText = (analysisDetail.highlights || []).join(\n                  \"; \"\n                );\n\n                if (summaryText || highlightsText) {\n                  enhancedRationale = [\n                    summaryText,\n                    highlightsText,\n                    enhancedRationale,\n                  ]\n                    .filter((text) => text && text.length > 0)\n                    .join(\" | \");\n                }\n              }\n\n              return {\n                company: companyName,\n                score: comp.score || comp.rating || comp.value || null,\n                rationale: enhancedRationale,\n                rank: comp.rank || comp.position || null,\n                detailed_metrics: detailedMetrics,\n                ...comp,\n              };\n            });\n          }\n\n          // If no competitors_ranked, build from analysis_details\n          if (\n            enhancedRanking.analysis_details &&\n            typeof enhancedRanking.analysis_details === \"object\"\n          ) {\n            console.log(\n              `Building competitors from analysis_details for scenario ${enhancedRanking.scenario_id}:`,\n              Object.keys(enhancedRanking.analysis_details)\n            );\n            const competitors = Object.entries(\n              enhancedRanking.analysis_details\n            ).map(([companyName, analysisDetail], index) => {\n              // Calculate overall score from metrics if available\n              let overallScore = null;\n              let detailedMetrics = {};\n\n              if (\n                analysisDetail.metrics &&\n                typeof analysisDetail.metrics === \"object\"\n              ) {\n                detailedMetrics = { ...analysisDetail.metrics };\n                // Calculate average score from metrics\n                const metricValues = Object.values(\n                  analysisDetail.metrics\n                ).filter((val) => typeof val === \"number\");\n                if (metricValues.length > 0) {\n                  overallScore = (\n                    metricValues.reduce((sum, val) => sum + val, 0) /\n                    metricValues.length\n                  ).toFixed(1);\n                }\n              }\n\n              // Build rationale from summary and highlights\n              const summaryText = analysisDetail.summary || \"\";\n              const highlightsText = (analysisDetail.highlights || []).join(\n                \"; \"\n              );\n              const rationale = [summaryText, highlightsText]\n                .filter((text) => text && text.length > 0)\n                .join(\" | \");\n\n              return {\n                company: companyName,\n                score: overallScore,\n                rationale: rationale,\n                rank: index + 1,\n                detailed_metrics: detailedMetrics,\n              };\n            });\n\n            // Sort by score (highest first) if scores are available\n            competitors.sort((a, b) => {\n              const scoreA = parseFloat(a.score) || 0;\n              const scoreB = parseFloat(b.score) || 0;\n              return scoreB - scoreA;\n            });\n\n            // Update ranks after sorting\n            competitors.forEach((comp, index) => {\n              comp.rank = index + 1;\n            });\n\n            return competitors;\n          }\n\n          // Fallback to empty array\n          return [];\n        })(),\n        key_findings: enhancedRanking.key_findings || [],\n        sources: enhancedRanking.analysis_details\n          ? Object.values(enhancedRanking.analysis_details).flatMap(\n              (detail) => detail.sources || []\n            )\n          : [],\n        // Mark scenario_rankings data as high priority (has complete data from response_text extraction)\n        isOriginal: true,\n        highPriority: true,\n      };\n    });\n\n    console.log(\n      `Adding ${convertedScenarios.length} converted scenarios to formattedData`\n    );\n    formattedData.scenarios =\n      formattedData.scenarios.concat(convertedScenarios);\n    console.log(`Total scenarios now: ${formattedData.scenarios.length}`);\n  }\n\n  // Handle results data (from Prompt 32 Formatter)\n  if (data.results && Array.isArray(data.results)) {\n    console.log(\"Found results:\", data.results.length);\n\n    // Process each result to extract scenario data\n    data.results.forEach((result, index) => {\n      console.log(`Processing result ${index}:`, Object.keys(result));\n\n      // Try to extract scenario data from various possible structures\n      let scenarioData = null;\n\n      // Check if result has scenario structure directly\n      if (result.scenario_id || result.title || result.competitors) {\n        scenarioData = {\n          scenario_id: result.scenario_id || index + 1,\n          title:\n            result.title || result.scenario_title || `Scenario ${index + 1}`,\n          description:\n            result.description || result.summary || result.overview || \"\",\n          // Preserve all competitor ranking data including scores, rationale, etc.\n          top_competitors: (\n            result.competitors ||\n            result.top_competitors ||\n            result.competitors_ranked ||\n            []\n          ).map((comp) => ({\n            company: comp.company || comp.name || comp,\n            score: comp.score || comp.rating || comp.value || null,\n            rationale:\n              comp.rationale ||\n              comp.reasoning ||\n              comp.explanation ||\n              comp.notes ||\n              \"\",\n            rank: comp.rank || comp.position || null,\n            // Preserve any additional fields that might be present\n            ...comp,\n          })),\n          key_findings: result.key_findings || result.findings || [],\n          sources: result.sources || result.references || [],\n        };\n      }\n\n      // Check if result has response_text that might contain JSON\n      if (!scenarioData && result.response_text) {\n        try {\n          const parsedResponse = JSON.parse(result.response_text);\n          if (parsedResponse.scenarios || parsedResponse.scenario_rankings) {\n            console.log(\"Found parsed scenarios in response_text\");\n            // Handle nested scenario data\n            if (parsedResponse.scenarios) {\n              parsedResponse.scenarios.forEach((scenario) => {\n                formattedData.scenarios.push({\n                  scenario_id: scenario.scenario_id || 0,\n                  title:\n                    scenario.title ||\n                    scenario.scenario_title ||\n                    `Scenario ${scenario.scenario_id || 0}`,\n                  description:\n                    scenario.description ||\n                    scenario.summary ||\n                    scenario.overview ||\n                    \"\",\n                  // Preserve all competitor ranking data including scores, rationale, etc.\n                  top_competitors: (\n                    scenario.top_competitors ||\n                    scenario.competitors ||\n                    []\n                  ).map((comp) => ({\n                    company: comp.company || comp.name || comp,\n                    score: comp.score || comp.rating || comp.value || null,\n                    rationale:\n                      comp.rationale ||\n                      comp.reasoning ||\n                      comp.explanation ||\n                      comp.notes ||\n                      \"\",\n                    rank: comp.rank || comp.position || null,\n                    // Preserve any additional fields that might be present\n                    ...comp,\n                  })),\n                  key_findings:\n                    scenario.key_findings || scenario.findings || [],\n                  sources: scenario.sources || scenario.references || [],\n                });\n              });\n            }\n            if (parsedResponse.scenario_rankings) {\n              parsedResponse.scenario_rankings.forEach((ranking) => {\n                formattedData.scenarios.push({\n                  scenario_id: ranking.scenario_id || 0,\n                  title:\n                    ranking.scenario_title ||\n                    ranking.title ||\n                    `Scenario ${ranking.scenario_id || 0}`,\n                  description:\n                    ranking.scenario_description ||\n                    ranking.description ||\n                    ranking.summary ||\n                    \"\",\n                  // Preserve all competitor ranking data including scores, rationale, etc.\n                  top_competitors: (\n                    ranking.competitors_ranked ||\n                    ranking.competitors ||\n                    []\n                  ).map((comp) => {\n                    const companyName = comp.company || comp.name || comp;\n\n                    // Extract detailed metrics from analysis_details if available\n                    let detailedMetrics = {};\n                    let enhancedRationale =\n                      comp.rationale ||\n                      comp.reasoning ||\n                      comp.explanation ||\n                      comp.notes ||\n                      \"\";\n\n                    if (\n                      ranking.analysis_details &&\n                      ranking.analysis_details[companyName]\n                    ) {\n                      const analysisDetail =\n                        ranking.analysis_details[companyName];\n\n                      // Extract metrics (scores for different dimensions)\n                      if (\n                        analysisDetail.metrics &&\n                        typeof analysisDetail.metrics === \"object\"\n                      ) {\n                        detailedMetrics = { ...analysisDetail.metrics };\n                      }\n\n                      // Enhance rationale with summary and highlights\n                      const summaryText = analysisDetail.summary || \"\";\n                      const highlightsText = (\n                        analysisDetail.highlights || []\n                      ).join(\"; \");\n\n                      if (summaryText || highlightsText) {\n                        enhancedRationale = [\n                          summaryText,\n                          highlightsText,\n                          enhancedRationale,\n                        ]\n                          .filter((text) => text && text.length > 0)\n                          .join(\" | \");\n                      }\n                    }\n\n                    return {\n                      company: companyName,\n                      score: comp.score || comp.rating || comp.value || null,\n                      rationale: enhancedRationale,\n                      rank: comp.rank || comp.position || null,\n                      // Add detailed metrics from analysis_details\n                      detailed_metrics: detailedMetrics,\n                      // Preserve any additional fields that might be present\n                      ...comp,\n                    };\n                  }),\n                  key_findings: ranking.key_findings || ranking.findings || [],\n                  sources: ranking.analysis_details\n                    ? Object.values(ranking.analysis_details).flatMap(\n                        (detail) => detail.sources || []\n                      )\n                    : [],\n                });\n              });\n            }\n          }\n        } catch (e) {\n          console.log(\"Could not parse response_text as JSON:\", e.message);\n        }\n      }\n\n      // Add scenario data if we found it\n      if (scenarioData) {\n        formattedData.scenarios.push(scenarioData);\n      }\n    });\n  }\n\n  // Handle original scenarios data (from Collect All Data node) - HIGHEST PRIORITY for original titles\n  if (data.original_scenarios && Array.isArray(data.original_scenarios)) {\n    console.log(\n      \"Found original scenarios from Collect All Data:\",\n      data.original_scenarios.length\n    );\n    console.log(\n      \"Sample original scenario titles:\",\n      data.original_scenarios\n        .slice(0, 3)\n        .map((s) => s.scenario_title || s.title)\n    );\n\n    formattedData.scenarios = formattedData.scenarios.concat(\n      data.original_scenarios.map((scenario) => ({\n        scenario_id: scenario.scenario_id || 0,\n        title:\n          scenario.scenario_title || // Prioritize scenario_title from original definitions\n          scenario.title ||\n          `Scenario ${scenario.scenario_id || 0}`,\n        description:\n          scenario.scenario_description || // Prioritize scenario_description from original definitions\n          scenario.description ||\n          scenario.summary ||\n          scenario.overview ||\n          scenario.subtitle ||\n          \"\",\n        // Preserve all competitor ranking data including scores, rationale, etc.\n        top_competitors: (scenario.top_competitors || []).map((comp) => ({\n          company: comp.company || comp.name || comp,\n          score: comp.score || comp.rating || comp.value || null,\n          rationale:\n            comp.rationale ||\n            comp.reasoning ||\n            comp.explanation ||\n            comp.notes ||\n            \"\",\n          rank: comp.rank || comp.position || null,\n          // Preserve any additional fields that might be present\n          ...comp,\n        })),\n        key_findings: scenario.key_findings || [],\n        sources: scenario.sources || [],\n        // Mark as original scenario for deduplication priority\n        isOriginal: true,\n      }))\n    );\n  }\n\n  // Handle direct scenarios data (from first document structure) - LOWER PRIORITY after scenario_rankings\n  if (data.scenarios && Array.isArray(data.scenarios)) {\n    console.log(\"Found scenarios:\", data.scenarios.length);\n    console.log(\n      \"Sample scenario titles:\",\n      data.scenarios.slice(0, 3).map((s) => s.scenario_title || s.title)\n    );\n\n    formattedData.scenarios = formattedData.scenarios.concat(\n      data.scenarios.map((scenario) => ({\n        scenario_id: scenario.scenario_id || 0,\n        title:\n          scenario.scenario_title || // Prioritize scenario_title from original definitions\n          scenario.title ||\n          `Scenario ${scenario.scenario_id || 0}`,\n        description:\n          scenario.scenario_description || // Prioritize scenario_description from original definitions\n          scenario.description ||\n          scenario.summary ||\n          scenario.overview ||\n          scenario.subtitle ||\n          \"\",\n        // Build top_competitors from analysis_details if top_competitors is empty\n        top_competitors: (() => {\n          // First try to use existing top_competitors if it has data\n          if (scenario.top_competitors && scenario.top_competitors.length > 0) {\n            return scenario.top_competitors.map((comp) => ({\n              company: comp.company || comp.name || comp,\n              score: comp.score || comp.rating || comp.value || null,\n              rationale:\n                comp.rationale ||\n                comp.reasoning ||\n                comp.explanation ||\n                comp.notes ||\n                \"\",\n              rank: comp.rank || comp.position || null,\n              detailed_metrics: comp.detailed_metrics || {},\n              ...comp,\n            }));\n          }\n\n          // If no top_competitors but has analysis_details, build from analysis_details\n          if (\n            scenario.analysis_details &&\n            typeof scenario.analysis_details === \"object\"\n          ) {\n            console.log(\n              `Building competitors from analysis_details for scenario ${scenario.scenario_id}:`,\n              Object.keys(scenario.analysis_details)\n            );\n\n            const competitors = Object.entries(scenario.analysis_details).map(\n              ([companyName, analysisDetail], index) => {\n                // Calculate overall score from metrics if available\n                let overallScore = null;\n                let detailedMetrics = {};\n\n                if (\n                  analysisDetail.metrics &&\n                  typeof analysisDetail.metrics === \"object\"\n                ) {\n                  detailedMetrics = { ...analysisDetail.metrics };\n                  // Calculate average score from metrics\n                  const metricValues = Object.values(\n                    analysisDetail.metrics\n                  ).filter((val) => typeof val === \"number\");\n                  if (metricValues.length > 0) {\n                    overallScore = (\n                      metricValues.reduce((sum, val) => sum + val, 0) /\n                      metricValues.length\n                    ).toFixed(1);\n                  }\n                }\n\n                // Build rationale from summary and highlights\n                const summaryText = analysisDetail.summary || \"\";\n                const highlightsText = (analysisDetail.highlights || []).join(\n                  \"; \"\n                );\n                const rationale = [summaryText, highlightsText]\n                  .filter((text) => text && text.length > 0)\n                  .join(\" | \");\n\n                return {\n                  company: companyName,\n                  score: overallScore,\n                  rationale: rationale,\n                  rank: index + 1,\n                  detailed_metrics: detailedMetrics,\n                };\n              }\n            );\n\n            // Sort by score (highest first) if scores are available\n            competitors.sort((a, b) => {\n              const scoreA = parseFloat(a.score) || 0;\n              const scoreB = parseFloat(b.score) || 0;\n              return scoreB - scoreA;\n            });\n\n            // Update ranks after sorting\n            competitors.forEach((comp, index) => {\n              comp.rank = index + 1;\n            });\n\n            console.log(\n              `Built ${competitors.length} competitors for scenario ${scenario.scenario_id}:`,\n              competitors.map((c) => `${c.company}: ${c.score}`)\n            );\n            return competitors;\n          }\n\n          // Fallback to empty array\n          console.log(\n            `No competitors data found for scenario ${scenario.scenario_id}`\n          );\n          return [];\n        })(),\n        key_findings: scenario.key_findings || [],\n        sources: scenario.sources || [],\n        // Mark as original scenario for deduplication priority\n        isOriginal: true,\n      }))\n    );\n  }\n\n  // Handle enhanced citations from multiple sources\n  if (\n    data.enhanced_citations &&\n    Array.isArray(data.enhanced_citations) &&\n    data.enhanced_citations.length > 0\n  ) {\n    console.log(\"âœ… Found enhanced_citations:\", data.enhanced_citations.length);\n    const sample = JSON.stringify(data.enhanced_citations[0], null, 2);\n    console.log(\n      \"First enhanced_citation sample:\",\n      sample ? sample.substring(0, 200) : \"No data\"\n    );\n    console.log(\n      `Adding ${data.enhanced_citations.length} enhanced citations to formattedData`\n    );\n    formattedData.enhanced_citations = formattedData.enhanced_citations.concat(\n      data.enhanced_citations\n    );\n    console.log(\n      `Total enhanced citations now: ${formattedData.enhanced_citations.length}`\n    );\n  }\n\n  if (data.source_citations && Array.isArray(data.source_citations)) {\n    console.log(\"Found source_citations:\", data.source_citations.length);\n    formattedData.enhanced_citations = formattedData.enhanced_citations.concat(\n      data.source_citations\n    );\n  }\n\n  if (data.scraping_results && Array.isArray(data.scraping_results)) {\n    console.log(\"Found scraping_results:\", data.scraping_results.length);\n    formattedData.enhanced_citations = formattedData.enhanced_citations.concat(\n      data.scraping_results\n    );\n  }\n\n  if (data.research_results && Array.isArray(data.research_results)) {\n    console.log(\"Found research_results:\", data.research_results.length);\n    formattedData.enhanced_citations = formattedData.enhanced_citations.concat(\n      data.research_results\n    );\n  }\n\n  // Handle other data types\n  if (data.report_metadata) {\n    formattedData.report_metadata = {\n      company:\n        data.report_metadata.company ||\n        formattedData.report_metadata.company ||\n        \"Unknown Company\",\n      total_scenarios:\n        data.report_metadata.total_scenarios ||\n        formattedData.report_metadata.total_scenarios ||\n        0,\n      competitors_analyzed:\n        data.report_metadata.competitors_analyzed ||\n        formattedData.report_metadata.competitors_analyzed ||\n        [],\n    };\n  }\n\n  // Handle company name from various sources - filter out invalid values\n  const invalidCompanyNames = [\n    \"Report\",\n    \"Unknown Company\",\n    \"Company\",\n    \"Target Company\",\n    \"\",\n  ];\n\n  if (data.company && !invalidCompanyNames.includes(data.company)) {\n    formattedData.report_metadata.company = data.company;\n    console.log(\"Extracted company name from data.company:\", data.company);\n  }\n  if (data.company_name && !invalidCompanyNames.includes(data.company_name)) {\n    formattedData.report_metadata.company = data.company_name;\n    console.log(\n      \"Extracted company name from data.company_name:\",\n      data.company_name\n    );\n  }\n  if (\n    data.target_company &&\n    !invalidCompanyNames.includes(data.target_company)\n  ) {\n    formattedData.report_metadata.company = data.target_company;\n    console.log(\n      \"Extracted company name from data.target_company:\",\n      data.target_company\n    );\n  }\n\n  // Additional fallback: try to extract company name from scenarios if not found or invalid\n  if (\n    !formattedData.report_metadata.company ||\n    invalidCompanyNames.includes(formattedData.report_metadata.company)\n  ) {\n    // Try to get company name from scenarios - look for the most frequently mentioned company\n    const companyMentions = {};\n\n    formattedData.scenarios.forEach((scenario) => {\n      if (scenario.top_competitors && Array.isArray(scenario.top_competitors)) {\n        scenario.top_competitors.forEach((comp, index) => {\n          if (comp.company && !invalidCompanyNames.includes(comp.company)) {\n            if (!companyMentions[comp.company]) {\n              companyMentions[comp.company] = {\n                count: 0,\n                totalScore: 0,\n                positions: [],\n              };\n            }\n            companyMentions[comp.company].count++;\n            companyMentions[comp.company].totalScore += comp.score || 0;\n            companyMentions[comp.company].positions.push(index + 1);\n          }\n        });\n      }\n    });\n\n    // Find the company with the most mentions and highest average score\n    let bestCompany = null;\n    let bestScore = 0;\n\n    Object.keys(companyMentions).forEach((company) => {\n      const mentions = companyMentions[company];\n      const avgScore = mentions.totalScore / mentions.count;\n      const avgPosition =\n        mentions.positions.reduce((sum, pos) => sum + pos, 0) /\n        mentions.positions.length;\n\n      // Score based on mentions, average score, and position (lower position is better)\n      const companyScore = mentions.count * 2 + avgScore - avgPosition * 0.5;\n\n      if (companyScore > bestScore) {\n        bestScore = companyScore;\n        bestCompany = company;\n      }\n    });\n\n    if (bestCompany) {\n      formattedData.report_metadata.company = bestCompany;\n      console.log(\n        \"Extracted company name from scenario analysis:\",\n        bestCompany,\n        \"(mentions:\",\n        companyMentions[bestCompany].count,\n        \"avg score:\",\n        (\n          companyMentions[bestCompany].totalScore /\n          companyMentions[bestCompany].count\n        ).toFixed(1),\n        \")\"\n      );\n    } else {\n      // Final fallback: try to get company name from the first scenario's top competitor\n      if (\n        formattedData.scenarios.length > 0 &&\n        formattedData.scenarios[0].top_competitors.length > 0\n      ) {\n        const firstCompany =\n          formattedData.scenarios[0].top_competitors[0].company;\n        if (firstCompany && !invalidCompanyNames.includes(firstCompany)) {\n          formattedData.report_metadata.company = firstCompany;\n          console.log(\n            \"Extracted company name from first scenario:\",\n            firstCompany\n          );\n        }\n      }\n    }\n  }\n\n  // Handle scenarios_completed count\n  if (\n    data.scenarios_completed &&\n    formattedData.report_metadata.total_scenarios === 0\n  ) {\n    formattedData.report_metadata.total_scenarios = data.scenarios_completed;\n  }\n\n  if (data.overall_metrics) {\n    Object.assign(formattedData.overall_metrics, data.overall_metrics);\n  }\n\n  if (data.company_performance) {\n    Object.assign(formattedData.company_performance, data.company_performance);\n  }\n\n  if (data.quality_metrics) {\n    Object.assign(formattedData.quality_metrics, data.quality_metrics);\n  }\n\n  // Handle data sources from multiple possible locations\n  if (data.data_sources_table) {\n    console.log(\"Found data_sources_table:\", data.data_sources_table.length);\n    formattedData.data_sources_table = formattedData.data_sources_table.concat(\n      data.data_sources_table\n    );\n  }\n  if (data.data_sources) {\n    console.log(\"Found data_sources:\", data.data_sources.length);\n    formattedData.data_sources_table = formattedData.data_sources_table.concat(\n      data.data_sources\n    );\n  }\n  if (data.source_citations) {\n    console.log(\n      \"Found source_citations for data_sources_table:\",\n      data.source_citations.length\n    );\n    formattedData.data_sources_table = formattedData.data_sources_table.concat(\n      data.source_citations\n    );\n  }\n\n  // Debug: Show current data_sources_table count\n  console.log(\n    \"Current data_sources_table count:\",\n    formattedData.data_sources_table.length\n  );\n});\n\nconsole.log(\"\\n=== REMOVING DUPLICATES ===\");\nconsole.log(\"Scenarios before deduplication:\", formattedData.scenarios.length);\nconsole.log(\n  \"Enhanced citations before deduplication:\",\n  formattedData.enhanced_citations.length\n);\nconsole.log(\n  \"Data sources before deduplication:\",\n  formattedData.data_sources_table.length\n);\n\n// If no scenarios found, provide detailed debugging information\nif (formattedData.scenarios.length === 0) {\n  console.log(\"\\n=== NO SCENARIOS FOUND - DEBUGGING INFO ===\");\n  console.log(\"Total input items processed:\", items.length);\n  items.forEach((item, index) => {\n    const data = item.json || {};\n    console.log(`\\nItem ${index} structure:`);\n    console.log(\"Keys:\", Object.keys(data));\n    console.log(\"Has scenario_rankings:\", !!data.scenario_rankings);\n    console.log(\"Has scenarios:\", !!data.scenarios);\n    console.log(\"Has results:\", !!data.results);\n    console.log(\"Has response_text:\", !!data.response_text);\n    console.log(\"Data type:\", typeof data);\n    console.log(\"Is array:\", Array.isArray(data));\n\n    // Show sample of the data structure\n    if (data.scenario_rankings && data.scenario_rankings.length > 0) {\n      const sample = JSON.stringify(data.scenario_rankings[0], null, 2);\n      console.log(\n        \"scenario_rankings sample:\",\n        sample ? sample.substring(0, 200) + \"...\" : \"No data\"\n      );\n    }\n    if (data.scenarios && data.scenarios.length > 0) {\n      const sample = JSON.stringify(data.scenarios[0], null, 2);\n      console.log(\n        \"scenarios sample:\",\n        sample ? sample.substring(0, 200) + \"...\" : \"No data\"\n      );\n    }\n    if (data.results && data.results.length > 0) {\n      const sample = JSON.stringify(data.results[0], null, 2);\n      console.log(\n        \"results sample:\",\n        sample ? sample.substring(0, 200) + \"...\" : \"No data\"\n      );\n    }\n  });\n}\n\n// Remove duplicates from scenarios, keeping the scenario with the most complete data\nconst uniqueScenarios = [];\nconst scenarioGroups = new Map();\n\n// Group scenarios by ID\nformattedData.scenarios.forEach((scenario) => {\n  const id = scenario.scenario_id;\n  if (!scenarioGroups.has(id)) {\n    scenarioGroups.set(id, []);\n  }\n  scenarioGroups.get(id).push(scenario);\n});\n\n// For each group, keep the scenario with the most complete data, prioritizing original scenarios\nscenarioGroups.forEach((scenarios, id) => {\n  if (scenarios.length === 1) {\n    uniqueScenarios.push(scenarios[0]);\n    // Special debug for Scenario 1\n    if (id === 1) {\n      console.log(`\\nðŸ” SCENARIO 1 DEDUPLICATION DEBUG:`);\n      console.log(\"Only one instance found, using it:\");\n      console.log(\"- Title:\", scenarios[0].title);\n      console.log(\"- Competitors:\", scenarios[0].top_competitors?.length || 0);\n      console.log(\"- Key findings:\", scenarios[0].key_findings?.length || 0);\n      console.log(\"- Sources:\", scenarios[0].sources?.length || 0);\n      console.log(\"- isOriginal:\", scenarios[0].isOriginal);\n    }\n  } else {\n    console.log(`\\nDeduplicating scenarios for ID ${id}:`);\n    scenarios.forEach((s, index) => {\n      console.log(\n        `  Scenario ${index + 1}: title=\"${s.title}\", isOriginal=${\n          s.isOriginal\n        }, competitors=${s.top_competitors?.length || 0}, findings=${\n          s.key_findings?.length || 0\n        }`\n      );\n    });\n\n    // Find the scenario with the most complete data, prioritizing high priority scenarios first\n    const bestScenario = scenarios.reduce((best, current) => {\n      // Priority 0: High priority scenarios (from scenario_rankings with response_text extraction)\n      if (best.highPriority && !current.highPriority) return best;\n      if (!best.highPriority && current.highPriority) return current;\n\n      // Priority 1: Original scenarios with proper titles\n      const bestIsOriginal =\n        best.isOriginal && best.title && !best.title.startsWith(\"Scenario \");\n      const currentIsOriginal =\n        current.isOriginal &&\n        current.title &&\n        !current.title.startsWith(\"Scenario \");\n\n      if (bestIsOriginal && !currentIsOriginal) return best;\n      if (!bestIsOriginal && currentIsOriginal) return current;\n\n      // Priority 2: Scenarios with better titles (not generic)\n      const bestHasGoodTitle =\n        best.title &&\n        !best.title.startsWith(\"Scenario \") &&\n        best.title.length > 10;\n      const currentHasGoodTitle =\n        current.title &&\n        !current.title.startsWith(\"Scenario \") &&\n        current.title.length > 10;\n\n      if (bestHasGoodTitle && !currentHasGoodTitle) return best;\n      if (!bestHasGoodTitle && currentHasGoodTitle) return current;\n\n      // Priority 3: Most complete data (competitors + sources)\n      const bestScore =\n        (best.top_competitors?.length || 0) + (best.sources?.length || 0);\n      const currentScore =\n        (current.top_competitors?.length || 0) + (current.sources?.length || 0);\n\n      return currentScore > bestScore ? current : best;\n    });\n\n    console.log(\n      `  Selected: title=\"${bestScenario.title}\", isOriginal=${bestScenario.isOriginal}`\n    );\n    uniqueScenarios.push(bestScenario);\n  }\n});\n\n// Sort by scenario_id to maintain order\nuniqueScenarios.sort((a, b) => a.scenario_id - b.scenario_id);\n\n// Only enhance scenarios if titles/descriptions are missing (fallback only)\nuniqueScenarios.forEach((scenario) => {\n  // Debug: Show what title we have for each scenario\n  console.log(\n    `Scenario ${scenario.scenario_id} title check: \"${scenario.title}\"`\n  );\n\n  // Only generate title if completely missing or very generic\n  const isGenericTitle =\n    !scenario.title ||\n    scenario.title === \"\" ||\n    scenario.title.startsWith(\"Scenario \") ||\n    scenario.title ===\n      `Competitive Analysis - Scenario ${scenario.scenario_id}` ||\n    scenario.title.l